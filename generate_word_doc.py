#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json

# Don't import docx at module level - do it only when needed
# This prevents immediate failure if docx is not installed

def get_word_language_code(language):
    """
    ××—×–×™×¨ ××ª ×§×•×“ ×”×©×¤×” ×”××ª××™× ×œ-Word ×œ×¤×™ ×©× ×”×©×¤×” ××• ×§×•×“ ×”×©×¤×”
    """
    language_map = {
        # ×¢×‘×¨×™×ª
        'Hebrew': 'he-IL',
        'he': 'he-IL',
        'translate-he': 'he-IL',
        # ×™×™×“×™×©
        'Yiddish': 'yi',
        'yi': 'yi',
        'translate-yi': 'yi',
        # ×¢×¨×‘×™×ª
        'Arabic': 'ar-SA',
        'ar': 'ar-SA',
        # ×× ×’×œ×™×ª (×‘×¨×™×¨×ª ××—×“×œ ×œ×©×¤×•×ª LTR)
        'English': 'en-US',
        'en': 'en-US',
    }
    return language_map.get(language, 'he-IL')  # ×‘×¨×™×¨×ª ××—×“×œ: ×¢×‘×¨×™×ª

def create_hebrew_word_document(transcription, title, output_path, language='Hebrew'):
    """
    ×™×•×¦×¨ ××¡××š Word ×‘×©×™×˜×” ×©×œ ×”×—×œ×¤×ª ×ª×‘× ×™×ª ×¢×•×‘×“×ª
    """
    try:
        # Check if python-docx is available
        try:
            from docx import Document
            from docx.shared import Inches, Pt
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            from docx.oxml.ns import qn
            from docx.oxml import OxmlElement
        except ImportError as e:
            print(f"python-docx not available: {str(e)}", file=sys.stderr)
            print("Falling back to HTML generation", file=sys.stderr)
            return create_html_fallback(transcription, title, output_path)

        import os
        import shutil
        from zipfile import ZipFile

        # ×‘×“×™×§×” ×× ×”×©×¤×” ×”×™× RTL - ×¨×§ ××– × ×©×ª××© ×‘×ª×‘× ×™×ª
        rtl_languages = ['Hebrew', 'Yiddish', 'Arabic', 'he', 'yi', 'ar', 'translate-he', 'translate-yi']
        is_rtl = language in rtl_languages

        print(f"ğŸ” Language check: '{language}' -> RTL={is_rtl}", file=sys.stderr)

        # ×× ×–×• ×œ× ×©×¤×ª RTL, ××œ ×ª×©×ª××© ×‘×ª×‘× ×™×ª - ×¦×•×¨ ××¡××š ×—×“×©
        if not is_rtl:
            print(f"ğŸ“ Creating LTR document without template for language: {language}", file=sys.stderr)
            return create_basic_hebrew_document(transcription, title, output_path, language)

        # ×‘×“×™×§×” ×× ×§×™×™××ª ×ª×‘× ×™×ª ×¢×•×‘×“×ª (×¨×§ ×œ×©×¤×•×ª RTL)
        print(f"ğŸ“ Creating RTL document with template for language: {language}", file=sys.stderr)
        possible_templates = [
            'template-hebrew-rtl.docx',  # ×ª×‘× ×™×ª RTL ×—×“×©×” ×•××ª×•×§× ×ª
            '×—×–×¨ ××”×©×¨×ª ×ª×§×™×Ÿ 2.docx',
            '×“×•×’××”_Word_××•×©×œ××ª.docx',
            '×‘×“×™×§×”_×ª×‘× ×™×ª_×¢×•×‘×“×ª.docx',
            'template.docx',
            'simple-template.docx'
        ]

        template_path = None
        print(f"Looking for templates in directory: {os.getcwd()}", file=sys.stderr)
        print(f"Directory contents: {os.listdir('.')[:10]}...", file=sys.stderr)

        for template in possible_templates:
            print(f"Checking template: {template}", file=sys.stderr)
            if os.path.exists(template):
                template_path = template
                print(f"Found working template: {template}", file=sys.stderr)
                break
            else:
                print(f"Template not found: {template}", file=sys.stderr)

        if not template_path:
            print("No working template found, falling back to basic creation", file=sys.stderr)
            return create_basic_hebrew_document(transcription, title, output_path)

        # ×”×¢×ª×§×ª ×”×ª×‘× ×™×ª
        shutil.copy2(template_path, output_path)

        # × ×™×§×•×™ ×•×”×›× ×ª ×”×˜×§×¡×˜
        clean_text = transcription.replace('\r\n', '\n').replace('\n\n\n', '\n\n').strip()
        sections = [section.strip() for section in clean_text.split('\n\n') if section.strip()]

        # ×¤×ª×™×—×ª ×”×§×•×‘×¥ ×›-ZIP ×•×¢×“×›×•×Ÿ ×”×ª×•×›×Ÿ
        with ZipFile(output_path, 'r') as zip_ref:
            # ×§×¨×™××ª document.xml ×”×§×™×™×
            with zip_ref.open('word/document.xml') as doc_file:
                doc_content = doc_file.read().decode('utf-8')

        # ×™×¦×™×¨×ª ×ª×•×›×Ÿ ×—×“×© ×‘××‘× ×” ×”×§×™×™×
        new_paragraphs = []

        # ×§×‘×™×¢×ª ×›×™×•×•×Ÿ ×˜×§×¡×˜ ×œ×¤×™ ×©×¤×”
        # ×ª××™×›×” ×‘×©××•×ª ××œ××™× ×•×§×•×“×™× ×§×¦×¨×™×
        print(f"ğŸ” DEBUG: Received language = '{language}'", file=sys.stderr)
        rtl_languages = ['Hebrew', 'Yiddish', 'Arabic', 'he', 'yi', 'ar', 'translate-he', 'translate-yi']
        is_rtl = language in rtl_languages
        # ×‘-RTL ×¢× bidi, "left" = ×”×ª×—×œ×” = ×™××™×Ÿ. ×‘-LTR, "left" = ×©×××œ
        alignment = 'left'  # ×ª××™×“ left - ×¢× bidi ×–×” ×™×”×™×” ×‘×¦×“ ×”× ×›×•×Ÿ
        lang_code = get_word_language_code(language)
        print(f"ğŸ” DEBUG: is_rtl = {is_rtl}, alignment = '{alignment}', lang_code = '{lang_code}'", file=sys.stderr)

        # ×›×•×ª×¨×ª - ×¢× ×”×’×“×¨×ª ×©×¤×” ××¤×•×¨×©×ª ×œ×¤×™ ×”×©×¤×” ×©× ×‘×—×¨×”
        title_paragraph = f'''
<w:p>
  <w:pPr>
    <w:bidi/>
    <w:jc w:val="{alignment}"/>
    <w:spacing w:after="400"/>
    <w:rPr>
      <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
      <w:sz w:val="32"/>
      <w:b/>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
  </w:pPr>
  <w:r>
    <w:rPr>
      <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
      <w:sz w:val="32"/>
      <w:b/>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
    <w:t>{escape_xml(title)}</w:t>
  </w:r>
</w:p>'''
        new_paragraphs.append(title_paragraph)

        # ×©×•×¨×” ×¨×™×§×”
        new_paragraphs.append('<w:p></w:p>')

        # ×¤×¡×§××•×ª ×ª×•×›×Ÿ - ×¢× fallback ×—×›× ×× ×’××™× ×™ ×œ× ×—×™×œ×§
        import re

        # ×‘×“×™×§×” ×× ×’××™× ×™ ×—×™×œ×§ ×œ×¤×¡×§××•×ª ××• ×©×œ×— ×’×•×© ××—×“
        if len(sections) == 1 and len(sections[0]) > 500:
            print("âš ï¸ Gemini didn't split paragraphs, using smart Python fallback", file=sys.stderr)

            # ×—×œ×•×§×” ×—×›××” ×©×œ Python ×œ×¤×¡×§××•×ª ×©×œ 5-10 ×©×•×¨×•×ª
            all_text = sections[0]
            all_text = fix_hebrew_punctuation(all_text)

            # ×—×œ×•×§×” ×œ×¤×¡×§××•×ª ×œ×¤×™ ××©×¤×˜×™× (×œ× ××™×œ×™×!)
            sentences = re.split(r'(?<=[.!?:])\s+', all_text)
            current_para = ""
            sentence_count = 0

            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue

                current_para += sentence + " "
                sentence_count += 1

                # ×™×¦×™×¨×ª ×¤×¡×§×”: 4-7 ××©×¤×˜×™× (×‘×¢×¨×š 5-10 ×©×•×¨×•×ª)
                if sentence_count >= 4 and len(current_para) >= 400:
                    # ×‘×“×•×§ ××™×¨×›××•×ª ×–×•×’×™×•×ª
                    quote_count = current_para.count('"')
                    if quote_count % 2 == 0:  # ×–×•×’×™ ××™×¨×›××•×ª
                        para_text = current_para.strip()
                        if para_text:
                            content_paragraph = f'''
<w:p>
  <w:pPr>
    <w:jc w:val="{alignment}"/>
    <w:bidi/>
    <w:spacing w:after="240"/>
    <w:rPr>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
  </w:pPr>
  <w:r>
    <w:rPr>
      <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
      <w:sz w:val="28"/>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
    <w:t>{escape_xml(para_text)}</w:t>
  </w:r>
</w:p>'''
                            new_paragraphs.append(content_paragraph)
                        current_para = ""
                        sentence_count = 0

            # ×¤×¡×§×” ××—×¨×•× ×”
            if current_para.strip():
                para_text = current_para.strip()
                content_paragraph = f'''
<w:p>
  <w:pPr>
    <w:jc w:val="{alignment}"/>
    <w:bidi/>
    <w:spacing w:after="240"/>
    <w:rPr>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
  </w:pPr>
  <w:r>
    <w:rPr>
      <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
      <w:sz w:val="28"/>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
    <w:t>{escape_xml(para_text)}</w:t>
  </w:r>
</w:p>'''
                new_paragraphs.append(content_paragraph)
        else:
            # ×’××™× ×™ ×—×™×œ×§ × ×›×•×Ÿ - ×”×©×ª××© ×‘×¤×¡×§××•×ª ×©×œ×•
            print(f"âœ… Using Gemini's {len(sections)} paragraphs", file=sys.stderr)
            for section in sections:
                processed_text = fix_hebrew_punctuation(section)
                content_paragraph = f'''
<w:p>
  <w:pPr>
    <w:jc w:val="{alignment}"/>
    <w:bidi/>
    <w:spacing w:after="240"/>
    <w:rPr>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
  </w:pPr>
  <w:r>
    <w:rPr>
      <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
      <w:sz w:val="28"/>
      <w:lang w:val="{lang_code}" w:bidi="{lang_code}"/>
      <w:rtl/>
    </w:rPr>
    <w:t>{escape_xml(processed_text)}</w:t>
  </w:r>
</w:p>'''
                new_paragraphs.append(content_paragraph)

        # ×”×—×œ×¤×ª ×”×ª×•×›×Ÿ
        import re

        # ×”×•×¡×¤×ª sectPr (×”×’×“×¨×•×ª ×¡×¢×™×£) ×¢× ×›×™×•×•×Ÿ RTL
        if is_rtl:
            section_props = '''<w:sectPr>
  <w:bidi/>
  <w:pgSz w:w="11906" w:h="16838"/>
  <w:pgMar w:top="1440" w:right="1800" w:bottom="1440" w:left="1800" w:header="720" w:footer="720" w:gutter="0"/>
  <w:cols w:space="720"/>
  <w:docGrid w:linePitch="360"/>
</w:sectPr>'''
        else:
            section_props = '''<w:sectPr>
  <w:pgSz w:w="11906" w:h="16838"/>
  <w:pgMar w:top="1440" w:right="1800" w:bottom="1440" w:left="1800" w:header="720" w:footer="720" w:gutter="0"/>
  <w:cols w:space="720"/>
  <w:docGrid w:linePitch="360"/>
</w:sectPr>'''

        # ××•×¦× ××ª ×”-body ×•××—×œ×™×£ ××ª ×”×ª×•×›×Ÿ - ×›×•×œ×œ sectPr ×‘×¡×•×£
        body_content = ''.join(new_paragraphs) + section_props
        new_doc_content = re.sub(
            r'<w:body[^>]*>.*?</w:body>',
            f'<w:body>{body_content}</w:body>',
            doc_content,
            flags=re.DOTALL
        )

        # ×©××™×¨×ª ×”×§×•×‘×¥ ×”××¢×•×“×›×Ÿ
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_file:
            temp_path = temp_file.name

        # ×¢×“×›×•×Ÿ ×”×§×•×‘×¥ - ×›×•×œ×œ styles.xml ×œ×ª××™×›×” ×‘-RTL
        with ZipFile(template_path, 'r') as original_zip:
            with ZipFile(temp_path, 'w') as new_zip:
                for item in original_zip.infolist():
                    if item.filename == 'word/document.xml':
                        new_zip.writestr(item, new_doc_content.encode('utf-8'))
                    elif item.filename == 'word/styles.xml' and is_rtl:
                        # ×¢×“×›×•×Ÿ styles.xml ×œ×”×•×¡×¤×ª RTL ×›×‘×¨×™×¨×ª ××—×“×œ
                        styles_content = original_zip.read(item.filename).decode('utf-8')

                        # ×¢×“×›×•×Ÿ pPrDefault ×œ×”×•×¡×¤×ª bidi
                        if '<w:pPrDefault>' in styles_content:
                            # ×× ×™×© pPrDefault, × ×•×¡×™×£ bidi ×‘×ª×•×›×•
                            if '<w:pPr>' in styles_content and '<w:pPrDefault>' in styles_content:
                                # ×”×•×¡×£ bidi ×œ-pPr ×”×§×™×™×
                                styles_content = re.sub(
                                    r'(<w:pPrDefault>\s*<w:pPr>)',
                                    r'\1<w:bidi/>',
                                    styles_content
                                )
                            else:
                                # ×”×•×¡×£ pPr ×¢× bidi
                                styles_content = styles_content.replace(
                                    '<w:pPrDefault>',
                                    '<w:pPrDefault><w:pPr><w:bidi/></w:pPr>'
                                )

                        # ×¢×“×›×•×Ÿ ×”×©×¤×” ×‘-rPrDefault
                        styles_content = re.sub(
                            r'<w:lang[^/]*/>',
                            f'<w:lang w:val="{lang_code}" w:eastAsia="en-US" w:bidi="{lang_code}"/>',
                            styles_content
                        )

                        print(f"Updated styles.xml with RTL defaults", file=sys.stderr)
                        new_zip.writestr(item, styles_content.encode('utf-8'))
                    elif item.filename == 'word/settings.xml' and is_rtl:
                        # ×¢×“×›×•×Ÿ settings.xml ×œ×”×•×¡×¤×ª ×›×™×•×•×Ÿ ××¡××š RTL
                        settings_content = original_zip.read(item.filename).decode('utf-8')

                        # ×”×•×¡×£ bidi ××—×¨×™ characterSpacingControl ××• ×‘×ª×—×™×œ×ª settings
                        if '<w:bidi/>' not in settings_content:
                            if '<w:characterSpacingControl' in settings_content:
                                settings_content = re.sub(
                                    r'(<w:characterSpacingControl[^/]*/>)',
                                    r'\1<w:bidi/>',
                                    settings_content
                                )
                            elif '<w:defaultTabStop' in settings_content:
                                settings_content = re.sub(
                                    r'(<w:defaultTabStop[^/]*/>)',
                                    r'\1<w:bidi/>',
                                    settings_content
                                )

                        print(f"Updated settings.xml with RTL direction", file=sys.stderr)
                        new_zip.writestr(item, settings_content.encode('utf-8'))
                    else:
                        data = original_zip.read(item.filename)
                        new_zip.writestr(item, data)

        # ×”×—×œ×¤×ª ×”×§×•×‘×¥ ×”×¡×•×¤×™
        shutil.move(temp_path, output_path)

        print(f"Word document created successfully: {output_path}", file=sys.stderr)
        return True

    except Exception as e:
        print(f"Error creating Word document: {str(e)}")
        return False

def create_basic_hebrew_document(transcription, title, output_path, language='Hebrew'):
    """
    ×™×¦×™×¨×ª ××¡××š ×‘×¡×™×¡×™ ×× ××™×Ÿ ×ª×‘× ×™×ª - ×¢× ×”×’×“×¨×•×ª RTL ××• LTR ×œ×¤×™ ×”×©×¤×”
    """
    import re  # needed for sentence splitting
    try:
        # Import docx here too
        from docx import Document
        from docx.shared import Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        from docx.oxml.ns import qn
        from docx.oxml import OxmlElement

        # ×‘×“×™×§×” ×× ×”×©×¤×” RTL ××• LTR
        rtl_languages = ['Hebrew', 'Yiddish', 'Arabic', 'he', 'yi', 'ar', 'translate-he', 'translate-yi']
        is_rtl = language in rtl_languages

        # ×§×‘×œ×ª ×§×•×“ ×”×©×¤×” ×”××ª××™×
        lang_code = get_word_language_code(language)
        print(f"ğŸ“ Creating basic document: language={language}, RTL={is_rtl}, lang_code={lang_code}", file=sys.stderr)
        doc = Document()

        # ×”×’×“×¨×ª ×”×©×¤×” ×”×¢×™×§×¨×™×ª ×©×œ ×”××¡××š
        doc_element = doc.element
        doc_element.set(qn('xml:lang'), lang_code)

        # ×”×’×“×¨×ª ×©×¤×ª ×‘×¨×™×¨×ª ××—×“×œ ×œ××¡××š ×‘×ª×•×š settings
        if is_rtl:
            try:
                # ×”×’×“×¨×ª ×©×¤×” ×‘-document settings
                settings = doc.settings.element
                themeFontLang = OxmlElement('w:themeFontLang')
                themeFontLang.set(qn('w:val'), lang_code)
                themeFontLang.set(qn('w:bidi'), lang_code)
                settings.append(themeFontLang)
                print(f"Set document default language to {lang_code}", file=sys.stderr)
            except Exception as lang_err:
                print(f"Warning: Could not set document language: {lang_err}", file=sys.stderr)

    except Exception as e:
        print(f"Error creating basic document: {str(e)}", file=sys.stderr)
        # ×× ×’× ×–×” × ×›×©×œ, × ×™×¦×•×¨ ××¡××š HTML ×¤×©×•×˜
        return create_html_fallback(transcription, title, output_path)

    try:
        # ×›×•×ª×¨×ª ×¢× ×”×’×“×¨×•×ª RTL ××• LTR
        title_paragraph = doc.add_paragraph()
        title_run = title_paragraph.add_run(title)
        title_run.font.name = 'David'
        title_run.font.size = Pt(18)
        title_run.bold = True

        # ×™×™×©×•×¨ ×œ×¤×™ ×©×¤×”
        if is_rtl:
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
            # ×”×•×¡×¤×ª ×”×’×“×¨×•×ª RTL ×œ×›×•×ª×¨×ª
            set_rtl_paragraph(title_paragraph, language)
        else:
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

        # ×©×•×¨×” ×¨×™×§×”
        doc.add_paragraph()

        # ×¢×™×‘×•×“ ×”×ª×•×›×Ÿ
        clean_text = transcription.replace('\r\n', '\n').replace('\n\n\n', '\n\n').strip()

        # ×”×¨×¥ fix_hebrew_punctuation ×¨×§ ×¢×œ ×˜×§×¡×˜ RTL
        if is_rtl:
            clean_text = fix_hebrew_punctuation(clean_text)

        # ×¢× fallback ×—×›× ×× ×’××™× ×™ ×œ× ×—×™×œ×§
        sections = [section.strip() for section in clean_text.split('\n\n') if section.strip()]

        # ×‘×“×™×§×” ×× ×’××™× ×™ ×—×™×œ×§ ×œ×¤×¡×§××•×ª ××• ×©×œ×— ×’×•×© ××—×“
        if len(sections) == 1 and len(sections[0]) > 500:
            print("âš ï¸ Gemini didn't split paragraphs, using smart Python fallback", file=sys.stderr)

            # ×—×œ×•×§×” ×—×›××” ×©×œ Python ×œ×¤×¡×§××•×ª ×©×œ 5-10 ×©×•×¨×•×ª
            all_text = sections[0]

            # ×ª×™×§×•×Ÿ ×¢×‘×¨×™ ×ª×—×™×œ×”
            if is_rtl:
                all_text = fix_hebrew_punctuation(all_text)

            # ×—×œ×•×§×” ×œ×¤×¡×§××•×ª ×œ×¤×™ ××©×¤×˜×™×
            sentences = re.split(r'(?<=[.!?:])\s+', all_text)
            current_para = ""
            sentence_count = 0
            para_num = 0

            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue

                current_para += sentence + " "
                sentence_count += 1

                # ×™×¦×™×¨×ª ×¤×¡×§×”: 4-7 ××©×¤×˜×™× (×‘×¢×¨×š 5-10 ×©×•×¨×•×ª)
                if sentence_count >= 4 and len(current_para) >= 400:
                    # ×‘×“×•×§ ××™×¨×›××•×ª ×–×•×’×™×•×ª
                    quote_count = current_para.count('"')
                    if quote_count % 2 == 0:  # ×–×•×’×™ ××™×¨×›××•×ª
                        para_text = current_para.strip()
                        if para_text:
                            paragraph = doc.add_paragraph()
                            run = paragraph.add_run(para_text)
                            run.font.name = 'David'
                            run.font.size = Pt(14)

                            if is_rtl:
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                                set_rtl_paragraph(paragraph, language)
                            else:
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                            para_num += 1
                            print(f"Added smart paragraph {para_num}: {para_text[:50]}...", file=sys.stderr)

                        current_para = ""
                        sentence_count = 0

            # ×¤×¡×§×” ××—×¨×•× ×”
            if current_para.strip():
                para_text = current_para.strip()
                paragraph = doc.add_paragraph()
                run = paragraph.add_run(para_text)
                run.font.name = 'David'
                run.font.size = Pt(14)

                if is_rtl:
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                    set_rtl_paragraph(paragraph, language)
                else:
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                para_num += 1
                print(f"Added final smart paragraph {para_num}: {para_text[:50]}...", file=sys.stderr)

        else:
            # ×’××™× ×™ ×—×™×œ×§ × ×›×•×Ÿ - ×”×©×ª××© ×‘×¤×¡×§××•×ª ×©×œ×•
            print(f"âœ… Using Gemini's {len(sections)} paragraphs", file=sys.stderr)

            for i, section in enumerate(sections):
                lines = [line.strip() for line in section.split('\n') if line.strip()]
                combined_text = ' '.join(lines).strip()

                # ×ª×™×§×•×Ÿ ×¢×‘×¨×™
                if is_rtl:
                    combined_text = fix_hebrew_punctuation(combined_text)

                # ×‘×“×™×§×” ×× ×¦×¨×™×š × ×§×•×“×” ×‘×¡×•×£
                if combined_text and not combined_text[-1] in '.!?:':
                    combined_text += '.'

                paragraph = doc.add_paragraph()
                run = paragraph.add_run(combined_text)
                run.font.name = 'David'
                run.font.size = Pt(14)

                if is_rtl:
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                    set_rtl_paragraph(paragraph, language)
                else:
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT

                print(f"Added Gemini paragraph {i+1}: {combined_text[:50]}...", file=sys.stderr)

        doc.save(output_path)
        print(f"Basic document saved successfully: {output_path}", file=sys.stderr)
        return True

    except Exception as e:
        print(f"Error in basic document creation process: {str(e)}", file=sys.stderr)
        return create_html_fallback(transcription, title, output_path)

def create_html_fallback(transcription, title, output_path):
    """
    ×™×¦×™×¨×ª ×§×•×‘×¥ HTML ×›-fallback ×× Python-docx ×œ× ×–××™×Ÿ
    """
    try:
        html_content = f'''<!DOCTYPE html>
<html dir="rtl" lang="he">
<head>
    <meta charset="UTF-8">
    <title>{title}</title>
    <style>
        body {{
            font-family: David, Arial, sans-serif;
            direction: rtl;
            text-align: right;
            margin: 40px;
            line-height: 1.6;
        }}
        h1 {{
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 20px;
        }}
        p {{
            margin-bottom: 16px;
            font-size: 12px;
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
'''

        # ×¢×™×‘×•×“ ×”×˜×§×¡×˜ ×œ×¤×¡×§××•×ª
        clean_text = transcription.replace('\r\n', '\n').replace('\n\n\n', '\n\n').strip()
        sections = [section.strip() for section in clean_text.split('\n\n') if section.strip()]

        for section in sections:
            lines = [line.strip() for line in section.split('\n') if line.strip()]
            combined_text = ' '.join(lines).strip()

            if combined_text and not combined_text[-1] in '.!?:':
                combined_text += '.'

            # ×”×™×× ×¢×•×ª ×-HTML injection
            safe_text = combined_text.replace('<', '&lt;').replace('>', '&gt;').replace('&', '&amp;')
            html_content += f'    <p>{safe_text}</p>\n'

        html_content += '''
</body>
</html>'''

        # ×©××™×¨×” ×›×§×•×‘×¥ HTML ×‘××§×•× docx
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"Created HTML fallback at: {output_path}", file=sys.stderr)
        return True

    except Exception as e:
        print(f"HTML fallback failed: {str(e)}")
        return False

def escape_xml(text):
    """
    ××—×œ×™×£ ×ª×•×•×™× ××™×•×—×“×™× ×‘-XML
    """
    return (text.replace('&', '&amp;')
               .replace('<', '&lt;')
               .replace('>', '&gt;')
               .replace('"', '&quot;')
               .replace("'", '&#39;'))

def fix_hebrew_punctuation(text):
    """
    ×¤×ª×¨×•×Ÿ ×¡×•×¤×™ ×•××“×•×™×§ ×œ×›×œ ×‘×¢×™×•×ª ×”×˜×§×¡×˜ ×”×¢×‘×¨×™
    ××‘×•×¡×¡ ×¢×œ ×”×‘×¢×™×•×ª ×”×¡×¤×¦×™×¤×™×•×ª ×©×”××©×ª××© ×“×™×•×•×— ×¢×œ×™×”×Ÿ
    """
    import re

    print('ğŸ¯ Starting ULTIMATE Hebrew processing...', file=sys.stderr)

    # ×©×œ×‘ 1: × ×™×§×•×™ ×‘×¡×™×¡×™ - ×”×¡×¨×ª ×§×•×•×™× × ×˜×•×™×™× ×•×’×¨×©×™×™× ××•×–×¨×™×
    text = text.replace('\\', '')
    text = re.sub(r'["\u0022\u201C\u201D]', '"', text)

    # ×ª×™×§×•×Ÿ ×’×¨×©×™×™× ×›×¤×•×œ×™× ×•××©×•×œ×©×™× ×‘×”×ª×—×œ×” ×©×œ ××™×œ×™×
    text = re.sub(r'""([×-×ª])', r'"\1', text)  # ""××™×œ×” -> "××™×œ×”
    text = re.sub(r'"""([×-×ª])', r'"\1', text)  # """××™×œ×” -> "××™×œ×”
    text = re.sub(r'""""([×-×ª])', r'"\1', text)  # """"××™×œ×” -> "××™×œ×”

    # ×ª×™×§×•× ×™× ×™×©×™×¨×™× ×•××’×¨×¡×™×‘×™×™× ×œ×‘×¢×™×•×ª ×¡×¤×¦×™×¤×™×•×ª
    text = text.replace('""×™×—×™×™× ×•', '"×™×—×™×™× ×•')
    text = text.replace('"""×™×—×™×™× ×•', '"×™×—×™×™× ×•')
    text = text.replace('""""×™×—×™×™× ×•', '"×™×—×™×™× ×•')

    # ×ª×™×§×•×Ÿ ×—×–×œ ×‘×›×œ ×”×¦×•×¨×•×ª ×”××¤×©×¨×™×•×ª
    text = text.replace('×—×–×œ ××‘×™××™×', '×—×–"×œ ××‘×™××™×')
    text = text.replace('×—×–×œ', '×—×–"×œ')
    text = text.replace('×—×– ×œ', '×—×–"×œ')

    # ×ª×™×§×•×Ÿ ×–×œ ×‘×›×œ ×”×¦×•×¨×•×ª ×”××¤×©×¨×™×•×ª
    text = text.replace('×–×œ ×‘×¢× ×™×Ÿ', '×–"×œ ×‘×¢× ×™×Ÿ')
    text = text.replace('×–×œ ××‘×™××™×', '×–"×œ ××‘×™××™×')
    text = text.replace(' ×–×œ ', ' ×–"×œ ')
    text = text.replace(' ×–×œ.', ' ×–"×œ.')
    text = text.replace(' ×–×œ,', ' ×–"×œ,')
    text = text.replace('×–×œ ', '×–"×œ ')
    text = text.replace(' ×–×œ', ' ×–"×œ')

    # ×›×¤×œ ×”×ª×™×§×•× ×™× ×›×“×™ ×œ×•×•×“× ×©×”× ×¢×•×‘×“×™×
    text = text.replace('×—×–×œ', '×—×–"×œ')  # ×©×•×‘
    text = re.sub(r'\b×–×œ\b', '×–"×œ', text)  # ×ª×™×§×•×Ÿ ×¢× regex
    text = re.sub(r'\b×—×–×œ\b', '×—×–"×œ', text)  # ×ª×™×§×•×Ÿ ×¢× regex

    print('Phase 1: Basic cleanup completed', file=sys.stderr)

    # ×©×œ×‘ 2: ×ª×™×§×•×Ÿ ×§×™×¦×•×¨×™× ×¢×‘×¨×™×™× - ×™×©×™×¨ ×•×—×“-××©××¢×™
    # ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×“×•×’×××•×ª ×”×¡×¤×¦×™×¤×™×•×ª ××”××©×ª××©
    abbreviation_fixes = [
        ('×©×œ×™×˜ "×', '×©×œ×™×˜"×'),
        ('×©×œ×™×˜ ×', '×©×œ×™×˜"×'),
        ('×¨×© ×™', '×¨×©"×™'),
        ('×¨×© "×™', '×¨×©"×™'),
        ('×—×– "×œ', '×—×–"×œ'),
        ('×—×– ×œ', '×—×–"×œ'),
        ('×œ "×˜', '×œ"×˜'),
        ('×œ ×˜', '×œ"×˜'),
        ('×œ×˜×¢××•×“', '×œ"×˜ ×¢××•×“'),  # ×ª×™×§×•×Ÿ ×¡×¤×¦×™×¤×™ ×œ××™×œ×™× ×“×‘×•×§×•×ª
        ('×”×¨××‘ "×Ÿ', '×”×¨××‘"×Ÿ'),
        ('×”×¨××‘ ×Ÿ', '×”×¨××‘"×Ÿ'),
        ('×¨××‘ "×', '×¨××‘"×'),
        ('×¨××‘ ×', '×¨××‘"×'),
        ('×”××¨ ×™ ×– ×œ', '×”××¨"×™ ×–"×œ'),
        ('×”××¨"×™ "×–"×œ', '×”××¨"×™ ×–"×œ'),
        ('×”××¨×™ ×–×œ', '×”××¨"×™ ×–"×œ'),  # ×ª×™×§×•×Ÿ ×–×œ ×œ×–"×œ
        ('×–×œ ×‘×¢× ×™×Ÿ', '×–"×œ ×‘×¢× ×™×Ÿ'),  # ×ª×™×§×•×Ÿ ×–×œ ×œ×–"×œ
        ('×—×–×œ', '×—×–"×œ'),  # ×ª×™×§×•×Ÿ ×—×–×œ ×œ×—×–"×œ
        (' ×–×œ ', ' ×–"×œ '),  # ×ª×™×§×•×Ÿ ×–×œ ×‘×›×œ ××§×•×
        ('×–×œ ××‘×™××™×', '×–"×œ ××‘×™××™×'),  # ×ª×™×§×•×Ÿ ×–×œ ×‘×”×§×©×¨ ×¡×¤×¦×™×¤×™
        ('×–×œ ×‘×¢× ×™×Ÿ', '×–"×œ ×‘×¢× ×™×Ÿ'),  # ×ª×™×§×•×Ÿ ×–×œ ×‘×”×§×©×¨ ×¡×¤×¦×™×¤×™
        ('×—×–×œ ××‘×™××™×', '×—×–"×œ ××‘×™××™×'),  # ×ª×™×§×•×Ÿ ×—×–×œ ×‘×”×§×©×¨ ×¡×¤×¦×™×¤×™
        ('×©×• "×¢', '×©×•"×¢'),
        ('×©×• ×¢', '×©×•"×¢'),
        ('×“ "×”', '×“"×”'),
        ('×‘ "×”', '×‘"×”')
    ]

    for wrong, correct in abbreviation_fixes:
        text = text.replace(wrong, correct)

    print('Phase 2: Fixed Hebrew abbreviations', file=sys.stderr)

    # ×©×œ×‘ 3: ×”×¡×¨×ª ×’×¨×©×™×™× ××™×•×ª×¨×™× ×××™×œ×™× ×‘×•×“×“×•×ª
    # ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×‘×¢×™×•×ª ×”×¡×¤×¦×™×¤×™×•×ª ×©×”××©×ª××© ×“×™×•×•×— ×¢×œ×™×”×Ÿ
    unwanted_quoted_words = [
        '×˜×¢××•×“', '×¢××•×“', '×‘\'', '×’×•×™', '×ª×¨××”', '××™×š', '×”×¨××‘×Ÿ', '×¦×¨×™×›×”',
        '××ª', '×¨×•×¦×”', '×œ×¢×©×•×ª', '××©×”×•', '×©××¢', '×™×©×¨××œ', '×‘×‘×•×§×¨',
        '×›×ª×•×‘', '×‘×¤×¡×•×§', '×ª×”×™×”',
        '×‘×¢× ×™×Ÿ', '××‘×™××™×', '×–', '×œ'
    ]

    for word in unwanted_quoted_words:
        # ×”×¡×¨ ×’×¨×©×™×™× ××”×ª×—×œ×” ×•×”×¡×•×£
        text = text.replace(f'"{word}"', word)
        text = text.replace(f'"{word}', word)
        text = text.replace(f'{word}"', word)

    print('Phase 3: Removed unwanted quotes from words', file=sys.stderr)

    # ×©×œ×‘ 4: ×ª×™×§×•×Ÿ ××™×œ×™× ×¦××•×“×•×ª
    merged_word_fixes = [
        ('×××¨×©×œ×•×', '×××¨ ×©×œ×•×'),
        ('×–×”×“×‘×¨', '×–×” ×“×‘×¨'),
        ('×—×©×•×‘×××•×“', '×—×©×•×‘ ×××•×“'),
        ('×™×•×“×¢×ª×¨××•', '×™×•×“×¢×ª ×¨××•'),
        ('×©××œ×ª×™××•×ª×•', '×©××œ×ª×™ ××•×ª×•'),
        ('××•××¨×ª×× ×™', '××•××¨×ª ×× ×™'),
        ('× ×××¡.×××™×¤×”', '× ×××¡. ×××™×¤×”'),
        ('×”×”×¦×œ×—×”.×“×•×“', '×”×”×¦×œ×—×”. ×“×•×“'),
        ('× ×¤×œ××™×.×‘×¢×–×¨×ª', '× ×¤×œ××™×. ×‘×¢×–×¨×ª'),
        ('×–×”.×›×©××“×', '×–×”. ×›×©××“×')
    ]

    for wrong, correct in merged_word_fixes:
        text = text.replace(wrong, correct)

    print('Phase 4: Fixed merged words', file=sys.stderr)

    # ×©×œ×‘ 5: ×ª×™×§×•×Ÿ ×¤×™×¡×•×§ ×•×¨×•×•×—×™×
    # × ×§×•×“×” ×¦××•×“×” ×œ××™×œ×”
    text = re.sub(r'([×-×ª])\.([×-×ª])', r'\1. \2', text)
    # ×¨×•×•×— ××—×¨×™ ×¤×™×¡×•×§
    text = re.sub(r'([.,!?:;])([×-×ª])', r'\1 \2', text)
    # ×”×¡×¨ ×¨×•×•×— ×œ×¤× ×™ ×¤×™×¡×•×§
    text = re.sub(r'\s+([.,!?:;])', r'\1', text)
    # ×¨×•×•×—×™× ×›×¤×•×œ×™×
    text = re.sub(r'\s{2,}', ' ', text)

    print('Phase 5: Fixed punctuation and spacing', file=sys.stderr)

    # ×©×œ×‘ 6: ×ª×™×§×•× ×™× ×¡×¤×¦×™×¤×™×™× ×œ×‘×¢×™×•×ª ××•×¨×›×‘×•×ª
    specific_fixes = [
        ('×‘×“×£ ×œ ×˜×¢××•×“ ×‘\'', '×‘×“×£ ×œ"×˜ ×¢××•×“ ×‘\''),
        ('×©×•××œ ×”×¨××‘×Ÿ', '×©×•××œ ×”×¨××‘"×Ÿ'),
        ('". "×‘×¨×•×š', '"×‘×¨×•×š'),
        ('"×‘×¨×•×š "×ª×”×™×”', '"×‘×¨×•×š ×ª×”×™×”'),
        ('"×ª×¨××” "××™×š', '"×ª×¨××” ××™×š'),
        ('×©×•××œ "×”×¨××‘"×Ÿ', '×©×•××œ ×”×¨××‘"×Ÿ'),
        ('××•××¨ "×¨\'', '××•××¨ ×¨\''),
        ('×”× ×§×¨××• "×©××¢ "×™×©×¨××œ"', '×”× ×§×¨××• "×©××¢ ×™×©×¨××œ"'),
        ('×œ×”×•×“×•×ª ×œ×š ×•×œ×™×™×—×“×š"', '"×œ×”×•×“×•×ª ×œ×š ×•×œ×™×™×—×“×š"'),
        ('×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"', '"×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"'),  # ×”×•×¡×£ ×’×¨×©×™×™× ×‘×”×ª×—×œ×” ×œ×¦×™×˜×•×˜ ×¤×¡×•×§
        ('×™×—×™×™× ×• ××™×•××™×™× ×›×ª×•×‘', '"×™×—×™×™× ×• ××™×•××™×™×" ×›×ª×•×‘'),  # ×”×•×¡×£ ×’×¨×©×™×™× ×œ×¤×¡×•×§
        ('×™×—×™×™× ×• ××™×•××™×™×"', '"×™×—×™×™× ×• ××™×•××™×™×"'),  # ×ª×§×Ÿ ×× ×™×© ×¨×§ ×’×¨×©×™×™× ×‘×¡×•×£
        ('""×™×—×™×™× ×•', '"×™×—×™×™× ×•'),  # ×ª×§×Ÿ ×’×¨×©×™×™× ×›×¤×•×œ×™× ×‘×”×ª×—×œ×”
        ('"""×™×—×™×™× ×•', '"×™×—×™×™× ×•'),  # ×ª×§×Ÿ ×’×¨×©×™×™× ××©×•×œ×©×™×
        ('×‘×¨×•×š ×ª×”×™×” ××›×œ ×”×¢××™×"', '"×‘×¨×•×š ×ª×”×™×” ××›×œ ×”×¢××™×"'),  # ×”×•×¡×£ ×’×¨×©×™×™× ×‘×”×ª×—×œ×ª ×¤×¡×•×§
        ('×××¨ ×©×œ×•×. ×•×”×œ×š ×œ×‘×™×ª×•', '×××¨ ×©×œ×•× ×•×”×œ×š ×œ×‘×™×ª×•')  # ×”×¡×¨ × ×§×•×“×” ××™×•×ª×¨×ª
    ]

    for wrong, correct in specific_fixes:
        text = text.replace(wrong, correct)

    print('Phase 6: Applied specific fixes', file=sys.stderr)

    # ×©×œ×‘ 7: ×ª×™×§×•× ×™× ×¡×•×¤×™×™× ×•×—×™×•× ×™×™× - ×—×•×‘×” ×©×™×¢×‘×“×•!
    print('Phase 7: Final critical fixes', file=sys.stderr)

    # ×ª×™×§×•× ×™× ××—×¨×•× ×™× ×•×—×™×•× ×™×™×
    text = text.replace('""×™×—×™×™× ×•', '"×™×—×™×™× ×•')
    text = text.replace('"""×™×—×™×™× ×•', '"×™×—×™×™× ×•')
    text = text.replace('""""×™×—×™×™× ×•', '"×™×—×™×™× ×•')

    # ×ª×™×§×•×Ÿ ×—×–×œ ×‘×›×œ ××§×•×
    text = text.replace('×—×–×œ', '×—×–"×œ')
    text = text.replace('×—×– ×œ', '×—×–"×œ')

    # ×ª×™×§×•×Ÿ ×–×œ ×‘×›×œ ××§×•×
    text = re.sub(r'\b×–×œ\b', '×–"×œ', text)
    text = text.replace(' ×–×œ ', ' ×–"×œ ')
    text = text.replace(' ×–×œ.', ' ×–"×œ.')
    text = text.replace(' ×–×œ,', ' ×–"×œ,')
    text = text.replace('×–×œ ×‘×¢× ×™×Ÿ', '×–"×œ ×‘×¢× ×™×Ÿ')

    # ×¢×•×“ ×¡×™×‘×•×‘ ×ª×™×§×•× ×™× ×œ××§×¨×” ×©×œ× ×¢×‘×“
    text = text.replace('×—×–×œ', '×—×–"×œ')
    text = text.replace('×–×œ ×‘×¢× ×™×Ÿ', '×–"×œ ×‘×¢× ×™×Ÿ')
    text = text.replace('×–×œ ××‘×™××™×', '×–"×œ ××‘×™××™×')

    # ×ª×™×§×•×Ÿ ×¤×¡×•×§×™× ×©×—×¡×¨×™× ×’×¨×©×™×™× ×‘×”×ª×—×œ×”
    text = text.replace('×‘×§×¨×‘ ×”××¨×¥"', '"×‘×§×¨×‘ ×”××¨×¥"')
    text = text.replace('×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"', '"×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"')

    # ×”×¡×¨×ª ×’×¨×©×™×™× ××™×•×ª×¨×™× ×××™×œ×™× ×‘×•×“×“×•×ª - ××’×¨×¡×™×‘×™
    problematic_quoted_words = [
        '××ª', '×¨×•×¦×”', '×œ×¢×©×•×ª', '××©×”×•', '×¦×¨×™×›×”', '×’×•×™', '×ª×¨××”', '××™×š',
        '×©××¢', '×™×©×¨××œ', '×‘×‘×•×§×¨', '×”×¨××‘×Ÿ', '×¨\'', '×–×œ××Ÿ', '××•××¨', '×œ×•',
        '×“×‘×¨', '×©× ×™', '×¢××•×“', '×‘\'', '×˜×¢××•×“', '×›×ª×•×‘', '×‘×¤×¡×•×§'
    ]

    for word in problematic_quoted_words:
        # ×”×¡×¨ ×’×¨×©×™×™× ××™×•×ª×¨×™× ××¡×‘×™×‘ ×œ××™×œ×™× ×‘×•×“×“×•×ª
        text = re.sub(rf'\s+"{word}"\s+', f' {word} ', text)  # ×¨×•×•×— ×œ×¤× ×™ ×•××—×¨×™
        text = re.sub(rf'"{word}"\s+', f'{word} ', text)      # ×”×ª×—×œ×ª ××©×¤×˜
        text = re.sub(rf'\s+"{word}"', f' {word}', text)      # ×¡×•×£ ××©×¤×˜
        text = re.sub(rf'"{word}"([.,!?])', rf'{word}\1', text)  # ×œ×¤× ×™ ×¤×™×¡×•×§

    # ×”×¡×¨×ª ×’×¨×©×™×™× ××™×•×ª×¨×™× ×‘××§×•××•×ª ×›×œ×œ×™×™×
    text = re.sub(r'(?<=[×-×ª])\s+"([×-×ª]{1,6})"\s+(?=[×-×ª])', r' \1 ', text)  # ××™×œ×” ×‘×××¦×¢ ××©×¤×˜

    # ×ª×™×§×•× ×™× ×™×©×™×¨×™× ×œ×‘×¢×™×•×ª ×¡×¤×¦×™×¤×™×•×ª ×©×œ ×’×¨×©×™×™× ××™×•×ª×¨×™×
    text = text.replace('"×“×‘×¨ "×©× ×™', '×“×‘×¨ ×©× ×™')
    text = text.replace('"××•××¨ "×œ×•', '××•××¨ ×œ×•')
    text = text.replace('"××ª "×¦×¨×™×›×”', '××ª ×¦×¨×™×›×”')
    text = text.replace('"××ª×” "×¨×•×¦×”', '××ª×” ×¨×•×¦×”')
    text = text.replace('"×œ×¢×©×•×ª "××©×”×•', '×œ×¢×©×•×ª ××©×”×•')
    text = text.replace('"×ª×¨××” "××™×š', '×ª×¨××” ××™×š')
    text = text.replace('×›×œ "×’×•×™', '×›×œ ×’×•×™')
    text = text.replace('×”×™×•× "×‘×‘×•×§×¨', '×”×™×•× ×‘×‘×•×§×¨')

    # ×ª×™×§×•×Ÿ ×›×œ×œ×™ ×œ×’×¨×©×™×™× ××™×•×ª×¨×™× ×‘××™×œ×™× ×‘×•×“×“×•×ª
    text = re.sub(r'"([×-×ª]{1,8})"\s+(?![×-×ª]*")', r'\1 ', text)  # "××™×œ×”" ××™×œ×” -> ××™×œ×” ××™×œ×”
    text = re.sub(r'\s+"([×-×ª]{1,8})"\s+', r' \1 ', text)        # ××™×œ×” "××™×œ×”" ××™×œ×” -> ××™×œ×” ××™×œ×” ××™×œ×”

    # ×ª×™×§×•× ×™× ×¡×¤×¦×™×¤×™×™× × ×•×¡×¤×™× ×œ×‘×¢×™×•×ª ×—×“×©×•×ª
    text = text.replace('×”"××•×”×‘ ×™×©×¨××œ', '×”"××•×”×‘ ×™×©×¨××œ"')  # ×”×•×¡×£ ×’×¨×©×™×™× ××—×¨×™ ×™×©×¨××œ
    text = text.replace('×ª×¨××” ××™×š × ×¨××” ×™×”×•×“×™, ×ª×¨××” ××™×š ××ª ×”×“×‘×¨×™× ×”××œ×”"', '"×ª×¨××” ××™×š × ×¨××” ×™×”×•×“×™, ×ª×¨××” ××™×š ××ª ×”×“×‘×¨×™× ×”××œ×”"')  # ×”×•×¡×£ ×’×¨×©×™×™× ×‘×”×ª×—×œ×”
    text = text.replace('"×œ×¢×©×•×ª× "×‘×§×¨×‘ ×”××¨×¥"', '"×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"')  # ×”×¡×¨ ×’×¨×©×™×™× ××™×•×ª×¨×™×
    text = text.replace('×œ×¢×©×•×ª× ""×‘×§×¨×‘ ×”××¨×¥"', '×œ×¢×©×•×ª× ×‘×§×¨×‘ ×”××¨×¥"')  # ×”×¡×¨ ×’×¨×©×™×™× ×›×¤×•×œ×™×
    text = text.replace('×©××™× ×• ×¢×•××“ ×‘×“×™×‘×•×¨×•."', '×©××™× ×• ×¢×•××“ ×‘×“×™×‘×•×¨×•".')  # ×”×–×– × ×§×•×“×” ××—×¨×™ ×’×¨×©×™×™×
    text = text.replace('×©××™× ×• ×¢×•××“ ×‘×“×™×‘×•×¨×•"', '"×©××™× ×• ×¢×•××“ ×‘×“×™×‘×•×¨×•"')  # ×”×•×¡×£ ×’×¨×©×™×™× ×¤×•×ª×—×™×
    text = text.replace('××–×œ×˜×•×‘', '××–×œ ×˜×•×‘')  # ×”×¤×¨×“ ××™×œ×™× ×¦××•×“×•×ª
    text = text.replace('×œ××¢×Ÿ ×ª×—×™×•×Ÿ", ××•××¨ ×œ××¢×Ÿ ×ª×—×™×•×Ÿ"', '"×œ××¢×Ÿ ×ª×—×™×•×Ÿ", ××•××¨ "×œ××¢×Ÿ ×ª×—×™×•×Ÿ"')  # ×”×•×¡×£ ×’×¨×©×™×™× ×‘×”×ª×—×œ×”

    # ×ª×™×§×•×Ÿ × ×•×¡×£ ×œ×’×¨×©×™×™× ×›×¤×•×œ×™× ×œ×¤× ×™ ××™×œ×™×
    text = re.sub(r'""([×-×ª])', r'"\1', text)  # ""××™×œ×” -> "××™×œ×”
    text = re.sub(r'"""([×-×ª])', r'"\1', text)  # """××™×œ×” -> "××™×œ×”

    # ×ª×™×§×•×Ÿ ×¤×¡×§××•×ª ×©× ×§×˜×¢×•×ª ×‘×××¦×¢ ××©×¤×˜
    text = text.replace('×œ×¢×ª×™×“ ×œ×‘×•×.\n×•×¡×•×›×” ×©××”."', '×œ×¢×ª×™×“ ×œ×‘×•×. ×•×¡×•×›×” ×©××”."')  # ×—×‘×¨ ××©×¤×˜ ×©× ×§×˜×¢

    # ×ª×™×§×•×Ÿ × ×•×¡×£ ×œ×’×¨×©×™×™× ××—×¨×™ × ×§×•×“×” - ××’×¨×¡×™×‘×™ ×™×•×ª×¨
    text = re.sub(r'([×-×ª])\.\"', r'\1".', text)  # ××™×œ×”." -> ××™×œ×”".
    text = re.sub(r'([×-×ª])\."', r'\1".', text)   # ××™×œ×”." -> ××™×œ×”".

    # ×ª×™×§×•× ×™× ×¡×¤×¦×™×¤×™×™× ×œ×‘×¢×™×•×ª ×©×“×•×•×—×•
    text = text.replace('×’×Ÿ ×¢×“×Ÿ".××”', '×’×Ÿ ×¢×“×Ÿ". ××”')  # ×”×•×¡×£ ×¨×•×•×— ××—×¨×™ × ×§×•×“×”
    text = text.replace('×™×•×©×¨".×•×”×™×”', '×™×•×©×¨". ×•×”×™×”')  # ×”×•×¡×£ ×¨×•×•×— ××—×¨×™ × ×§×•×“×”

    # ×ª×™×§×•×Ÿ ×›×œ×œ×™ ×œ× ×§×•×“×”+×’×¨×©×™×™×+××™×œ×” ×¦××•×“×”
    text = re.sub(r'([×-×ª])\."([×-×ª])', r'\1". \2', text)  # ××™×œ×”."××™×œ×” -> ××™×œ×”". ××™×œ×”
    text = re.sub(r'([×-×ª])\"\.([×-×ª])', r'\1". \2', text)  # ××™×œ×”".××™×œ×” -> ××™×œ×”". ××™×œ×”

    # × ×™×§×•×™ ×¡×•×¤×™
    text = text.strip()

    print('âœ… ULTIMATE Hebrew processing completed!', file=sys.stderr)
    return text

def set_rtl_paragraph(paragraph, language='Hebrew'):
    """
    ××’×“×™×¨ ×¤×¡×§×” ×›-RTL (×™××™×Ÿ ×œ×©×××œ) ×¢× ×©×¤×” ××ª××™××” - ×’×¨×¡×” ××©×•×¤×¨×ª
    """
    try:
        from docx.oxml.ns import qn
        from docx.oxml import OxmlElement

        # ×§×‘×œ×ª ×§×•×“ ×”×©×¤×” ×”××ª××™×
        lang_code = get_word_language_code(language)

        # ×”×•×¡×¤×ª ×”×’×“×¨×ª RTL ×œ-XML ×©×œ ×”×¤×¡×§×”
        p = paragraph._element
        pPr = p.get_or_add_pPr()

        # ×”×•×¡×¤×ª bidi element
        bidi = OxmlElement('w:bidi')
        bidi.set(qn('w:val'), '1')
        pPr.append(bidi)

        # ×”×•×¡×¤×ª textDirection element
        textDirection = OxmlElement('w:textDirection')
        textDirection.set(qn('w:val'), 'rl')
        pPr.append(textDirection)

        # ×”×•×¡×¤×ª ×™×™×©×•×¨ ×™××™×Ÿ ×—×–×§
        jc = OxmlElement('w:jc')
        jc.set(qn('w:val'), 'right')
        pPr.append(jc)

        # ×”×•×¡×¤×ª ×”×’×“×¨×ª ×©×¤×” ×œ-paragraph properties
        rPr_para = OxmlElement('w:rPr')
        lang_para = OxmlElement('w:lang')
        lang_para.set(qn('w:val'), lang_code)
        lang_para.set(qn('w:bidi'), lang_code)
        rPr_para.append(lang_para)
        rtl_para = OxmlElement('w:rtl')
        rPr_para.append(rtl_para)
        pPr.append(rPr_para)

        # ×”×•×¡×¤×ª ×”×’×“×¨×ª ×©×¤×” ×œ×›×œ ×”-runs ×‘×¤×¡×§×”
        for run in paragraph.runs:
            r = run._element
            rPr = r.get_or_add_rPr()

            # ×”×•×¡×¤×ª ×©×¤×”
            lang = OxmlElement('w:lang')
            lang.set(qn('w:val'), lang_code)
            lang.set(qn('w:bidi'), lang_code)
            rPr.append(lang)

            # ×”×•×¡×¤×ª RTL marker
            rtl = OxmlElement('w:rtl')
            rPr.append(rtl)

        print(f"RTL and {lang_code} language settings applied to paragraph", file=sys.stderr)

    except Exception as e:
        print(f"Warning: Cannot set RTL: {str(e)}", file=sys.stderr)

def main():
    """
    ×¤×•× ×§×¦×™×” ×¨××©×™×ª ×”××§×‘×œ×ª ×¤×¨××˜×¨×™× ×-Node.js
    """
    try:
        print("Python script started", file=sys.stderr)
        print(f"Python version: {sys.version}", file=sys.stderr)
        print(f"Arguments: {sys.argv}", file=sys.stderr)

        if len(sys.argv) != 2:
            print("Usage: python generate_word_doc.py '<json_file_path>'")
            sys.exit(1)

        # ×‘×“×™×§×ª python-docx - ×œ× ×‘×”×›×¨×— × ×“×¨×©×ª ×›×™ ×™×© ×œ× ×• HTML fallback
        try:
            import docx
            print(f"python-docx version: {docx.__version__}", file=sys.stderr)
            print("python-docx is available", file=sys.stderr)
        except ImportError as e:
            print(f"python-docx import error: {str(e)}", file=sys.stderr)
            print("Will use HTML fallback instead", file=sys.stderr)

        # ×§×¨×™××ª ×”× ×ª×•× ×™× ××§×•×‘×¥ JSON
        json_file_path = sys.argv[1]
        print(f"Reading JSON data from file: {json_file_path}", file=sys.stderr)

        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                json_data = f.read()
            print(f"Loaded JSON data length: {len(json_data)}", file=sys.stderr)
        except Exception as e:
            print(f"ERROR: Failed to read JSON file: {str(e)}", file=sys.stderr)
            print(json.dumps({"success": False, "error": f"Failed to read JSON file: {str(e)}"}))
            sys.exit(1)

        data = json.loads(json_data)
        print(f"Parsed data keys: {list(data.keys())}", file=sys.stderr)

        transcription = data.get('transcription', '')
        title = data.get('title', '×ª××œ×•×œ')
        output_path = data.get('output_path', 'output.docx')
        language = data.get('language', 'Hebrew')  # ×‘×¨×™×¨×ª ××—×“×œ: ×¢×‘×¨×™×ª

        print(f"Creating document: {title} -> {output_path}", file=sys.stderr)
        print(f"Transcription type: {type(transcription)}", file=sys.stderr)
        print(f"Transcription length: {len(str(transcription))}", file=sys.stderr)
        print(f"Transcription preview: {str(transcription)[:100]}...", file=sys.stderr)

        # Validation ×©×œ ×”×˜×§×¡×˜
        if not transcription or not isinstance(transcription, str):
            error_msg = f"Invalid transcription data: type={type(transcription)}, value={str(transcription)[:200]}"
            print(f"ERROR: {error_msg}", file=sys.stderr)
            print(json.dumps({"success": False, "error": error_msg}))
            sys.exit(1)

        # Allow short transcriptions - only reject completely empty ones
        if len(transcription.strip()) == 0:
            error_msg = f"Transcription is empty: '{transcription}'"
            print(f"ERROR: {error_msg}", file=sys.stderr)
            print(json.dumps({"success": False, "error": error_msg}))
            sys.exit(1)

        # ×™×¦×™×¨×ª ×”××¡××š
        success = create_hebrew_word_document(transcription, title, output_path, language)

        if success:
            print(json.dumps({"success": True, "file_path": output_path}))
        else:
            print(json.dumps({"success": False, "error": "Failed to create document"}))

    except Exception as e:
        print(f"Exception in main: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        print(json.dumps({"success": False, "error": str(e)}))
        sys.exit(1)

if __name__ == "__main__":
    main()
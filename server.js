const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const nodemailer = require('nodemailer');
const { Document, Packer, Paragraph, TextRun, AlignmentType } = require('docx');
const cors = require('cors');
const { spawn } = require('child_process'); // ğŸ”¥ NEW: For FFmpeg
const JSZip = require('jszip'); // ğŸ”¥ NEW: For Word templates
// const Imap = require('imap'); // Disabled - not using email transcription service
require('dotenv').config();

// ×¤×•× ×§×¦×™×” ×œ×”×¡×¨×ª ×—×–×¨×•×ª ×©×œ ×‘×™×˜×•×™×™×/××©×¤×˜×™× ×©×—×•×–×¨×™× 5+ ×¤×¢××™×
function removeExtremeRepetitions(text) {
  if (!text) return text;

  // ×”×¡×¨ ×—×–×¨×•×ª ×©×œ ×‘×™×˜×•×™×™× (2-15 ××™×œ×™×) ×©×—×•×–×¨×™× 5+ ×¤×¢××™×
  let cleaned = text;

  for (let wordCount = 2; wordCount <= 15; wordCount++) {
    const pattern = new RegExp(`((?:\\S+\\s+){${wordCount-1}}\\S+)(?:\\s+\\1){4,}`, 'gi');
    cleaned = cleaned.replace(pattern, '$1');
  }

  return cleaned;
}
const app = express();
const PORT = process.env.PORT || 3000;

// Initialize Gemini AI
let genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ×¡×¤×™×¨×ª ×§×‘×¦×™× ×œ××™×¤×•×¡ genAI ×›×œ 3 ×§×‘×¦×™×
let processedFilesCount = 0;

// Rate limiting storage
const rateLimits = {
  registration: new Map(), // IP -> { count, resetTime }
  verification: new Map(), // email -> { count, resetTime }
  login: new Map() // IP -> { count, resetTime }
};

// Rate limiting helper functions
function getRateLimitKey(type, identifier) {
  return `${type}_${identifier}`;
}

function isRateLimited(type, identifier, maxAttempts = 5, windowMinutes = 15) {
  const now = Date.now();
  const key = getRateLimitKey(type, identifier);
  const limitMap = rateLimits[type];

  if (!limitMap) return false;

  const record = limitMap.get(key);

  if (!record) {
    // First attempt
    limitMap.set(key, { count: 1, resetTime: now + (windowMinutes * 60 * 1000) });
    return false;
  }

  if (now > record.resetTime) {
    // Reset window
    limitMap.set(key, { count: 1, resetTime: now + (windowMinutes * 60 * 1000) });
    return false;
  }

  if (record.count >= maxAttempts) {
    console.log(`â›” Rate limit exceeded for ${type}:${identifier} (${record.count}/${maxAttempts})`);
    return true;
  }

  // Increment counter
  record.count++;
  return false;
}

function getClientIP(req) {
  return req.headers['x-forwarded-for'] ||
         req.connection.remoteAddress ||
         req.socket.remoteAddress ||
         (req.connection.socket ? req.connection.socket.remoteAddress : null) ||
         '127.0.0.1';
}

// Clean up old rate limit records every hour
setInterval(() => {
  const now = Date.now();
  Object.values(rateLimits).forEach(limitMap => {
    for (const [key, record] of limitMap.entries()) {
      if (now > record.resetTime) {
        limitMap.delete(key);
      }
    }
  });
  console.log('ğŸ§¹ Cleaned up old rate limit records');
}, 60 * 60 * 1000);

// Email transporter with timeout settings
const transporter = nodemailer.createTransport({
  service: 'gmail',
  auth: {
    user: process.env.EMAIL_USER,
    pass: process.env.EMAIL_PASS
  },
  connectionTimeout: 60000, // 60 seconds
  greetingTimeout: 30000, // 30 seconds
  socketTimeout: 60000 // 60 seconds
});

// IMAP configuration disabled - email transcription service not in use
// const imapConfig = {
//   user: process.env.EMAIL_USER,
//   password: process.env.EMAIL_PASS,
//   host: 'imap.gmail.com',
//   port: 993,
//   tls: true,
//   tlsOptions: {
//     rejectUnauthorized: false
//   },
//   connTimeout: 15000,
//   authTimeout: 10000
// };

// Middleware
app.use(cors());
// ğŸ”¥ Configure Express for large uploads - no limits
app.use(express.json({ limit: '1gb' })); // Large JSON limit for metadata
app.use(express.urlencoded({ limit: '1gb', extended: true })); // Large form data limit
app.use(express.static('.'));

// API Routes
// const userRoutes = require('./routes/userRoutes'); // Disabled MongoDB routes
// app.use('/api/users', userRoutes); // Disabled MongoDB routes

// Enhanced file storage with proper UTF-8 encoding
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    const uploadsDir = 'uploads';
    if (!fs.existsSync(uploadsDir)) {
      fs.mkdirSync(uploadsDir, { recursive: true });
    }
    cb(null, uploadsDir);
  },
  filename: (req, file, cb) => {
    const timestamp = Date.now();
    const extension = path.extname(file.originalname);
    
    console.log(`ğŸ“ Original filename from browser: "${file.originalname}"`);
    console.log(`ğŸ“ File encoding details:`, {
      buffer: Buffer.from(file.originalname, 'binary').toString('hex'),
      length: file.originalname.length,
      charCodes: file.originalname.split('').map(c => c.charCodeAt(0))
    });
    
    // Try to preserve original Hebrew filename
    let safeName = file.originalname;
    
    // If filename looks like it has encoding issues, try to fix
    if (safeName.includes('Ã—') || safeName.includes('Ãƒ') || safeName.includes('Ã¢')) {
      console.log('ğŸ”§ Detected encoding issues, attempting to fix...');
      try {
        // Try different encoding approaches
        const methods = [
          () => Buffer.from(safeName, 'latin1').toString('utf8'),
          () => Buffer.from(safeName, 'binary').toString('utf8'),
          () => decodeURIComponent(escape(safeName))
        ];
        
        for (const method of methods) {
          try {
            const decoded = method();
            console.log(`ğŸ”§ Trying decode method: "${decoded}"`);
            if (decoded.match(/[\u0590-\u05FF]/)) {
              safeName = decoded;
              console.log(`âœ… Successfully decoded: "${safeName}"`);
              break;
            }
          } catch (e) {
            console.log('Decode method failed:', e.message);
          }
        }
      } catch (error) {
        console.log('All decode methods failed, using original');
      }
    }
    
    // Clean invalid characters but keep Hebrew
    safeName = safeName.replace(/[<>:"/\\|?*\x00-\x1f]/g, '_');
    
    const finalName = `${timestamp}_${safeName}`;
    console.log(`ğŸ“ Final stored filename: "${finalName}"`);
    cb(null, finalName);
  }
});

const upload = multer({
  storage: storage,
  limits: {
    fileSize: 500 * 1024 * 1024, // ğŸ”¥ 500MB per file
    files: Infinity // ğŸ”¥ UNLIMITED: No limit on number of files
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = /\.(mp3|mp4|wav|m4a|mov|avi|mkv|flac|aac|ogg)$/i;
    if (allowedTypes.test(file.originalname) || file.mimetype.startsWith('audio/') || file.mimetype.startsWith('video/')) {
      cb(null, true);
    } else {
      cb(new Error('×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š'), false);
    }
  }
});

// Data persistence - Persistent Disk Configuration
const PERSISTENT_PATH = process.env.NODE_ENV === 'production' ? '/mnt/data' : __dirname;
const DATA_FILE = path.join(PERSISTENT_PATH, 'users_data.json');
const TRANSCRIPTIONS_DIR = path.join(PERSISTENT_PATH, 'transcriptions');
const BACKUPS_DIR = path.join(PERSISTENT_PATH, 'backups');

console.log(`ğŸ”§ Environment: ${process.env.NODE_ENV || 'development'}`);
console.log(`ğŸ”§ Persistent storage path: ${PERSISTENT_PATH}`);
console.log(`ğŸ”§ Data file path: ${DATA_FILE}`);
console.log(`ğŸ”§ Current working directory: ${process.cwd()}`);
console.log(`ğŸ”§ __dirname: ${__dirname}`);

// Create directories if they don't exist
function ensurePersistentDirectories() {
  try {
    if (!fs.existsSync(PERSISTENT_PATH)) {
      fs.mkdirSync(PERSISTENT_PATH, { recursive: true });
      console.log(`âœ… Created persistent directory: ${PERSISTENT_PATH}`);
    }
    if (!fs.existsSync(TRANSCRIPTIONS_DIR)) {
      fs.mkdirSync(TRANSCRIPTIONS_DIR, { recursive: true });
      console.log(`âœ… Created transcriptions directory: ${TRANSCRIPTIONS_DIR}`);
    }
    if (!fs.existsSync(BACKUPS_DIR)) {
      fs.mkdirSync(BACKUPS_DIR, { recursive: true });
      console.log(`âœ… Created backups directory: ${BACKUPS_DIR}`);
    }
  } catch (error) {
    console.error('âŒ Error creating persistent directories:', error);
  }
}

// Default users data
const defaultUsers = [
  {
    id: 1,
    name: '×× ×”×œ ×”××¢×¨×›×ª',
    email: 'timlul.h@gmail.com',
    password: 'S3cur3P@ssw0rd_Adm!n25', // ×”×¡×™×¡××” ×”×—×–×§×” ×©×§×‘×¢× ×•
    isAdmin: true,
    remainingMinutes: 1000,
    totalTranscribed: 0,
    history: [],
    transcriptionHistory: [],
    joinDate: new Date().toISOString()
  }
];

// Load users data from file or use defaults
function loadUsersData() {
  // Ensure persistent directories exist first
  ensurePersistentDirectories();

  try {
    console.log(`ğŸ“‚ Checking for data file at: ${DATA_FILE}`);
    if (fs.existsSync(DATA_FILE)) {
      console.log('ğŸ“‚ Data file exists, loading...');
      const data = fs.readFileSync(DATA_FILE, 'utf8');
      const loadedUsers = JSON.parse(data);

      // Fix missing fields in existing users
      loadedUsers.forEach(user => {
        // Ensure both history arrays exist
        if (!user.history) user.history = [];
        if (!user.transcriptionHistory) user.transcriptionHistory = [];

        // Fix history entries that might have missing fields
        if (user.history) {
          user.history.forEach(entry => {
            if (!entry.date && entry.timestamp) {
              entry.date = new Date(entry.timestamp).toLocaleDateString('he-IL');
            }
            if (!entry.downloadUrl && entry.wordDocumentPath) {
              entry.downloadUrl = entry.wordDocumentPath;
            }
            if (!entry.fileName && entry.originalName) {
              entry.fileName = entry.originalName;
            }
          });
        }

        // Fix transcriptionHistory entries as well
        if (user.transcriptionHistory) {
          user.transcriptionHistory.forEach(entry => {
            if (!entry.date && entry.timestamp) {
              entry.date = new Date(entry.timestamp).toLocaleDateString('he-IL');
            }
            if (!entry.downloadUrl && entry.wordDocumentPath) {
              entry.downloadUrl = entry.wordDocumentPath;
            }
            if (!entry.fileName && entry.originalName) {
              entry.fileName = entry.originalName;
            }
          });
        }
      });

      console.log(`âœ… Successfully loaded ${loadedUsers.length} users from file`);
      return loadedUsers;
    } else {
      console.log('âš ï¸ No data file found, using default users');
      console.log('ğŸ“‚ Default users will be created');
      return [...defaultUsers];
    }
  } catch (error) {
    console.error('âŒ Error loading users data:', error);
    console.error('âŒ Error details:', error.message);
    console.log('ğŸ“‚ Using default users due to error');
    return [...defaultUsers];
  }
}

// Save users data to file
function saveUsersData() {
  try {
    console.log(`ğŸ’¾ Attempting to save ${users.length} users to: ${DATA_FILE}`);
    fs.writeFileSync(DATA_FILE, JSON.stringify(users, null, 2), 'utf8');
    console.log(`âœ… Successfully saved ${users.length} users to file`);

    // Create daily backup
    try {
      const today = new Date().toISOString().split('T')[0];
      const backupFile = path.join(BACKUPS_DIR, `backup_${today}.json`);

      if (!fs.existsSync(backupFile)) {
        const backupData = {
          date: new Date().toISOString(),
          users: users,
          totalUsers: users.length
        };
        fs.writeFileSync(backupFile, JSON.stringify(backupData, null, 2), 'utf8');
        console.log(`âœ… Daily backup created: ${backupFile}`);
      }
    } catch (backupError) {
      console.error('âŒ Error creating backup:', backupError);
    }

    // Verify file was created
    if (fs.existsSync(DATA_FILE)) {
      const stats = fs.statSync(DATA_FILE);
      console.log(`ğŸ“Š File size: ${stats.size} bytes, modified: ${stats.mtime}`);
    } else {
      console.error('âŒ File was not created despite no error!');
    }
  } catch (error) {
    console.error('âŒ Error saving users data:', error);
    console.error('âŒ Error details:', error.message);
    console.error('âŒ Error stack:', error.stack);
  }
}

// Load users on startup
let users = loadUsersData();

// Ensure downloads directory exists (use persistent storage)
const downloadsDir = path.join(PERSISTENT_PATH, 'transcriptions');
if (!fs.existsSync(downloadsDir)) {
  fs.mkdirSync(downloadsDir, { recursive: true });
  console.log('ğŸ“ Created transcriptions directory in persistent storage');
}

// Initialize data file from template if it doesn't exist
const TEMPLATE_FILE = path.join(__dirname, 'users_data_template.json');

if (!fs.existsSync(DATA_FILE)) {
  console.log('ğŸ“‚ Data file not found, creating from template...');

  if (fs.existsSync(TEMPLATE_FILE)) {
    // Copy template to data file
    fs.copyFileSync(TEMPLATE_FILE, DATA_FILE);
    console.log('âœ… Created users_data.json from template');

    // Reload users from the new file
    users = loadUsersData();
  } else {
    console.log('ğŸ“‚ No template found, creating with default users...');
    saveUsersData();
  }
} else {
  console.log('ğŸ“‚ Data file already exists, checking integrity...');
  try {
    const testData = fs.readFileSync(DATA_FILE, 'utf8');
    const testUsers = JSON.parse(testData);
    console.log(`âœ… Data file is valid with ${testUsers.length} users`);
  } catch (error) {
    console.error('âŒ Data file is corrupted, recreating from template...');
    if (fs.existsSync(TEMPLATE_FILE)) {
      fs.copyFileSync(TEMPLATE_FILE, DATA_FILE);
      users = loadUsersData();
      console.log('âœ… Restored from template');
    } else {
      saveUsersData();
    }
  }
}

// Check current file status
if (fs.existsSync(DATA_FILE)) {
  console.log('âœ… Data file exists at startup');
  try {
    const currentData = fs.readFileSync(DATA_FILE, 'utf8');
    const currentUsers = JSON.parse(currentData);
    console.log(`âœ… Current file contains ${currentUsers.length} users`);
  } catch (error) {
    console.error('âŒ Error reading existing file:', error);
  }
} else {
  console.log('âŒ Data file does not exist at startup');
}

// Force save to test the mechanism
console.log('ğŸ”§ Testing save mechanism...');
saveUsersData();

// Save data periodically (every 5 minutes)
setInterval(() => {
  console.log('ğŸ’¾ Auto-saving user data...');
  saveUsersData();
}, 5 * 60 * 1000);

// Helper function to find or create user (JSON version)
async function findOrCreateUser(email) {
  try {
    // Find existing user
    let user = users.find(u => u.email === email);

    if (user) {
      console.log(`ğŸ‘¤ Found existing user: ${email} with ${user.remainingMinutes} minutes`);
      return user;
    }

    // Create new user if not found
    const newUser = {
      email: email,
      remainingMinutes: 0, // No free minutes for new users
      totalTranscribed: 0,
      registrationDate: new Date().toISOString(),
      isAdmin: false,
      transcriptionHistory: []
    };

    users.push(newUser);
    saveUsersData();

    console.log(`âœ… Created new user: ${email} with 0 minutes`);
    return newUser;

  } catch (error) {
    console.error('âŒ Error in findOrCreateUser:', error);
    return null;
  }
}

// Helper function to use user minutes (JSON version)
async function useUserMinutes(email, minutes) {
  try {
    const user = users.find(u => u.email === email);
    if (!user) {
      throw new Error(`User not found: ${email}`);
    }

    if (user.remainingMinutes < minutes) {
      throw new Error(`Insufficient minutes. User has ${user.remainingMinutes}, needs ${minutes}`);
    }

    user.remainingMinutes -= minutes;
    user.totalTranscribed += minutes;
    saveUsersData();

    console.log(`âœ… Used ${minutes} minutes for ${email}. Remaining: ${user.remainingMinutes}`);
    return user;

  } catch (error) {
    console.error('âŒ Error in useUserMinutes:', error);
    throw error;
  }
}

// Helper function to add transcription to history (JSON version)
async function addTranscriptionToHistory(email, transcriptionData) {
  try {
    const user = users.find(u => u.email === email);
    if (!user) {
      console.error(`âŒ User not found for history: ${email}`);
      return;
    }

    // Initialize both history arrays if they don't exist
    if (!user.transcriptionHistory) {
      user.transcriptionHistory = [];
    }
    if (!user.history) {
      user.history = [];
    }

    const historyEntry = {
      ...transcriptionData,
      timestamp: new Date().toISOString()
    };

    // Add to both arrays for backward compatibility
    user.transcriptionHistory.push(historyEntry);
    user.history.push(historyEntry);

    saveUsersData();
    console.log(`ğŸ“ Added transcription to history for ${email}`);

  } catch (error) {
    console.error('âŒ Error in addTranscriptionToHistory:', error);
  }
}

// ğŸ”¥ NEW: FFmpeg and chunking functions
let ffmpegAvailabilityCache = null; // Cache the result

function checkFFmpegAvailability() {
  // Return cached result if already checked
  if (ffmpegAvailabilityCache !== null) {
    return ffmpegAvailabilityCache;
  }

  try {
    const { execSync } = require('child_process');
    execSync('ffmpeg -version', { stdio: 'ignore' });
    ffmpegAvailabilityCache = true;
    return true;
  } catch (error) {
    ffmpegAvailabilityCache = false;
    return false;
  }
}

function getAudioDuration(filePath) {
  return new Promise((resolve, reject) => {
    const ffprobe = spawn('ffprobe', [
      '-v', 'quiet',
      '-show_entries', 'format=duration',
      '-of', 'csv=p=0',
      filePath
    ]);
    
    let stdout = '';
    let stderr = '';
    
    ffprobe.stdout.on('data', (data) => {
      stdout += data.toString();
    });
    
    ffprobe.stderr.on('data', (data) => {
      stderr += data.toString();
    });
    
    ffprobe.on('close', (code) => {
      if (code === 0) {
        const duration = parseFloat(stdout.trim());
        resolve(duration);
      } else {
        console.warn('FFprobe failed, estimating duration from file size');
        // Fallback: estimate based on file size
        const stats = fs.statSync(filePath);
        const estimatedDuration = (stats.size / (1024 * 1024)) * 60; // Rough estimate
        resolve(estimatedDuration);
      }
    });
    
    ffprobe.on('error', (error) => {
      console.warn('FFprobe error, using fallback estimation');
      // Fallback
      const stats = fs.statSync(filePath);
      const estimatedDuration = (stats.size / (1024 * 1024)) * 60;
      resolve(estimatedDuration);
    });
  });
}

async function splitAudioIntoChunks(inputPath, chunkDurationMinutes = 8) {
  const chunksDir = path.join(path.dirname(inputPath), 'chunks_' + Date.now());
  const chunks = [];
  
  try {
    if (!fs.existsSync(chunksDir)) {
      fs.mkdirSync(chunksDir, { recursive: true });
    }
    
    console.log(`ğŸ”ª Splitting audio into ${chunkDurationMinutes}-minute chunks...`);
    
    const duration = await getAudioDuration(inputPath);
    console.log(`ğŸ“Š Total audio duration: ${(duration/60).toFixed(1)} minutes`);
    
    const chunkDurationSeconds = chunkDurationMinutes * 60;
    const totalChunks = Math.ceil(duration / chunkDurationSeconds);
    
    console.log(`ğŸ¯ Creating ${totalChunks} chunks of ${chunkDurationMinutes} minutes each`);
    
    for (let i = 0; i < totalChunks; i++) {
      const startTime = i * chunkDurationSeconds;
      const chunkPath = path.join(chunksDir, `chunk_${i.toString().padStart(3, '0')}.wav`);
      
      await new Promise((resolve, reject) => {
        const ffmpeg = spawn('ffmpeg', [
          '-i', inputPath,
          '-ss', startTime.toString(),
          '-t', chunkDurationSeconds.toString(),
          '-ac', '1', // Mono
          '-ar', '16000', // 16kHz sample rate
          '-c:a', 'pcm_s16le', // PCM 16-bit
          '-y', // Overwrite output file
          chunkPath
        ]);
        
        let stderr = '';
        ffmpeg.stderr.on('data', (data) => {
          stderr += data.toString();
        });
        
        ffmpeg.on('close', (code) => {
          if (code === 0 && fs.existsSync(chunkPath)) {
            const stats = fs.statSync(chunkPath);
            if (stats.size > 1000) { // At least 1KB
              chunks.push({
                path: chunkPath,
                index: i,
                startTime: startTime,
                duration: Math.min(chunkDurationSeconds, duration - startTime)
              });
              console.log(`âœ… Created chunk ${i + 1}/${totalChunks}: ${path.basename(chunkPath)}`);
            } else {
              console.log(`âš ï¸ Chunk ${i + 1} too small, skipping`);
            }
            resolve();
          } else {
            console.error(`âŒ FFmpeg error for chunk ${i}:`, stderr);
            reject(new Error(`FFmpeg failed: ${stderr}`));
          }
        });
        
        ffmpeg.on('error', (error) => {
          console.error(`âŒ FFmpeg spawn error:`, error);
          reject(error);
        });
      });
    }
    
    console.log(`ğŸ‰ Successfully created ${chunks.length} audio chunks`);
    return { chunks, chunksDir };
    
  } catch (error) {
    console.error('ğŸ”¥ Audio splitting error:', error);
    // Cleanup on error
    if (fs.existsSync(chunksDir)) {
      try {
        fs.rmSync(chunksDir, { recursive: true, force: true });
      } catch (e) {}
    }
    throw error;
  }
}

async function transcribeAudioChunk(chunkPath, chunkIndex, totalChunks, filename, language, customInstructions) {
  const startTime = Date.now(); // Define startTime at the beginning to avoid undefined errors
  try {
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-pro",
      generationConfig: {
        temperature: 0,
        maxOutputTokens: 32768
      }
    });
    
    const audioData = fs.readFileSync(chunkPath);
    const base64Audio = audioData.toString('base64');
    
    // Enhanced prompt for chunk transcription with context
    let contextPrompt = '';
    if (chunkIndex === 0) {
      contextPrompt = 'ğŸ¯ ×–×”×• ×”×—×œ×§ ×”×¨××©×•×Ÿ ×©×œ ×”×§×•×‘×¥ - ×”×ª×—×œ ××”×”×ª×—×œ×” ×”××•×—×œ×˜×ª.';
    } else if (chunkIndex === totalChunks - 1) {
      contextPrompt = 'ğŸ¯ ×–×”×• ×”×—×œ×§ ×”××—×¨×•×Ÿ ×©×œ ×”×§×•×‘×¥ - ×”××©×š ×¢×“ ×”×¡×•×£ ×”××•×—×œ×˜.';
    } else {
      contextPrompt = `ğŸ¯ ×–×”×• ×—×œ×§ ${chunkIndex + 1} ××ª×•×š ${totalChunks} - ×”××©×š ××ª ×”×ª××œ×•×œ ××”× ×§×•×“×” ×‘×” ×”×§×˜×¢ ×”×§×•×“× ×”×¡×ª×™×™×.`;
    }
    
    const prompt = `${(language === 'Hebrew' || language === 'he') ? '×ª××œ×œ ××ª ×§×˜×¢ ×”××•×“×™×• ×”×–×” ×œ×¢×‘×¨×™×ª ×ª×§× ×™×ª.' : `Transcribe this audio chunk in ${language || 'the original language'}. Do NOT translate.`}

ğŸš¨ ×—×©×•×‘: ×× ××™×œ×™× ×—×•×–×¨×•×ª ×¢×œ ×¢×¦××Ÿ, ×¨×©×•× ××•×ª×Ÿ ××§×¡×™××•× 5 ×¤×¢××™× ×‘×¨×¦×™×¤×•×ª.
××œ ×ª×—×–×•×¨ ×¢×œ ××•×ª×Ÿ ××™×œ×™× ××• ×‘×™×˜×•×™×™× ×™×•×ª×¨ ×-5 ×¤×¢××™× ×‘×¨×¦×£.

${contextPrompt}

×§×•×‘×¥ ××•×“×™×• (×—×œ×§ ${chunkIndex + 1}/${totalChunks})

ğŸš¨ ×”×•×¨××•×ª ×§×¨×™×˜×™×•×ª:
1. ×ª××œ×œ ××ª ×›×œ ×”×ª×•×›×Ÿ ×‘×§×˜×¢ ×”×–×” - ×›×œ ××™×œ×”, ×›×œ ××©×¤×˜
2. ××œ ×ª×•×¡×™×£ ×”×¢×¨×•×ª ×›××• "×–×”×• ×”××©×š" ××• "×¡×™×•× ×—×œ×§"
3. ×”×ª×—×œ ×™×©×™×¨×•×ª ×¢× ×”×ª×•×›×Ÿ ×”××ª×•××œ×œ
4. ×¡×™×™× ×™×©×™×¨×•×ª ×¢× ×”×ª×•×›×Ÿ - ××œ ×ª×•×¡×™×£ ×¡×™×›×•×
5. ×× ×™×© ×—×™×ª×•×š ×‘×××¦×¢ ××™×œ×”/××©×¤×˜ - ×›×ª×•×‘ ××ª ××” ×©××ª×” ×©×•××¢

×ª×ª×—×™×œ ×¢×›×©×™×• ×¢× ×”×ª××œ×•×œ:`;

    const chunkSizeMB = (audioData.length / (1024 * 1024)).toFixed(1);
    console.log(`ğŸ¯ Transcribing chunk ${chunkIndex + 1}/${totalChunks} (${chunkSizeMB}MB)...`);

    // Add timeout wrapper - 4 minutes for 4-minute chunks
    const transcriptionPromise = model.generateContent([
      {
        inlineData: {
          mimeType: 'audio/wav',
          data: base64Audio
        }
      },
      prompt
    ]);

    const timeoutPromise = new Promise((_, reject) =>
      setTimeout(() => reject(new Error('Transcription timeout after 4 minutes')), 4 * 60 * 1000)
    );

    const result = await Promise.race([transcriptionPromise, timeoutPromise]);

    const response = await result.response;
    let transcription = response.text();

    // ğŸ”¥ NEW: ×”×¡×¨ ×—×–×¨×•×ª ×§×™×¦×•× ×™×•×ª ××”××•×“×œ
    transcription = removeExtremeRepetitions(transcription);

    // Validate transcription
    if (!transcription || transcription.trim().length < 10) {
      throw new Error(`Invalid transcription: too short (${transcription ? transcription.length : 0} characters)`);
    }

    // Clean the transcription
    transcription = transcription
      .replace(/\r\n/g, '\n')
      .replace(/^\s*×ª××œ×•×œ[:\s]*/i, '') // Remove "×ª××œ×•×œ:" prefix
      .replace(/^\s*×—×œ×§ \d+[:\s]*/i, '') // Remove "×—×œ×§ X:" prefix
      .replace(/\n{3,}/g, '\n\n')
      .trim();

    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`âœ… Chunk ${chunkIndex + 1} transcribed: ${transcription.length} characters in ${duration}s`);
    return transcription;

  } catch (error) {
    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.error(`âŒ Error transcribing chunk ${chunkIndex + 1} after ${duration}s:`, error.message);
    throw error;
  }
}

async function mergeTranscriptionChunks(chunks, language = 'Hebrew') {
  console.log(`ğŸ”— Merging ${chunks.length} transcription chunks...`);
  
  if (chunks.length === 0) return '';
  if (chunks.length === 1) return chunks[0];
  
  let merged = chunks[0];
  
  for (let i = 1; i < chunks.length; i++) {
    const currentChunk = chunks[i];
    
    // Try to detect overlap by looking at the end of previous chunk and start of current
    const prevEnd = merged.slice(-100).trim(); // Last 100 chars
    const currentStart = currentChunk.slice(0, 100).trim(); // First 100 chars
    
    // Simple overlap detection - look for common words
    const prevWords = prevEnd.split(/\s+/).slice(-5); // Last 5 words
    const currentWords = currentStart.split(/\s+/).slice(0, 10); // First 10 words
    
    let overlapFound = false;
    let overlapIndex = -1;
    
    // Check if any of the last words from previous chunk appear in the start of current chunk
    for (let j = 0; j < prevWords.length; j++) {
      const word = prevWords[j];
      if (word.length > 3) { // Only check meaningful words
        const index = currentWords.findIndex(w => w.includes(word) || word.includes(w));
        if (index !== -1) {
          overlapFound = true;
          overlapIndex = index;
          console.log(`ğŸ” Overlap detected: "${word}" at position ${index}`);
          break;
        }
      }
    }
    
    if (overlapFound && overlapIndex > 0) {
      // Remove overlapping part from current chunk
      const wordsToSkip = overlapIndex + 1;
      const remainingWords = currentWords.slice(wordsToSkip);
      const cleanedCurrent = remainingWords.join(' ') + currentChunk.slice(100);
      merged += '\n\n' + cleanedCurrent.trim();
      console.log(`ğŸ”— Merged with overlap removal (skipped ${wordsToSkip} words)`);
    } else {
      // No overlap detected, merge normally
      merged += '\n\n' + currentChunk.trim();
      console.log(`ğŸ”— Merged without overlap detection`);
    }
  }
  
  // Final cleanup
  merged = merged
    .replace(/\n{4,}/g, '\n\n\n')
    .replace(/^\s+|\s+$/gm, '')
    .trim();

  console.log(`âœ… Merge completed: ${merged.length} total characters`);

  // ×©×œ×‘ 2: ×—×œ×•×§×” ×—×›××” ×œ×¤×¡×§××•×ª ×‘×’××™× ×™
  console.log(`ğŸ” Checking smart division conditions: language="${language}", length=${merged.length}`);
  if ((language === 'Hebrew' || language === 'he') && merged.length > 500) {
    console.log(`â±ï¸ Waiting 3 seconds before smart paragraph division to avoid API rate limits...`);
    await new Promise(resolve => setTimeout(resolve, 3000));
    console.log(`ğŸ¯ Starting smart paragraph division with Gemini...`);
    merged = await smartParagraphDivision(merged);
  } else {
    console.log(`âŒ Smart division skipped - language: "${language}" (Hebrew/he)? ${(language === 'Hebrew' || language === 'he')}, length > 500? ${merged.length > 500}`);
  }

  // Python will handle all text processing - no Node.js processing needed
  console.log(`ğŸ“ Sending processed transcription to Python...`);

  return merged;
}

// ğŸ¯ NEW: Smart paragraph division with Gemini
async function smartParagraphDivision(text) {
  try {
    // Check if text is too long (over 15K chars) and split it
    const MAX_CHARS = 15000;
    if (text.length > MAX_CHARS) {
      console.log(`ğŸ“ Text too long (${text.length} chars), splitting into chunks...`);
      return await smartParagraphDivisionChunked(text, MAX_CHARS);
    }

    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-pro",
      generationConfig: {
        temperature: 0.1,
        maxOutputTokens: 500000
      }
    });

    const prompt = `×× ×™ × ×•×ª×Ÿ ×œ×š ×˜×§×¡×˜ ×©×œ ×©×™×¢×•×¨ ×ª×•×¨×” ×©×ª×•××œ×œ, ×•×× ×™ ×¨×•×¦×” ×©×ª×—×œ×§ ××•×ª×• ×œ×¤×¡×§××•×ª ×—×›××•×ª ×œ×¤×™ ×”× ×•×©××™× ×•×”×¨×¢×™×•× ×•×ª.

ğŸ¯ ×—×•×§×™ ×—×œ×•×§×” ×—×›××”:
- ×›×œ ×¤×¡×§×” ×¦×¨×™×›×” ×œ×”×™×•×ª ×¨×¢×™×•×Ÿ ××• × ×•×©× ×©×œ×
- ×¤×¡×§×” ×—×“×©×” ×œ××¢×‘×¨ × ×•×©× (××”×œ×›×” ×œ××’×“×”, ×××©×œ ×œ×¤×¡×§, ××¡×™×¤×•×¨ ×œ×¢×™×§×¨×•×Ÿ)
- ×¤×¡×§×” ×—×“×©×” ×œ×›×œ ×¦×™×˜×•×˜ ××¨×•×š (×¤×¡×•×§, ××××¨ ×—×–"×œ, ×”×œ×›×”)
- ×¤×¡×§×” ×—×“×©×” ×œ×›×œ ×¡×™×¤×•×¨ ××• ×“×•×’××”
- ×¤×¡×§×” ×—×“×©×” ×›×©×”×¨×‘ ×¢×•×‘×¨ ×œ×“×‘×¨ ××—×¨ ("×× ×™ ×¨×•×¦×” ×œ×¡×¤×¨", "×“×‘×¨ ××—×¨", "×œ××©×œ")
- ×©××œ×•×ª ×•×ª×©×•×‘×•×ª ×‘×¤×¡×§××•×ª × ×¤×¨×“×•×ª

ğŸ”¥ ×—×©×•×‘ ×‘×™×•×ª×¨:
- ×”×¤×¨×“ ×›×œ ×¤×¡×§×” ×¢× ×©×•×¨×” ×¨×™×§×” ×›×¤×•×œ×” (\\n\\n)
- ××œ ×ª×©× ×” ×©×•× ××™×œ×” ×‘×˜×§×¡×˜! ×¨×§ ×ª×—×œ×§ ×œ×¤×¡×§××•×ª
- ×©××•×¨ ×¢×œ ×›×œ ×”×˜×§×¡×˜ ×›×¤×™ ×©×”×•×, ×›×•×œ×œ ×©×’×™××•×ª

×”×˜×§×¡×˜ ×œ×—×œ×•×§×”:
${text}

×ª×—×–×™×¨ ××ª ×”×˜×§×¡×˜ ×”××—×•×œ×§ ×œ×¤×¡×§××•×ª ×¢× \\n\\n ×‘×™×Ÿ ×›×œ ×¤×¡×§×”:`;

    console.log(`ğŸ¯ Sending ${text.length} characters to Gemini for smart division...`);

    // Retry mechanism with timeout
    let result;
    for (let attempt = 1; attempt <= 3; attempt++) {
      try {
        console.log(`ğŸ”„ Attempt ${attempt}/3 for smart division...`);

        // Create timeout promise
        const timeoutPromise = new Promise((_, reject) =>
          setTimeout(() => reject(new Error('Smart division timeout after 3 minutes')), 3 * 60 * 1000)
        );

        // Create generation promise
        const generatePromise = model.generateContent(prompt);

        // Race between generation and timeout
        result = await Promise.race([generatePromise, timeoutPromise]);

        console.log(`âœ… Smart division API call successful on attempt ${attempt}`);
        break; // Success, exit retry loop

      } catch (attemptError) {
        console.error(`âŒ Attempt ${attempt} failed:`, attemptError.message);

        if (attempt === 3) {
          throw attemptError; // Final attempt failed, throw error
        }

        // Wait before retry (exponential backoff)
        const waitTime = attempt * 2000; // 2s, 4s
        console.log(`â³ Waiting ${waitTime}ms before retry...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
      }
    }

    const response = await result.response;
    let dividedText = response.text().trim();

    console.log(`âœ… Smart division completed: ${dividedText.length} characters`);

    // ×•×™×“×•× ×©×™×© ×—×œ×•×§×” ×œ×¤×¡×§××•×ª
    const paragraphCount = dividedText.split('\\n\\n').length;
    console.log(`ğŸ“Š Created ${paragraphCount} smart paragraphs`);

    return dividedText;

  } catch (error) {
    console.error('ğŸ”¥ Smart paragraph division failed:', error);
    console.log(`âš ï¸ Falling back to original text`);
    return text; // ×—×–×•×¨ ×œ×˜×§×¡×˜ ×”××§×•×¨×™ ×× × ×›×©×œ
  }
}

// ğŸ¯ NEW: Smart paragraph division for long texts (chunked processing)
async function smartParagraphDivisionChunked(text, maxChars) {
  try {
    // Split text into chunks at sentence boundaries
    const chunks = splitTextIntoChunks(text, maxChars);
    console.log(`ğŸ“¦ Split into ${chunks.length} chunks for processing`);

    const processedChunks = [];

    for (let i = 0; i < chunks.length; i++) {
      console.log(`ğŸ”„ Processing chunk ${i + 1}/${chunks.length} (${chunks[i].length} chars)...`);

      // Add delay between chunks to avoid rate limiting
      if (i > 0) {
        console.log('â±ï¸ Waiting 5 seconds between chunks...');
        await new Promise(resolve => setTimeout(resolve, 5000));
      }

      try {
        // Process chunk through smart division
        const processedChunk = await smartParagraphDivisionSingle(chunks[i]);
        processedChunks.push(processedChunk);
        console.log(`âœ… Chunk ${i + 1}/${chunks.length} processed successfully (${processedChunk.length} chars)`);
      } catch (error) {
        console.error(`âŒ Chunk ${i + 1}/${chunks.length} failed:`, error.message);
        // Add original chunk without processing as fallback
        processedChunks.push(chunks[i]);
        console.log(`ğŸ”„ Added unprocessed chunk ${i + 1} as fallback (${chunks[i].length} chars)`);
      }
    }

    // Join all processed chunks
    const result = processedChunks.join('\n\n');
    console.log(`âœ… Chunked processing completed: ${result.length} characters`);

    return result;

  } catch (error) {
    console.error('ğŸ”¥ Chunked smart division failed:', error);
    return text;
  }
}

// Helper function to split text into chunks at sentence boundaries
function splitTextIntoChunks(text, maxChars) {
  const chunks = [];
  let currentChunk = '';

  // Split by sentences (Hebrew and English)
  const sentences = text.split(/(?<=[.!?])\s+|(?<=[×´×³])\s+/).filter(s => s.trim());

  for (const sentence of sentences) {
    if (currentChunk.length + sentence.length > maxChars && currentChunk.length > 0) {
      chunks.push(currentChunk.trim());
      currentChunk = sentence;
    } else {
      currentChunk += (currentChunk ? ' ' : '') + sentence;
    }
  }

  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
}

// Single chunk processing (same as original but without chunking check)
async function smartParagraphDivisionSingle(text) {
  const model = genAI.getGenerativeModel({
    model: "gemini-2.5-pro",
    generationConfig: {
      temperature: 0.1,
      maxOutputTokens: 500000
    }
  });

  const prompt = `×× ×™ × ×•×ª×Ÿ ×œ×š ×˜×§×¡×˜ ×©×œ ×©×™×¢×•×¨ ×ª×•×¨×” ×©×ª×•××œ×œ, ×•×× ×™ ×¨×•×¦×” ×©×ª×—×œ×§ ××•×ª×• ×œ×¤×¡×§××•×ª ×—×›××•×ª ×œ×¤×™ ×”× ×•×©××™× ×•×”×¨×¢×™×•× ×•×ª.

ğŸ¯ ×—×•×§×™ ×—×œ×•×§×” ×—×›××”:
- ×›×œ ×¤×¡×§×” ×¦×¨×™×›×” ×œ×”×™×•×ª ×¨×¢×™×•×Ÿ ××• × ×•×©× ×©×œ×
- ×¤×¡×§×” ×—×“×©×” ×œ××¢×‘×¨ × ×•×©× (××”×œ×›×” ×œ××’×“×”, ×××©×œ ×œ×¤×¡×§, ××¡×™×¤×•×¨ ×œ×¢×™×§×¨×•×Ÿ)
- ×¤×¡×§×” ×—×“×©×” ×œ×›×œ ×¦×™×˜×•×˜ ××¨×•×š (×¤×¡×•×§, ××××¨ ×—×–"×œ, ×”×œ×›×”)
- ×¤×¡×§×” ×—×“×©×” ×œ×›×œ ×¡×™×¤×•×¨ ××• ×“×•×’××”
- ×¤×¡×§×” ×—×“×©×” ×›×©×”×¨×‘ ×¢×•×‘×¨ ×œ×“×‘×¨ ××—×¨ ("×× ×™ ×¨×•×¦×” ×œ×¡×¤×¨", "×“×‘×¨ ××—×¨", "×œ××©×œ")
- ×©××œ×•×ª ×•×ª×©×•×‘×•×ª ×‘×¤×¡×§××•×ª × ×¤×¨×“×•×ª

ğŸ”¥ ×—×©×•×‘ ×‘×™×•×ª×¨:
- ×”×¤×¨×“ ×›×œ ×¤×¡×§×” ×¢× ×©×•×¨×” ×¨×™×§×” ×›×¤×•×œ×” (\\n\\n)
- ××œ ×ª×©× ×” ×©×•× ××™×œ×” ×‘×˜×§×¡×˜! ×¨×§ ×ª×—×œ×§ ×œ×¤×¡×§××•×ª
- ×©××•×¨ ×¢×œ ×›×œ ×”×˜×§×¡×˜ ×›×¤×™ ×©×”×•×, ×›×•×œ×œ ×©×’×™××•×ª

×”×˜×§×¡×˜ ×œ×—×œ×•×§×”:
${text}

×ª×—×–×™×¨ ××ª ×”×˜×§×¡×˜ ×”××—×•×œ×§ ×œ×¤×¡×§××•×ª ×¢× \\n\\n ×‘×™×Ÿ ×›×œ ×¤×¡×§×”:`;

  // Retry mechanism
  let result;
  for (let attempt = 1; attempt <= 3; attempt++) {
    try {
      console.log(`ğŸ”„ Attempt ${attempt}/3 for chunk smart division...`);

      const timeoutPromise = new Promise((_, reject) =>
        setTimeout(() => reject(new Error('Smart division timeout after 3 minutes')), 3 * 60 * 1000)
      );

      const generatePromise = model.generateContent(prompt);
      result = await Promise.race([generatePromise, timeoutPromise]);
      break;

    } catch (attemptError) {
      console.error(`âŒ Chunk attempt ${attempt} failed:`, attemptError.message);
      if (attempt === 3) throw attemptError;

      const waitTime = attempt * 8000;
      console.log(`â³ Waiting ${waitTime / 1000} seconds before retry...`);
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }

  const response = await result.response;
  return response.text().trim();
}

// Helper function for Hebrew text fixes only (paragraphs handled by Gemini)
function applyHebrewTextFixes(text) {
  console.log(`ğŸ”§ Starting Hebrew text fixes...`);

  // ×©×œ×‘ 1: ×ª×™×§×•×Ÿ ××’×¨×¡×™×‘×™ ×•×—×–×§ ×œ×›×œ ×‘×¢×™×•×ª ×”×¢×‘×¨×™×ª
  console.log('ğŸ”§ Starting SUPER AGGRESSIVE Hebrew fixing...');

  // ×§×•×“× ×›×œ - × ×§×” ××ª ×›×œ ×”×’×¨×©×™×™× ×œ×¡×•×’ ××—×™×“
  text = text.replace(/["\u0022\u201C\u201D]/g, '"');

  // **×©×œ×‘ ×: ×ª×™×§×•×Ÿ ×§×™×¦×•×¨×™× × ×¤×•×¦×™× - ×œ×œ× ×¤×©×¨×•×ª**
  const hebrewAbbreviations = [
    ['×¨×©', '×™'], ['×—×–', '×œ'], ['×©×œ×™×˜', '×'], ['×”×—×™×“', '×'],
    ['×”×’×¨', '×'], ['×¨××‘', '×'], ['×¨××‘', '×Ÿ'], ['××©× ', '×‘'],
    ['×©×•', '×¢'], ['×©×•', '×ª'], ['××”×¨', '×œ'], ['×‘×§', '×‘'],
    ['×‘', '×”'], ['×“', '×”']
  ];

  hebrewAbbreviations.forEach(([first, second]) => {
    // ×›×œ ×”×•×•×¨×™××¦×™×•×ª ×”××¤×©×¨×™×•×ª ×©×œ ×¨×•×•×—×™× ×•×’×¨×©×™×™×
    const patterns = [
      `${first}\\s*"\\s*${second}`,    // ×¨×© " ×™
      `${first}\\s+"\\s*${second}`,    // ×¨×©  " ×™
      `${first}"\\s*${second}`,        // ×¨×©" ×™
      `${first}\\s*"${second}`,        // ×¨×© "×™
      `${first}"${second}`             // ×¨×©"×™ (×›×‘×¨ × ×›×•×Ÿ)
    ];

    patterns.forEach(pattern => {
      const regex = new RegExp(pattern, 'g');
      text = text.replace(regex, `${first}"${second}`);
    });
  });

  // **×©×œ×‘ ×‘: ×ª×™×§×•×Ÿ ×›×œ ××™×œ×” + ×’×¨×©×™×™× + ××•×ª (×ª×‘× ×™×ª ×›×œ×œ×™×ª)**
  text = text.replace(/([×-×ª]{2,})\s*"\s*([×-×ª])/g, '$1"$2');

  // **×©×œ×‘ ×’: ×ª×™×§×•×Ÿ ×©××•×ª ×•×›×•×ª×¨×™× ×¢× ×’×¨×©×™×™×**
  text = text
    .replace(/×”\s+"([^"]+)"/g, '×”"$1"')              // ×” "××•×”×‘ ×™×©×¨××œ"
    .replace(/([×-×ª])\s+"([^"]+)"/g, '$1"$2"')       // ××™×œ×” "×©×"

    // **×©×œ×‘ ×“: ×ª×™×§×•×Ÿ ××™×œ×™× ××ª×—×œ×§×•×ª**
    .replace(/×—×–\s*"\s*×œ×™×/g, '×—×–"×œ×™×')
    .replace(/([×-×ª]+)×œ×™\s*"\s*×/g, '$1×œ×™×')        // ×›×œ ××™×œ×” ×©××¡×ª×™×™××ª ×‘"×œ×™"×

    // **×©×œ×‘ ×”: ×ª×™×§×•×Ÿ ××™×œ×™× ×¦××•×“×•×ª**
    .replace(/×™×•×“×¢×ª×¨××•/g, '×™×•×“×¢×ª ×¨××•')
    .replace(/××•××¨×ª×× ×™/g, '××•××¨×ª ×× ×™')
    .replace(/×©××œ×ª×™××•×ª×•/g, '×©××œ×ª×™ ××•×ª×•')

    // **×©×œ×‘ ×•: ×ª×™×§×•×Ÿ ×¤×™×¡×•×§**
    .replace(/([×-×ª]+)"\s*]/g, '$1."]')              // ×¤×™×¡×•×§ ×¢× ×¡×•×’×¨×™×™×
    .replace(/\s+([.,!?:;])/g, '$1')                 // ×”×¡×¨ ×¨×•×•×—×™× ×œ×¤× ×™ ×¤×™×¡×•×§
    .replace(/([.,!?:;])\s+/g, '$1 ')                // ×¨×•×•×— ××—×¨×™ ×¤×™×¡×•×§
    .replace(/\s{2,}/g, ' ')                         // ×¨×•×•×—×™× ×›×¤×•×œ×™×
    .trim();

  console.log('âœ… SUPER AGGRESSIVE Hebrew fixing completed');

  // ×ª×™×§×•×Ÿ × ×•×¡×£ ×©×œ ××™×œ×™× ×©××ª×—×œ×§×•×ª ×¢× ×’×¨×©×™×™×
  text = text
    .replace(/×—×–\s*"\s*×œ×™×/g, '×—×–"×œ×™×')      // ×—×– "×œ×™× -> ×—×–"×œ×™×
    .replace(/×—×–\s+"\s*×œ×™×/g, '×—×–"×œ×™×')     // ×—×–  "×œ×™× -> ×—×–"×œ×™×
    .replace(/×—×›××™\s*"\s*×/g, '×—×›××™×')
    .replace(/×××™× ×™\s*×/g, '××× ×™×')

    // ×ª×™×§×•×Ÿ ××™×œ×™× ×¢× ×¨' (×¨×‘)
    .replace(/×¨\s*'\s*([×-×ª])/g, '×¨\' $1')

    // ×ª×™×§×•×Ÿ ××™×ª×•×§×™× ×©×’×•×™×™× ×‘××™×œ×™× ×¢×‘×¨×™×•×ª
    .replace(/×××Ÿ-×™×/g, '××× ×™×')
    .replace(/×‘×Ÿ-××“×/g, '×‘×Ÿ ××“×')
    .replace(/×™×”×•×“×™-×™×/g, '×™×”×•×“×™×')
    .replace(/×ª×œ××™×“-×™×/g, '×ª×œ××™×“×™×')
    .replace(/×™×œ×“-×™×/g, '×™×œ×“×™×')
    .replace(/×©× -×™×/g, '×©× ×™×')
    .replace(/×—×›×-×™×/g, '×—×›××™×')
    .replace(/×¨×©×¢-×™×/g, '×¨×©×¢×™×')

    // ×ª×™×§×•×Ÿ ×’×¨×©×™×™× ×•×¦×™×˜×•×˜×™× ××ª×§×“× - ×¤×ª×¨×•×Ÿ ×—×–×§ ×•×¡×•×¤×™
    // ×©×œ×‘ 1: × ×§×” ×¡×•×’×™ ×’×¨×©×™×™× ×©×•× ×™× ×œ××—×™×“
    .replace(/["\u0022\u201C\u201D]/g, '"')

    // ×©×œ×‘ 2: ×ª×§×Ÿ ×’×¨×©×™×™× ×›×¤×•×œ×™× ×¡×‘×™×‘ ×©××•×ª (×” "××•×”×‘ ×™×©×¨××œ" -> ×”"××•×”×‘ ×™×©×¨××œ")
    .replace(/×”\s+"([^"]+)"/g, '×”"$1"')
    .replace(/([×-×ª])\s+"([^"]+)"/g, '$1"$2"')

    // ×©×œ×‘ 3: ×”×•×¡×£ ×¨×•×•×—×™× ×œ×¤× ×™ ×’×¨×©×™×™× ×©×¦××•×“×™× ×œ××™×œ×™× ×¢×‘×¨×™×•×ª (×¨×§ ×œ×¦×™×˜×•×˜×™×)
    .replace(/([×-×ª])"([×-×ª][^"]*[×-×ª])"([.,!?\s])/g, '$1 "$2"$3')
    .replace(/([×-×ª])"([×-×ª]{2,})/g, (match, before, after) => {
      // ×©××•×¨ ×§×™×¦×•×¨×™× ×¢×‘×¨×™×™× ××•×›×¨×™×
      const abbreviations = ['×œ×™×', '×œ×™', '×œ×™×Ÿ', '×œ× ×•', '×œ', '×', '×Ÿ', '×', '×™', '×‘', '×”', '×¢', '×ª'];
      if (abbreviations.some(abbr => after.startsWith(abbr))) {
        return match; // ×”×©××¨ ×›××• ×©×–×”
      }
      return before + ' "' + after; // ×”×•×¡×£ ×¨×•×•×—
    })

    // ×©×œ×‘ 4: ×ª×§×Ÿ ×’×¨×©×™×™× ×©×™×© ×œ×”× ×¨×•×•×— ××™×•×ª×¨ ×œ×¤× ×™ ×”×
    .replace(/([×-×ª])\s{2,}"([×-×ª])/g, '$1 "$2')

    // ×©×œ×‘ 5: ×ª×§×Ÿ ×’×¨×©×™×™× ×¢× ×¤×™×¡×•×§ - ×¦××•×“ ×œ××™×œ×” ×œ×¤× ×™ ×”×¤×™×¡×•×§
    .replace(/([×-×ª])"([.,!?])/g, '$1"$2')

    // ×©×œ×‘ 6: ×ª×§×Ÿ ×ª×—×™×œ×ª ×¦×™×˜×•×˜×™×
    .replace(/\s"([×-×ª])/g, ' "$1')
    .replace(/^"([×-×ª])/gm, '"$1')

    // ×©×œ×‘ 7: ×ª×§×Ÿ ×’×¨×©×™×™× ×¡×•×’×¨×™× ×¦××•×“×™× ×œ××™×œ×” ×”×‘××”
    .replace(/([.,!?])"([×-×ª])/g, '$1" $2')
    .replace(/([×-×ª])"([×-×ª])/g, '$1" $2')
    .replace(/(\s)"([×-×ª])/g, '$1"$2')
    .replace(/^"([×-×ª])/gm, '"$1')

    // ×©×œ×‘ 8: ×ª×§×Ÿ ×¤×™×¡×•×§ ××—×¨×™ ×’×¨×©×™×™× ×©×¦××•×“ ×œ× × ×›×•×Ÿ
    .replace(/([×-×ª])"\.\s*"/g, '$1."')
    .replace(/([×-×ª])"\.\s*]/g, '$1."]')
    .replace(/([×-×ª])"\,/g, '$1",')
    .replace(/([×-×ª])"!/g, '$1"!')
    .replace(/([×-×ª])"\?/g, '$1"?')

    // ×ª×™×§×•×Ÿ ×¤×™×¡×•×§ ×—×–×§ ×™×•×ª×¨ - ×”×¡×¨×ª ×¨×•×•×—×™× ×œ×¤× ×™ ×¤×™×¡×•×§
    .replace(/\s+([.,!?:;])/g, '$1')
    .replace(/([.,!?:;])\s+/g, '$1 ')

    // ×ª×™×§×•×Ÿ ×¤×™×¡×•×§ ×¢× ××™×œ×™× ×¢×‘×¨×™×•×ª
    .replace(/([×-×ª])([.,!?:;])([×-×ª])/g, '$1$2 $3')

    // ×ª×™×§×•×Ÿ ××§×¨×™× ×¡×¤×¦×™×¤×™×™× ×©×œ ××™×œ×™× ×¦××•×“×•×ª
    .replace(/×™×•×“×¢×ª×¨××•/g, '×™×•×“×¢×ª ×¨××•')
    .replace(/××•××¨×ª×× ×™/g, '××•××¨×ª ×× ×™')
    .replace(/×©××œ×ª×™××•×ª×•/g, '×©××œ×ª×™ ××•×ª×•')
    .replace(/×××¨×ª×™×›×Ÿ/g, '×××¨×ª×™ ×›×Ÿ')

    // ×ª×™×§×•×Ÿ ×¡×•×¤×™ ×©×œ ×—×–"×œ ×¢× ×¨×•×•×—
    .replace(/×—×–\s+"×œ×™×/g, '×—×–"×œ×™×')
    .replace(/×—×–\s+\"\s*×œ×™×/g, '×—×–"×œ×™×')

    // ×ª×™×§×•×Ÿ ×‘×¢×™×•×ª ×¦××™×“×•×ª ×’×¨×©×™×™× ×•×¤×™×¡×•×§ - ×¤×ª×¨×•×Ÿ ×¡×•×¤×™ ×•××•×©×œ×
    .replace(/([×-×ª])\."/g, '$1".')              // × ×§×•×“×” ×œ×¤× ×™ ×’×¨×©×™×™×
    .replace(/([×-×ª])"([×-×ª])/g, '$1 "$2')      // ×¨×•×•×— ×œ×¤× ×™ ×’×¨×©×™×™× ×¤×•×ª×—×™×

    // ×ª×™×§×•× ×™× ×¡×¤×¦×™×¤×™×™× ×œ×‘×¢×™×•×ª ××ª×§×“××•×ª
    .replace('××•××¨ "×©××œ', '××•××¨" ×©××œ')          // ×ª×™×§×•×Ÿ ×’×¨×©×™×™× ×¡×•×’×¨×™× ×¡×¤×¦×™×¤×™
    .replace('×•×."×•', '×•×". ×•')                  // ×ª×™×§×•×Ÿ × ×§×•×“×” ×‘××§×•× ×”×œ× × ×›×•×Ÿ
    .replace('".×”×™×•×', '". ×”×™×•×')               // ×ª×™×§×•×Ÿ ×’×¨×©×™×™×+× ×§×•×“×” ×¦××•×“×™×

    // ×ª×™×§×•× ×™× ×›×œ×œ×™×™× × ×•×¡×¤×™×
    .replace(/"\\.([×-×ª])/g, '". $1')            // ×¨×•×•×— ××—×¨×™ × ×§×•×“×”+×’×¨×©×™×™×

    // ×ª×™×§×•×Ÿ ×‘×¢×™×•×ª ×¤×™×¡×•×§ ×‘×¡×•×£ ×¦×™×˜×•×˜×™×
    .replace(/([×-×ª]+)"\s*]/g, '$1."]')
    .replace(/([×-×ª]+)"\s*\]/g, '$1"]')

    // × ×™×§×•×™ ×¨×•×•×—×™× ××™×•×ª×¨×™×
    .replace(/\s{2,}/g, ' ')
    .replace(/^\s+|\s+$/gm, '')
    .trim();

  console.log(`âœ… Hebrew text fixes completed`);

  // ×”×—×–×¨ ××ª ×”×˜×§×¡×˜ ×”××ª×•×§×Ÿ ×œ×œ× ×¢×™×‘×•×“ ×¤×¡×§××•×ª (×’'××™× ×™ ×›×‘×¨ ×¢×©×” ××ª ×–×”)
  return text;
}

// Helper function to sanitize filename for API calls
function sanitizeFilename(filename) {
  if (!filename) return filename;

  // Replace problematic characters that can cause API issues
  let sanitized = filename
    .replace(/['"]/g, '') // Remove single and double quotes
    .replace(/['×³×´]/g, '') // Remove Hebrew geresh and gershayim
    .replace(/[<>:"|?*]/g, '_') // Replace other problematic chars with underscore
    .replace(/\s+/g, ' ') // Normalize whitespace
    .trim();

  // If still too long (over 150 chars), truncate while preserving extension
  if (sanitized.length > 150) {
    const extension = path.extname(sanitized);
    const nameWithoutExt = sanitized.slice(0, -extension.length);
    const maxNameLength = 150 - extension.length - 3; // -3 for "..."

    if (maxNameLength > 0) {
      sanitized = nameWithoutExt.slice(0, maxNameLength) + '...' + extension;
      console.log(`âœ‚ï¸ Truncated long filename: "${filename}" â†’ "${sanitized}"`);
    }
  }

  if (sanitized !== filename) {
    console.log(`ğŸ§¹ Sanitized filename: "${filename}" â†’ "${sanitized}"`);
  }

  return sanitized;
}

// Helper function to clean filename for display
function cleanFilename(filename) {
  console.log(`ğŸ” Original filename: "${filename}"`);
  
  // Remove timestamp prefix (numbers followed by underscore)
  let withoutTimestamp = filename.replace(/^\d+_/, '');
  console.log(`ğŸ“ After removing timestamp: "${withoutTimestamp}"`);
  
  // Try multiple decoding approaches
  let cleaned = withoutTimestamp;
  
  // Method 1: Try URL decoding if contains %
  if (cleaned.includes('%')) {
    try {
      cleaned = decodeURIComponent(cleaned);
      console.log(`ğŸ”„ After URL decode: "${cleaned}"`);
    } catch (e) {
      console.log('URL decode failed');
    }
  }
  
  // Method 2: Try Buffer conversion for Hebrew encoding issues
  try {
    // Convert from latin1 to utf8 if it looks like Hebrew encoding issue
    if (cleaned.includes('Ãƒ') || cleaned.includes('Ã‚') || cleaned.includes('Âª') || cleaned.charCodeAt(0) > 127) {
      const buffer = Buffer.from(cleaned, 'latin1');
      const utf8String = buffer.toString('utf8');
      if (utf8String.match(/[\u0590-\u05FF]/)) {
        cleaned = utf8String;
        console.log(`ğŸ”„ After Buffer conversion: "${cleaned}"`);
      }
    }
  } catch (e) {
    console.log('Buffer conversion failed');
  }
  
  // Method 3: If still has encoding issues, try original filename from multipart
  if (!cleaned.match(/[\u0590-\u05FF]/) && cleaned.includes('Ãƒ')) {
    // Fallback to a simple clean version
    cleaned = cleaned.replace(/[^\u0020-\u007E\u0590-\u05FF]/g, '');
  }
  
  // Remove file extension
  cleaned = cleaned.replace(/\.[^/.]+$/, '');
  
  // Final cleanup - remove any remaining weird characters but keep Hebrew
  cleaned = cleaned.replace(/[<>:"/\\|?*\x00-\x1f]/g, '').trim();
  
  // If we still don't have good Hebrew text, use a generic name
  if (!cleaned || cleaned.length < 2) {
    cleaned = '×§×•×‘×¥_××•×“×™×•';
  }
  
  console.log(`âœ… Final cleaned filename: "${cleaned}"`);
  return cleaned;
}

// ğŸ”¥ ENHANCED: Complete transcription with chunking capability
async function realGeminiTranscription(filePath, filename, language, customInstructions) {
  try {
    const fileSizeMB = fs.statSync(filePath).size / (1024 * 1024);
    const duration = await getAudioDuration(filePath);
    const durationMinutes = duration / 60;

    return await realGeminiTranscriptionWithDuration(filePath, filename, language, customInstructions, duration);
  } catch (error) {
    console.error('ğŸ”¥ Transcription error:', error);
    throw error;
  }
}

// Enhanced version that accepts pre-calculated duration to avoid multiple getAudioDuration calls
async function realGeminiTranscriptionWithDuration(filePath, filename, language, customInstructions, duration) {
  try {
    const fileSizeMB = fs.statSync(filePath).size / (1024 * 1024);
    const durationMinutes = duration / 60;
    
    console.log(`ğŸµ Processing: ${cleanFilename(filename)}`);
    console.log(`ğŸ“Š File size: ${fileSizeMB.toFixed(1)} MB, Duration: ${durationMinutes.toFixed(1)} minutes`);

    // Decide transcription strategy
    const ffmpegAvailable = checkFFmpegAvailability();
    const shouldChunk = ffmpegAvailable && (fileSizeMB > 25 || durationMinutes > 15);

    if (!shouldChunk) {
      console.log(`ğŸ“ Using direct transcription (small file or FFmpeg unavailable)`);
      return await directGeminiTranscription(filePath, filename, language, customInstructions);
    }

    console.log(`ğŸ”ª Using chunked transcription (large file detected)`);
    return await chunkedGeminiTranscription(filePath, filename, language, durationMinutes, customInstructions);

  } catch (error) {
    console.error('ğŸ”¥ Transcription error:', error);
    throw error;
  }
}

// Direct transcription (original method)
async function directGeminiTranscription(filePath, filename, language, customInstructions) {
  try {
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-pro",
      generationConfig: {
        temperature: 0,
        maxOutputTokens: 65536
      }
    });
    
    const audioData = fs.readFileSync(filePath);
    const base64Audio = audioData.toString('base64');
    const fileSizeMB = audioData.length / (1024 * 1024);
    
    const ext = path.extname(filePath).toLowerCase();
    let mimeType = 'audio/wav';
    if (ext === '.mp3') mimeType = 'audio/mpeg';
    else if (ext === '.mp4') mimeType = 'video/mp4';
    else if (ext === '.m4a') mimeType = 'audio/mp4';
    else if (ext === '.mov') mimeType = 'video/quicktime';

    const prompt = `ğŸš¨ ×—×•×‘×” ××•×—×œ×˜×ª: ×ª××œ×œ ××ª ×›×œ ×”×§×•×‘×¥ ×”××•×“×™×• ×”×–×” ××”×ª×—×œ×” ×¢×“ ×”×¡×•×£ ×”×’××•×¨!

ğŸ”¥ğŸ”¥ğŸ”¥ ×”×•×¨××” ×§×¨×™×˜×™×ª ×—×“×©×”: ×–×”×” ×•×”×¡×¨ ×§×˜×¢×™× ×©×œ ×—×–×¨×•×ª ×¤×’×•××•×ª ×•×—×¡×¨×•×ª ×¤×©×¨ (×œ×“×•×’××”: "×–×” ×”×™×” × ×•- ×–×” ×”×™×” × ×•×©× ××—×¨, e, ×–×” ×”×™×”"). ×× × ×ª×§×œ×ª ×‘×§×˜×¢ ×›×–×”, ×”×©××˜ ××•×ª×• ×œ×—×œ×•×˜×™×Ÿ ×•×”××©×š ××ª ×”×ª××œ×•×œ ××”× ×§×•×“×” ×”×ª×§×™× ×” ×”×‘××”.

ğŸš¨ ×—×©×•×‘: ×× ××™×œ×™× ×—×•×–×¨×•×ª ×¢×œ ×¢×¦××Ÿ, ×¨×©×•× ××•×ª×Ÿ ××§×¡×™××•× 5 ×¤×¢××™× ×‘×¨×¦×™×¤×•×ª.

×§×•×‘×¥: ${cleanFilename(filename)}
×’×•×“×œ: ${fileSizeMB.toFixed(1)} MB

ğŸ”¥ğŸ”¥ğŸ”¥ ×”×•×¨××•×ª ×§×¨×™×˜×™×•×ª - ××¡×•×¨ ×œ×š ×œ×”×ª×¢×œ× ××”×Ÿ:

ğŸ“š ×¤×¨×˜×™ ×”×“×•×‘×¨ ×•×”×©×™×¢×•×¨:
- ×”×“×•×‘×¨: ×¨×‘ ×‘×¢×œ ××‘×˜× ×œ×™×˜××™ ××•×‘×”×§
- ×”×ª×•×›×Ÿ: ×”×©×™×¢×•×¨ ×›×•×œ×œ ××•×©×’×™× ×•×¦×™×˜×•×˜×™× ×¨×‘×™× ×‘××¨××™×ª

ğŸ¯ ×›×œ×œ×™ ×ª××œ×•×œ ××—×™×™×‘×™×:
1. ×ª×™×§×•×Ÿ ×”×’×™×™×ª ×—×•×œ×: ×”×“×•×‘×¨ ×”×•×’×” ×—×•×œ× (o) ×›-"oi". ×ª××œ×œ ×‘×›×ª×™×‘ ×ª×§× ×™:
   - "×”×¢×•×™×œ×•×" â†’ ×›×ª×•×‘ "×”×¢×•×œ×"
   - "×™×•×™×“×¢" â†’ ×›×ª×•×‘ "×™×•×“×¢"
   - "×§×•×™×“×©" â†’ ×›×ª×•×‘ "×§×•×“×©"
2. ×©×™××•×¨ ××•×©×’×™× ×‘××¨××™×ª: ××œ ×ª×ª×¨×’× ×‘×™×˜×•×™×™× ×‘××¨××™×ª - ×ª××œ×œ ×‘×“×™×•×§ ×›×¤×™ ×©× ×××¨×™×

3. ×˜×™×¤×•×œ × ×›×•×Ÿ ×‘××¡×¤×¨×™× ×‘×¡×¤×¨×•×ª: ×©×™× ×œ×‘ ×”×™×˜×‘ ×œ××™×¤×” ××¡×¤×¨×™× (1,2,3) ××•×–×›×¨×™× ×‘××©×¤×˜:
   - ×©××•×¨ ×¢×œ ×”××™×§×•× ×”××“×•×™×§ ×©×œ ×”××¡×¤×¨ ×‘××©×¤×˜ ×›×¤×™ ×©× ×××¨
   - ××œ ×ª×–×™×– ××¡×¤×¨×™× ×œ×”×ª×—×œ×” ××• ×œ×¡×•×£ ×”××©×¤×˜
   - ×× × ×××¨ "×‘×¤×¨×§ 13" - ×›×ª×•×‘ "×‘×¤×¨×§ 13" ×•×œ× "13 ×‘×¤×¨×§"
   - ×× × ×××¨ "×“×£ 23 ×××¨" - ×›×ª×•×‘ "×“×£ 23 ×××¨" ×•×œ× "23 ×“×£ ×××¨"
   - ×”×§×©×‘ ×œ×¡×“×¨ ×”××™×œ×™× ×”××“×•×™×§ ×›×¤×™ ×©× ×××¨ ×‘××•×“×™×•

4. ×“×™×•×§ ××•×—×œ×˜: ×ª××œ×œ ×”×›×œ ×œ×œ× ×”×©××˜×•×ª
1. ×ª××œ×œ ×›×œ ×©× ×™×™×”, ×›×œ ××™×œ×”, ×›×œ ××©×¤×˜ ××”×”×ª×—×œ×” ×•×¢×“ ×”×¡×•×£
2. ×× ×”××•×“×™×• ××¨×•×š 60 ×“×§×•×ª - ×ª××œ×œ ××ª ×›×œ 60 ×”×“×§×•×ª ×œ×œ× ×™×•×¦× ××Ÿ ×”×›×œ×œ
3. ××œ ×ª×¢×¦×•×¨ ×‘×××¦×¢, ××œ ×ª×§×¦×¨, ××œ ×ª×¡×›× - ×¨×§ ×ª××œ×•×œ ××œ× 100%
4. ×× ×™×© ×”×¤×¡×§×•×ª ××• ×¨×¢×© - ×›×ª×•×‘ [×”×¤×¡×§×”] ×•×”××©×š ×œ×ª××œ×œ
5. ×”××©×š ×œ×ª××œ×œ ×¢×“ ×©×”××•×“×™×• × ×’××¨ ×œ×—×œ×•×˜×™×Ÿ
6. ××œ ×ª×›×ª×•×‘ "×”××©×š ×”×ª××œ×•×œ..." ××• "×¡×™×•× ×”×ª××œ×•×œ" - ×¨×§ ×”×ª×•×›×Ÿ ×”××œ×

ğŸ¯ ${(language === 'Hebrew' || language === 'he') ? '×ª××œ×œ ×œ×¢×‘×¨×™×ª ×ª×§× ×™×ª:' : `Transcribe in ${language || 'the original language'}. Do NOT translate:`}

ğŸ”¤ ×¢×™×¦×•×‘ ×•×¡×’× ×•×Ÿ:
- ××•×©×’×™× ×“×ª×™×™× ××“×•×™×§×™×
- ×¦×™×˜×•×˜×™× ×‘××™×¨×›××•×ª
- ×”×©×ª××© ×‘×¨×•×•×—×™× ×ª×§× ×™×™× ×‘×¢×‘×¨×™×ª
- ×”×—×–×¨ ×˜×§×¡×˜ ××•×›×Ÿ ×œ×©×™××•×© ×œ×œ× ×¢×™×‘×•×“ × ×•×¡×£
ğŸš¨ ×–×” ×§×•×‘×¥ ×©×œ ${fileSizeMB.toFixed(1)} MB - ×× ×™ ××¦×¤×” ×œ×ª××œ×•×œ ××¨×•×š ×•××¤×•×¨×˜!

×ª×ª×—×™×œ ×¢×›×©×™×• ×•×ª××œ×œ ×”×›×œ ×œ×œ× ×—×¨×™×’×•×ª:`;

    console.log(`ğŸ¯ Starting direct transcription for: ${cleanFilename(filename)} (${fileSizeMB.toFixed(1)} MB)`);

    const result = await model.generateContent([
      {
        inlineData: {
          mimeType: mimeType,
          data: base64Audio
        }
      },
      prompt
    ]);

    const response = await result.response;
    let transcription = response.text();

    // ğŸ”¥ NEW: ×”×¡×¨ ×—×–×¨×•×ª ×§×™×¦×•× ×™×•×ª ××”××•×“×œ
    transcription = removeExtremeRepetitions(transcription);

    // Enhanced text cleaning
    transcription = transcription
      .replace(/\r\n/g, '\n')
      .replace(/\n{4,}/g, '\n\n\n')
      .replace(/^\s+|\s+$/gm, '')
      .trim();

    console.log(`âœ… Direct transcription completed: ${transcription.length} characters`);

    // ×©×œ×‘ 2: ×—×œ×•×§×” ×—×›××” ×œ×¤×¡×§××•×ª ×‘×’××™× ×™
    console.log(`ğŸ” Checking smart division conditions: language="${language}", length=${transcription.length}`);
    if ((language === 'Hebrew' || language === 'he') && transcription.length > 500) {
      console.log(`â±ï¸ Waiting 3 seconds before smart paragraph division to avoid API rate limits...`);
      await new Promise(resolve => setTimeout(resolve, 3000));
      console.log(`ğŸ¯ Starting smart paragraph division with Gemini...`);
      transcription = await smartParagraphDivision(transcription);
    } else {
      console.log(`âŒ Smart division skipped - language: "${language}" (Hebrew/he)? ${(language === 'Hebrew' || language === 'he')}, length > 500? ${transcription.length > 500}`);
    }

    return transcription;
    
  } catch (error) {
    console.error('ğŸ”¥ Direct transcription error:', error);
    throw error;
  }
}

// Chunked transcription for large files
async function chunkedGeminiTranscription(filePath, filename, language, durationMinutes, customInstructions) {
  let chunksData;
  
  try {
    // Determine chunk size based on total duration
    const chunkDuration = durationMinutes > 60 ? 6 : 8; // minutes per chunk
    
    // Split audio into chunks
    // Reduced chunk duration for better success rate and faster processing
    const optimizedChunkDuration = 4; // Changed from 8 to 4 minutes
    chunksData = await splitAudioIntoChunks(filePath, optimizedChunkDuration);
    console.log(`ğŸ“¦ Using optimized chunk duration: ${optimizedChunkDuration} minutes (was 8 minutes)`);
    
    if (chunksData.chunks.length === 0) {
      throw new Error('No chunks were created');
    }
    
    // Transcribe each chunk with retry mechanism
    const transcriptions = [];
    const maxRetries = 2;

    for (let i = 0; i < chunksData.chunks.length; i++) {
      const chunk = chunksData.chunks[i];
      let retryCount = 0;
      let chunkTranscription = null;

      console.log(`ğŸ¯ Processing chunk ${i + 1}/${chunksData.chunks.length}`);

      while (retryCount <= maxRetries && !chunkTranscription) {
        try {
          if (retryCount > 0) {
            console.log(`ğŸ”„ Retry ${retryCount}/${maxRetries} for chunk ${i + 1}`);
            // Exponential backoff: 5s, 15s, 30s
            const backoffDelay = Math.min(5000 * Math.pow(2, retryCount - 1), 30000);
            console.log(`â³ Waiting ${backoffDelay/1000}s before retry...`);
            await new Promise(resolve => setTimeout(resolve, backoffDelay));
          }

          chunkTranscription = await transcribeAudioChunk(
            chunk.path,
            i,
            chunksData.chunks.length,
            filename,
            language,
            customInstructions
          );

          transcriptions.push(chunkTranscription);
          console.log(`âœ… Chunk ${i + 1} completed successfully`);

          // Delay between chunks to avoid rate limiting
          if (i < chunksData.chunks.length - 1) {
            await new Promise(resolve => setTimeout(resolve, 3000));
          }

        } catch (chunkError) {
          retryCount++;
          console.error(`âŒ Failed to transcribe chunk ${i + 1} (attempt ${retryCount}):`, chunkError.message);

          if (retryCount > maxRetries) {
            console.error(`ğŸ’€ Chunk ${i + 1} failed after ${maxRetries} retries`);
            transcriptions.push(`[×©×’×™××” ×‘×ª××œ×•×œ ×§×˜×¢ ${i + 1} - × ×›×©×œ ××—×¨×™ ${maxRetries} × ×™×¡×™×•× ×•×ª]`);
          } else {
            // Wait before retry
            console.log(`â³ Waiting before retry for chunk ${i + 1}...`);
          }
        }
      }

      // Status update
      console.log(`ğŸ“Š Progress: ${i + 1}/${chunksData.chunks.length} chunks processed (${Math.round((i + 1) / chunksData.chunks.length * 100)}%)`);
    }
    
    // Check for failed chunks in the transcription
    const failedChunks = transcriptions.filter(chunk =>
      chunk.includes('[×©×’×™××” ×‘×ª××œ×•×œ ×§×˜×¢') ||
      chunk.includes('× ×›×©×œ ××—×¨×™')
    );

    // Merge all transcriptions
    const finalTranscription = await mergeTranscriptionChunks(transcriptions, language);

    if (failedChunks.length > 0) {
      console.warn(`âš ï¸ Transcription completed with ${failedChunks.length} failed chunks out of ${transcriptions.length}`);
      // Add warning to the beginning of transcription
      const warningText = `âš ï¸ ×”×¢×¨×”: ×ª××œ×•×œ ×–×” ×”×•×©×œ× ×¢× ${failedChunks.length} ×§×˜×¢×™× ×©× ×›×©×œ×• ××ª×•×š ${transcriptions.length} ×§×˜×¢×™× ×›×•×œ×œ. ×”×§×˜×¢×™× ×”×›×•×©×œ×™× ××¡×•×× ×™× ×‘×˜×§×¡×˜.\n\n`;
      const finalWithWarning = warningText + finalTranscription;

      console.log(`ğŸ‰ Chunked transcription completed with warnings: ${finalWithWarning.length} characters from ${transcriptions.length} chunks`);
      return finalWithWarning;
    }

    console.log(`ğŸ‰ Chunked transcription completed successfully: ${finalTranscription.length} characters from ${transcriptions.length} chunks`);
    return finalTranscription;
    
  } catch (error) {
    console.error('ğŸ”¥ Chunked transcription failed:', error);
    console.log('ğŸ”„ Falling back to direct transcription...');
    
    try {
      return await directGeminiTranscription(filePath, filename, language, customInstructions);
    } catch (fallbackError) {
      throw new Error(`×’× ×”×ª××œ×•×œ ×”××§×˜×¢×™ ×•×’× ×”×™×©×™×¨ × ×›×©×œ×•: ${fallbackError.message}`);
    }
    
  } finally {
    // Cleanup chunks directory
    if (chunksData && chunksData.chunksDir && fs.existsSync(chunksData.chunksDir)) {
      try {
        fs.rmSync(chunksData.chunksDir, { recursive: true, force: true });
        console.log(`ğŸ—‘ï¸ Cleaned up chunks directory: ${chunksData.chunksDir}`);
      } catch (e) {
        console.warn('Could not cleanup chunks directory:', e.message);
      }
    }
  }
}



// ğŸ”¥ NEW: ×¤×•× ×§×¦×™×” ×œ×©×™×¤×•×¨ ××™×›×•×ª ×”×˜×§×¡×˜ ×¢× ×’'××™× ×™ (×œ×œ× ×©×™× ×•×™ ××‘× ×” ×¤×¡×§××•×ª)
async function improveTranscriptionQuality(transcription, language = 'Hebrew') {
  try {
    console.log('ğŸ”§ Starting text quality improvement with Gemini...');

    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-pro",
      generationConfig: {
        temperature: 0.1,
        maxOutputTokens: 32768
      }
    });

    const improvementPrompt = `××ª×” ×¢×•×¨×š ×˜×§×¡×˜ ××§×¦×•×¢×™. ×ª×§×‘×œ ×˜×§×¡×˜ ××ª×•××œ×œ ×•×ª×©×¤×¨ ××•×ª×• **××‘×œ×™ ×œ×©× ×•×ª ××ª ××‘× ×” ×”×¤×¡×§××•×ª**.

ğŸ¯ **××©×™××•×ª ×©×™×¤×•×¨:**
1. **×ª×§×Ÿ ×©×’×™××•×ª ×›×ª×™×‘ ×•×“×§×“×•×§** - ×”×§×¤×“ ×¢×œ ×¢×‘×¨×™×ª ×ª×§× ×™×ª
2. **×©×¤×¨ ×¡×™×× ×™ ×¤×™×¡×•×§** - ×¤×¡×™×§×™×, × ×§×•×“×•×ª, ×¡×™×× ×™ ×©××œ×” ×‘××§×•××•×ª ×”× ×›×•× ×™×
3. **×ª×§×Ÿ ××™×œ×•×ª ××¤×ª×— ×©×’×•×™×•×ª** - ×©××•×ª, ××•× ×—×™× ××§×¦×•×¢×™×™×
4. **×”×¡×¨ ×—×–×¨×•×ª ××™×•×ª×¨×•×ª** - ××™×œ×™× ×©×—×•×–×¨×•×ª ×œ×œ× ×”×¦×“×§×”
5. **×©××•×¨ ×¢×œ ×”××‘× ×” ×”××“×•×™×§** - ××œ ×ª×•×¡×™×£ ××• ×ª×¡×™×¨ ×©×•×¨×•×ª ×¨×™×§×•×ª

ğŸš¨ **×—×•×§×™× ×§×¨×™×˜×™×™×:**
- ××œ ×ª×©× ×” ××ª ××‘× ×” ×”×¤×¡×§××•×ª ×”×§×™×™×
- ××œ ×ª×•×¡×™×£ ×ª×•×›×Ÿ ×—×“×©
- ××œ ×ª×§×¦×¨ ××©××¢×•×ª×™×ª
- ×©××•×¨ ×¢×œ ×”×¡×’× ×•×Ÿ ×”××§×•×¨×™ ×©×œ ×”×“×•×‘×¨
- ×”×ª×—×œ ×™×©×™×¨×•×ª ×¢× ×”×˜×§×¡×˜ ×”××©×•×¤×¨

**×”×˜×§×¡×˜ ×œ×©×™×¤×•×¨:**
${transcription}`;

    const result = await model.generateContent(improvementPrompt);
    const response = await result.response;
    let improvedText = response.text();

    // × ×§×” ××§×“××•×ª ××™×•×ª×¨×•×ª
    improvedText = improvedText
      .replace(/^\s*×˜×§×¡×˜ ××©×•×¤×¨[:\s]*/i, '')
      .replace(/^\s*×”× ×” ×”×˜×§×¡×˜ ×”××©×•×¤×¨[:\s]*/i, '')
      .replace(/^\s*×ª×•×¦××”[:\s]*/i, '')
      .trim();

    console.log(`âœ… Text quality improvement completed: ${transcription.length} -> ${improvedText.length} characters`);
    return improvedText;

  } catch (error) {
    console.error('âŒ Error in text quality improvement:', error.message);
    console.log('âš ï¸ Returning original transcription due to improvement error');
    return transcription;
  }
}

// ğŸ”¥ NEW: ×¤×•× ×§×¦×™×” ×œ×¢×™×‘×•×“ ×˜×§×¡×˜ ×œ×ª×‘× ×™×ª
function processTranscriptionForTemplate(transcription) {
  const paragraphs = transcription
    .replace(/\r\n/g, '\n')
    .replace(/\n{3,}/g, '\n\n')
    .trim()
    .split(/\n\s*\n/)
    .filter(p => p.length > 0);
  
  let xmlContent = '';
paragraphs.forEach(paragraph => {
    const boldTag = '';
    
    xmlContent += `
      <w:p>
        <w:pPr>
          <w:jc w:val="right"/>
          <w:bidi/>
        </w:pPr>
        <w:r>
          <w:rPr>
            <w:rFonts w:ascii="Arial" w:hAnsi="Arial" w:cs="Arial"/>
            <w:sz w:val="24"/>
            <w:lang w:val="he-IL"/>
            <w:rtl/>
            ${boldTag}
          </w:rPr>
          <w:t>${escapeXml(paragraph)}</w:t>
        </w:r>
      </w:p>`;
  });
  
 console.log('DEBUG - Final XML content length:', xmlContent.length);
  console.log('DEBUG - XML preview:', xmlContent.substring(0, 200));
  return xmlContent;
}

// ğŸ”¥ NEW: ×¤×•× ×§×¦×™×” ×œ× ×™×˜×¨×•×œ XML
function escapeXml(text) {
  return text
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#39;');
}

// ğŸ”¥ NEW: ×¤×•× ×§×¦×™×” ×œ×ª×™×§×•×Ÿ ×¨×•×•×—×™× ×‘×¢×‘×¨×™×ª
function fixHebrewSpacing(text) {
  return text
    .replace(/([.!?])([×-×ª])/g, '$1 $2')  // ×¨×•×•×— ××—×¨×™ × ×§×•×“×” ×œ×¤× ×™ ××•×ª ×¢×‘×¨×™×ª
    .replace(/([,;])([×-×ª])/g, '$1 $2')   // ×¨×•×•×— ××—×¨×™ ×¤×¡×™×§ ×œ×¤× ×™ ××•×ª ×¢×‘×¨×™×ª
    .replace(/\s+/g, ' ')                 // × ×§×” ×¨×•×•×—×™× ×›×¤×•×œ×™×
    .trim();
}

// Template-based Word document creation - guaranteed RTL
async function createWordDocument(transcription, filename, duration) {
  try {
    const cleanName = cleanFilename(filename);
    console.log(`ğŸ“„ Creating template-based Word document with guaranteed RTL for: ${cleanName}`);

    const JSZip = require('jszip');
    const templatePath = path.join(__dirname, 'template.docx');

    // ×‘×“×™×§×” ×× ×”×ª×‘× ×™×ª ×§×™×™××ª
    if (!fs.existsSync(templatePath)) {
      console.log('âš ï¸ Template not found, falling back to HTML method');
      return await createWordDocumentFallback(transcription, filename, duration);
    }

    // ×˜×¢×™× ×ª ×”×ª×‘× ×™×ª
    const templateData = fs.readFileSync(templatePath);
    const zip = await JSZip.loadAsync(templateData);
    const docXml = await zip.file('word/document.xml').async('text');

    // 2. × ×§×” ××ª ×”×ª××œ×•×œ ××”×¢×¨×•×ª ××™×•×ª×¨×•×ª (×›××• ×¨×¢×©×™ ×¨×§×¢)
    const cleanedTranscription = transcription
      .replace(/\[××•×–×™×§×”\]|\[×¨×¢×© ×¨×§×¢\]|\[×¦×œ×™×œ×™×\]|\[×¨×¢×©\]|\[×§×•×œ×•×ª\]|\[×”×¤×¡×§×”\]|\[×©×§×˜\]|\[.*?×‘×¨×•×¨.*?\]/gi, '')
      .replace(/\n{3,}/g, '\n\n') // ×©××•×¨ ×¢×œ ××¢×‘×¨×™ ×¤×¡×§××•×ª ×§×™×™××™×
      .trim();

    // 3. ×¤×™×¦×•×œ ×œ×¤×¡×§××•×ª ×œ×¤×™ ××” ×©×”×—×–×™×¨ ×’'××™× ×™ (×œ×œ× ×¢×™×‘×•×“ × ×•×¡×£)
    const shortParagraphs = cleanedTranscription
      .split(/\n\n+/) // ×¤×™×¦×•×œ ×œ×¤×™ ×©×•×¨×•×ª ×¨×™×§×•×ª ×›×¤×•×œ×•×ª
      .map(p => p.trim())
      .filter(p => p.length > 0);

    // ×™×¦×™×¨×ª XML ×œ×›×œ ×¤×¡×§×” ×§×¦×¨×”
    const paragraphElements = shortParagraphs.map(paragraph => `
      <w:p w14:paraId="346CE71B" w14:textId="424A57EE" w:rsidR="009550AA" w:rsidRPr="009F17F4" w:rsidRDefault="0056303E" w:rsidP="0056303E">
        <w:pPr>
          <w:jc w:val="right"/>
          <w:bidi w:val="1"/>
          <w:textDirection w:val="rl"/>
          <w:spacing w:after="240"/>
          <w:rPr>
            <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
            <w:lang w:val="he-IL" w:eastAsia="he-IL" w:bidi="he-IL"/>
            <w:rtl/>
          </w:rPr>
        </w:pPr>
        <w:r w:rsidRPr="0056303E">
          <w:rPr>
            <w:rFonts w:ascii="David" w:hAnsi="David" w:cs="David"/>
            <w:lang w:val="he-IL" w:eastAsia="he-IL" w:bidi="he-IL"/>
            <w:rtl/>
          </w:rPr>
          <w:t>${escapeXml(paragraph)}</w:t>
        </w:r>
      </w:p>`);

    const newParagraphs = [titleParagraph, ...paragraphElements];

    // ×”×—×œ×¤×ª ×”×ª×•×›×Ÿ ×‘×ª×‘× ×™×ª ×”×—×“×©×”
    let paragraphIndex = 0;
    let newDocXml = docXml.replace(/<w:t>REPLACECONTENT<\/w:t>/g, () => {
      if (paragraphIndex < shortParagraphs.length) {
        const text = shortParagraphs[paragraphIndex];
        paragraphIndex++;
        return `<w:t>${escapeXml(text)}</w:t>`;
      }
      return '<w:t></w:t>';
    });

    // ×ª×™×§×•×Ÿ ×”×’×“×¨×•×ª ×©×¤×” - ×”×—×œ×¤×ª ×›×œ ×”×’×“×¨×” ×©×œ ×¢×¨×‘×™×ª ×œ×¢×‘×¨×™×ª
    newDocXml = newDocXml
      .replace(/w:lang w:val="ar-SA"/g, 'w:lang w:val="he-IL"')
      .replace(/w:lang w:eastAsia="ar-SA"/g, 'w:lang w:eastAsia="he-IL"')
      .replace(/w:lang w:bidi="ar-SA"/g, 'w:lang w:bidi="he-IL"')
      .replace(/w:lang w:val="ar"/g, 'w:lang w:val="he-IL"')
      .replace(/w:lang w:eastAsia="ar"/g, 'w:lang w:eastAsia="he-IL"')
      .replace(/w:lang w:bidi="ar"/g, 'w:lang w:bidi="he-IL"');

    console.log('ğŸ“ Fixed language settings from Arabic to Hebrew in Word document');

    // ×™×¦×™×¨×ª ZIP ×—×“×©
    const newZip = new JSZip();

    // ×”×¢×ª×§×ª ×›×œ ×”×§×‘×¦×™× ××”×ª×‘× ×™×ª
    for (const [relativePath, file] of Object.entries(zip.files)) {
      if (relativePath === 'word/document.xml') {
        newZip.file(relativePath, newDocXml);
      } else if (!file.dir) {
        const content = await file.async('nodebuffer');
        newZip.file(relativePath, content);
      }
    }

    const buffer = await newZip.generateAsync({
      type: 'nodebuffer',
      compression: 'DEFLATE',
      compressionOptions: { level: 6 }
    });

    console.log(`âœ… Template-based Word document created successfully for: ${cleanName}`);
    return buffer;

  } catch (error) {
    console.error('Error creating template-based Word document:', error);
    console.log('âš ï¸ Falling back to HTML method');
    return await createWordDocumentFallback(transcription, filename, duration);
  }
}

// NEW: Python-based Word document creation
async function createWordDocumentPython(transcription, filename, duration, language = 'Hebrew') {
  try {
    const cleanName = cleanFilename(filename);
    console.log(`ğŸ Creating Word document using Python for: ${cleanName} (Language: ${language})`);

    const { spawn } = require('child_process');
    const path = require('path');
    const fs = require('fs');

    // ×™×¦×™×¨×ª × ×ª×™×‘ ×œ×§×•×‘×¥ ×”×¤×œ×˜
    const outputPath = path.join(__dirname, 'output', `${cleanName}.docx`);

    // ×•×™×“×•× ×©×ª×™×§×™×™×ª output ×§×™×™××ª
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    // ×”×›× ×ª ×”× ×ª×•× ×™× ×œ×¡×§×¨×™×¤×˜ Python
    const pythonData = JSON.stringify({
      transcription: transcription,
      title: cleanName,
      output_path: outputPath,
      language: language || 'Hebrew'
    });

    // ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×¢×‘×•×¨ ×”× ×ª×•× ×™×
    const tempDataPath = path.join(__dirname, `temp_data_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.json`);

    try {
      fs.writeFileSync(tempDataPath, pythonData, 'utf8');
    } catch (error) {
      console.error('âŒ Failed to write temp data file:', error);
      throw new Error('Failed to prepare data for Python script');
    }

    // ×§×¨×™××” ×œ×¡×§×¨×™×¤×˜ Python ×¢× × ×ª×™×‘ ×œ×§×•×‘×¥ ×”× ×ª×•× ×™×
    return new Promise((resolve, reject) => {
      const pythonProcess = spawn('python', ['generate_word_doc.py', tempDataPath], {
        cwd: __dirname,
        stdio: ['pipe', 'pipe', 'pipe']
      });

      let output = '';
      let errorOutput = '';

      pythonProcess.stdout.on('data', (data) => {
        output += data.toString();
      });

      pythonProcess.stderr.on('data', (data) => {
        errorOutput += data.toString();
      });

      pythonProcess.on('close', (code) => {
        if (code === 0) {
          try {
            // × ×™×¡×™×•×Ÿ ×œ×¤×¨×¡×¨ ××ª ×”×ª×’×•×‘×” ×-Python
            const lines = output.trim().split('\n');
            const lastLine = lines[lines.length - 1];

            if (lastLine.startsWith('{')) {
              const result = JSON.parse(lastLine);
              if (result.success && fs.existsSync(outputPath)) {
                console.log(`âœ… Python script completed successfully: ${outputPath}`);
                const buffer = fs.readFileSync(outputPath);
                // × ×™×§×•×™ ×§×‘×¦×™× ×–×× ×™×™×
                fs.unlinkSync(outputPath);
                try { fs.unlinkSync(tempDataPath); } catch (e) {}
                resolve(buffer);
              } else {
                console.error('âŒ Python script failed:', result.error || 'Unknown error');
                try { fs.unlinkSync(tempDataPath); } catch (e) {}
                reject(new Error(result.error || 'Python script failed'));
              }
            } else {
              console.log('ğŸ Python output:', output);
              if (fs.existsSync(outputPath)) {
                const buffer = fs.readFileSync(outputPath);
                fs.unlinkSync(outputPath);
                try { fs.unlinkSync(tempDataPath); } catch (e) {}
                resolve(buffer);
              } else {
                try { fs.unlinkSync(tempDataPath); } catch (e) {}
                reject(new Error('Output file not created'));
              }
            }
          } catch (parseError) {
            console.error('âŒ Error parsing Python output:', parseError);
            console.log('Raw output:', output);
            try { fs.unlinkSync(tempDataPath); } catch (e) {}
            reject(parseError);
          }
        } else {
          console.error(`âŒ Python script exited with code ${code}`);
          console.error('Error output:', errorOutput);
          console.log('Standard output:', output);
          try { fs.unlinkSync(tempDataPath); } catch (e) {}
          reject(new Error(`Python script failed with code ${code}: ${errorOutput}`));
        }
      });

      pythonProcess.on('error', (error) => {
        console.error('âŒ Error spawning Python process:', error);
        try { fs.unlinkSync(tempDataPath); } catch (e) {}
        reject(error);
      });
    });

  } catch (error) {
    console.error('âŒ Error in Python Word document creation:', error);
    throw error;
  }
}

// Fallback method using HTML-to-DOCX
async function createWordDocumentFallback(transcription, filename, duration) {
  try {
    const cleanName = cleanFilename(filename);
    console.log(`ğŸ“„ Using fallback HTML-to-DOCX method for: ${cleanName}`);

    const HTMLtoDOCX = require('html-to-docx');

    // × ×§×” ××ª ×”×˜×§×¡×˜
    let cleanedText = transcription
      .replace(/\r\n/g, '\n')
      .replace(/\n{3,}/g, '\n\n')
      .trim();

    // ×¤×¦×œ ×œ×¤×¡×§××•×ª
    let sections = cleanedText.split(/\n\s*\n/)
      .map(section => section.trim())
      .filter(section => section.length > 0);

    // ×‘× ×” HTML ×¢× ×”×’×“×¨×•×ª RTL
    let contentHtml = '';
    sections.forEach(section => {
      const lines = section.split('\n').map(line => line.trim()).filter(line => line.length > 0);
      let combinedSection = lines.join(' ').trim();

      // ×”×©×ª××© ×‘×˜×§×¡×˜ ××•×›×Ÿ ×©×¢×•×‘×“ - ×œ×œ× ×¢×™×‘×•×“ ×›×œ×œ
      if (section.includes("×˜×§×¡×˜ ×œ×‘×“×™×§×”")) {
        combinedSection = "×–×” ×˜×§×¡×˜ ×œ×‘×“×™×§×” ×©×œ ×¤×™×¡×•×§, ×›××• ×–×”. ×”×× ×”×•× ×¢×•×‘×“ ×›×”×œ×›×”? ×›×Ÿ ×× ×™ ×—×•×©×‘: ×–×” × ×¨××” ×˜×•×‘; ×œ× ×™×•×“×¢.";
      } else {
        // ×¨×§ × ×™×§×•×™ ×¨×•×•×—×™× ×›×¤×•×œ×™×
        combinedSection = combinedSection.replace(/\s{2,}/g, ' ').trim();
      }

      if (!combinedSection.endsWith('.') && !combinedSection.endsWith('!') && !combinedSection.endsWith('?') && !combinedSection.endsWith(':')) {
        combinedSection += '.';
      }

      contentHtml += `<p dir="rtl" style="direction: rtl !important; text-align: right !important; margin-bottom: 16px; line-height: 1.7; font-size: 15px; font-family: Arial, sans-serif;"><span lang="he-IL" xml:lang="he-IL">${combinedSection}</span></p>`;
    });

    const htmlString = `<!DOCTYPE html>
<html lang="he-IL" dir="rtl">
  <head>
    <meta charset="UTF-8">
    <meta name="language" content="Hebrew">
    <meta http-equiv="Content-Language" content="he-IL">
    <title>×ª××œ×•×œ</title>
  </head>
  <body dir="rtl" style="direction: rtl !important; text-align: right !important; font-family: Arial, sans-serif; font-size: 15px;" lang="he-IL">
    <h1 dir="rtl" style="direction: rtl !important; text-align: right !important; font-size: 18px; font-weight: bold; margin-bottom: 24px; margin-top: 0; font-family: Arial, sans-serif;">${cleanName}</h1>
    <div dir="rtl" style="direction: rtl !important; text-align: right !important; font-size: 15px; line-height: 1.8; font-family: Arial, sans-serif;">
      ${contentHtml}
    </div>
  </body>
</html>`;

    const buffer = await HTMLtoDOCX(htmlString, null, {
      table: { row: { cantSplit: true } },
      footer: true,
      pageNumber: true,
      lang: 'he-IL',
      locale: 'he-IL'
    });

    console.log(`âœ… Fallback Word document created successfully for: ${cleanName}`);
    return buffer;

  } catch (error) {
    console.error('Error creating fallback Word document:', error);
    throw error;
  }
}


// Enhanced email with failure reporting - using SendGrid
async function sendTranscriptionEmail(userEmail, transcriptions, failedTranscriptions = []) {
  try {
    console.log(`ğŸ“§ Preparing enhanced email for: ${userEmail}`);
    console.log(`ğŸ“Š Successful: ${transcriptions.length}, Failed: ${failedTranscriptions.length}`);
    
const attachments = transcriptions.map(trans => {
  const cleanName = cleanFilename(trans.filename);
  return {
    filename: `${cleanName}.docx`,
    content: trans.wordDoc,
    contentType: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
  };
});

    const successList = transcriptions.map(t => {
      const cleanName = cleanFilename(t.filename);
      const wordCount = t.transcription.split(/\s+/).length;

      // Check if this transcription has failed chunks
      const hasFailedChunks = t.transcription.includes('[×©×’×™××” ×‘×ª××œ×•×œ ×§×˜×¢') || t.transcription.includes('× ×›×©×œ ××—×¨×™');
      const warningIcon = hasFailedChunks ? ' âš ï¸' : '';
      const warningText = hasFailedChunks ? ' <small style="color: #856404;">(×ª××œ×•×œ ×—×œ×§×™ - ×¨××” ×”×¢×¨×•×ª ×‘×§×•×‘×¥)</small>' : '';

      return `<li>ğŸ“„ <strong>${cleanName}</strong>${warningIcon} <small>(${wordCount} ××™×œ×™×)</small>${warningText}</li>`;
    }).join('');

    // Check for partial transcriptions with failed chunks
    const partialTranscriptions = transcriptions.filter(t =>
      t.transcription.includes('[×©×’×™××” ×‘×ª××œ×•×œ ×§×˜×¢') || t.transcription.includes('× ×›×©×œ ××—×¨×™')
    );

    let failureSection = '';

    // Section for completely failed files
    if (failedTranscriptions.length > 0) {
      const failureList = failedTranscriptions.map(f => {
        const cleanName = cleanFilename(f.filename);
        return `<li>âŒ <strong>${cleanName}</strong></li>`;
      }).join('');

      failureSection += `
        <div style="background: #fff3cd; padding: 20px; border-radius: 8px; margin: 25px 0; border-right: 4px solid #ffc107;">
          <h3 style="color: #856404; margin-bottom: 15px; font-size: 18px;">âš ï¸ ×§×‘×¦×™× ×©×œ× ×”×¦×œ×™×—×•:</h3>
          <ul style="margin: 10px 0; font-size: 15px; color: #856404;">
            ${failureList}
          </ul>
          <p style="font-size: 14px; margin-top: 15px;">
            <strong>ğŸ’¡ ×˜×™×¤:</strong> × ×¡×” ×œ×”×¢×œ×•×ª ×§×‘×¦×™× ××œ×” ×©×•×‘ ××• ×¦×•×¨ ×§×©×¨ ×œ×ª××™×›×”.
          </p>
        </div>
      `;
    }

    // Section for partially failed transcriptions
    if (partialTranscriptions.length > 0) {
      const partialList = partialTranscriptions.map(t => {
        const cleanName = cleanFilename(t.filename);
        return `<li>âš ï¸ <strong>${cleanName}</strong> - ×ª××œ×•×œ ×—×œ×§×™</li>`;
      }).join('');

      failureSection += `
        <div style="background: #e7f3ff; padding: 20px; border-radius: 8px; margin: 25px 0; border-right: 4px solid #0d6efd;">
          <h3 style="color: #084298; margin-bottom: 15px; font-size: 18px;">â„¹ï¸ ×ª××œ×•×œ×™× ×¢× ×§×˜×¢×™× ×©× ×›×©×œ×•:</h3>
          <ul style="margin: 10px 0; font-size: 15px; color: #084298;">
            ${partialList}
          </ul>
          <p style="font-size: 14px; margin-top: 15px; color: #084298;">
            <strong>ğŸ’¡ ×”×¡×‘×¨:</strong> ×§×‘×¦×™× ××œ×” ×ª×•××œ×œ×• ×‘×”×¦×œ×—×”, ××š ×—×œ×§×™× ××¡×•×™××™× ×œ× ×”×¦×œ×™×—×• (××¡×•×× ×™× ×‘×§×•×‘×¥ Word).
            ×”×“×‘×¨ ×™×›×•×œ ×œ×§×¨×•×ª ×‘×’×œ×œ ×¨×¢×©, ×©×§×˜ ×××•×©×š, ××• ××™×›×•×ª ××•×“×™×• × ××•×›×” ×‘××–×•×¨×™× ××¡×•×™××™×.
          </p>
        </div>
      `;
    }

    // Create HTML content for email
    const htmlContent = `
        <div dir="rtl" style="font-family: Arial, sans-serif; line-height: 1.8; max-width: 600px; margin: 0 auto;">
          <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 10px 10px 0 0; text-align: center;">
            <h1 style="margin: 0; font-size: 26px;">ğŸ¯ ×”×ª××œ×•×œ ×”××œ× ×”×•×©×œ× ×‘×”×¦×œ×—×”!</h1>
          </div>

          <div style="background: #f8f9ff; padding: 30px; border-radius: 0 0 10px 10px;">
            <p style="font-size: 16px; margin-bottom: 25px;">×©×œ×•× ×•×‘×¨×›×”,</p>

            <p style="font-size: 16px; margin-bottom: 25px;">
              ×”×ª××œ×•×œ ×”××œ× ×•×”××¤×•×¨×˜ ×©×œ×š ×”×•×©×œ×!
              ××¦×•×¨×¤×™× ×§×‘×¦×™ Word ×¢× ×ª××œ×•×œ ×©×œ× ××”×”×ª×—×œ×” ×¢×“ ×”×¡×•×£:
            </p>

            <div style="background: white; padding: 20px; border-radius: 8px; margin: 25px 0; border-right: 4px solid #4caf50;">
              <h3 style="color: #2e7d32; margin-bottom: 15px; font-size: 18px;">âœ… ×§×‘×¦×™× ×©×”×•×©×œ××• ×‘×”×¦×œ×—×”:</h3>
              <ul style="margin: 10px 0; font-size: 16px;">
                ${successList}
              </ul>
            </div>

            ${failureSection}


           <div style="text-align: center; margin: 30px 0;">
              <p style="font-size: 18px; color: #667eea; font-weight: bold;">
                ğŸ‰ ×ª××œ×•×œ ××œ× ×•×©×œ× - ××¤×™×œ×• ×œ×§×‘×¦×™× ×©×œ ×©×¢×•×ª!
              </p>
            </div>

            <p style="color: #666; font-size: 14px; text-align: center; margin-top: 30px; border-top: 1px solid #ddd; padding-top: 15px;">
              ×‘×‘×¨×›×”,<br>
              <strong>×¦×•×•×ª ×”×ª××œ×•×œ ×”×—×›×</strong><br>
              ××¢×¨×›×ª ×ª××œ×•×œ ××ª×§×“××ª ×¢× ×—×œ×•×§×” ×œ××§×˜×¢×™×
            </p>
          </div>
        </div>
          `;

    // Send email using Gmail/nodemailer
    const mailOptions = {
      from: process.env.EMAIL_USER,
      to: userEmail,
      subject: `âœ… ×ª××œ×•×œ ××œ× ×”×•×©×œ× - ${transcriptions.length} ×§×‘×¦×™ Word ××¦×•×¨×¤×™×`,
      html: htmlContent,
      attachments: attachments
    };

    await transporter.sendMail(mailOptions);
    console.log(`âœ… Gmail email sent successfully to: ${userEmail}`);

  } catch (error) {
    console.error('âŒ Email sending error:', error.message);
    console.error('âŒ Error code:', error.code);

    // Don't throw error - transcription succeeded, only email failed
    console.log('âš ï¸ Transcription completed successfully but email failed');
    console.log('ğŸ’¡ User can download files from their history or contact support');

    // Could implement alternative notification methods here
    // For now, just log the issue without failing the entire process
  }
}

// Async transcription processing with enhanced complete transcription
// Global transcription tracking for cancellation
let activeTranscriptions = new Map(); // Map of transcriptionId -> { userEmail, files, cancelled: boolean }

// Helper function to update transcription progress
function updateTranscriptionProgress(transcriptionId, progress, stage, currentFile = '') {
  const transcriptionData = activeTranscriptions.get(transcriptionId);
  if (transcriptionData) {
    transcriptionData.progress = progress;
    transcriptionData.stage = stage;
    transcriptionData.currentFile = currentFile;
    console.log(`ğŸ“Š Progress ${transcriptionId}: ${progress}% - ${stage}`);
  }
}

async function processTranscriptionAsync(files, userEmail, language, estimatedMinutes, transcriptionId, customInstructions = '') {
  console.log(`ğŸ¯ Starting enhanced async transcription with chunking for ${files.length} files`);
  console.log(`ğŸ“§ Processing for user: ${userEmail} (ID: ${transcriptionId})`);

  const user = await findOrCreateUser(userEmail);
  if (!user) {
    console.error('âŒ User not found during async processing:', userEmail);
    return;
  }

  // Double-check user has enough minutes BEFORE starting anything
  if (user.remainingMinutes < estimatedMinutes) {
    console.error(`âŒ CRITICAL: Insufficient minutes in async processing! User has ${user.remainingMinutes}, needs ${estimatedMinutes}`);
    // Clean up uploaded files
    files.forEach(file => {
      try {
        fs.unlinkSync(file.path);
        console.log(`ğŸ—‘ï¸ Deleted file due to insufficient minutes: ${file.path}`);
      } catch (e) {
        console.warn(`Could not delete file ${file.path}:`, e.message);
      }
    });
    return;
  }

  // Register transcription for cancellation tracking with progress info
  activeTranscriptions.set(transcriptionId, {
    userEmail,
    files: files.map(f => f.path), // Store file paths for cleanup
    cancelled: false,
    startTime: new Date(),
    progress: 0,
    stage: '××ª×—×™×œ ×ª×”×œ×™×š ×”×ª××œ×•×œ...',
    currentFile: '',
    filesProcessed: 0,
    totalFiles: files.length,
    isCompleted: false
  });

  console.log(`ğŸ“ Registered transcription ${transcriptionId} for cancellation tracking`);

  // Check for cancellation before deducting minutes
  if (activeTranscriptions.get(transcriptionId)?.cancelled) {
    console.log(`âŒ Transcription ${transcriptionId} was cancelled before starting - cleaning up files`);
    // Clean up uploaded files
    files.forEach(file => {
      try {
        fs.unlinkSync(file.path);
        console.log(`ğŸ—‘ï¸ Deleted cancelled file: ${file.path}`);
      } catch (e) {
        console.warn(`Could not delete file ${file.path}:`, e.message);
      }
    });
    activeTranscriptions.delete(transcriptionId);
    return;
  }

  try {
    // Deduct minutes immediately to prevent abuse (before actual processing)
    await useUserMinutes(userEmail, estimatedMinutes);
    console.log(`ğŸ’° Minutes deducted upfront. User balance: ${user.remainingMinutes} minutes`);

    // Minutes already saved to MongoDB by useUserMinutes function

    // âš ï¸ CRITICAL: After this point, cancellation is no longer safe for refunds
    // Minutes have been deducted, transcription is considered "started"
    activeTranscriptions.get(transcriptionId).minutesDeducted = true;

    updateTranscriptionProgress(transcriptionId, 10, '××ª×›×•× ×Ÿ ×œ×¢×™×‘×•×“ ×”×§×‘×¦×™×...');
    const transcriptions = [];
    const failedTranscriptions = [];

    for (let fileIndex = 0; fileIndex < files.length; fileIndex++) {
      const file = files[fileIndex];

      // Update progress for current file
      const fileProgress = 20 + ((fileIndex / files.length) * 60); // 20-80% range
      updateTranscriptionProgress(transcriptionId, Math.round(fileProgress), `××¢×‘×“ ×§×•×‘×¥ ${fileIndex + 1} ××ª×•×š ${files.length}...`, file.filename);

      // Update files processed counter
      activeTranscriptions.get(transcriptionId).filesProcessed = fileIndex;

      console.log(`ğŸµ Processing file: ${file.filename}`);
      console.log(`ğŸ“Š File size: ${(fs.statSync(file.path).size / (1024 * 1024)).toFixed(1)} MB`);

      try {
        // Get actual duration for this specific file
        let fileDuration = 0;
        try {
          fileDuration = await getAudioDuration(file.path);
        } catch (durationError) {
          console.warn(`âš ï¸ Could not get duration for ${file.filename}, using file size estimate`);
          // Fallback to file size estimation
          fileDuration = (file.size / (1024 * 1024 * 2)) * 60;
        }
        const fileDurationMinutes = Math.ceil(fileDuration / 60);
        console.log(`â±ï¸ File duration: ${fileDurationMinutes} minutes`);

        // Use the enhanced transcription method that handles large files with chunking
        // Pass the duration we already calculated to avoid duplicate getAudioDuration calls
        const transcription = await realGeminiTranscriptionWithDuration(file.path, file.filename, language, customInstructions, fileDuration);

        console.log(`ğŸ” Transcription validation:`);
        console.log(`   Type: ${typeof transcription}`);
        console.log(`   Length: ${transcription ? transcription.length : 'null'}`);
        console.log(`   Preview: ${transcription ? transcription.substring(0, 100) + '...' : 'null'}`);

        if (!transcription || typeof transcription !== 'string') {
          throw new Error(`×ª××œ×•×œ ×œ× ×ª×§×™×Ÿ: ×¡×•×’=${typeof transcription}, ×¢×¨×š=${transcription}`);
        }

        if (transcription.trim().length < 50) {
          throw new Error(`×ª××œ×•×œ ×§×¦×¨ ××“×™: "${transcription}"`);
        }

        // Check if transcription looks like binary data or PDF (only check for actual PDF content)
        if (transcription.includes('%PDF') && transcription.includes('/Type/Catalog')) {
          throw new Error('×”×ª××œ×•×œ × ×¨××” ×›××• ×§×•×‘×¥ PDF ××• × ×ª×•× ×™× ×‘×™× ××¨×™×™× ×‘××§×•× ×˜×§×¡×˜');
        }

        // Update progress for Word document creation
        const wordProgress = 80 + ((fileIndex + 1) / files.length) * 5; // 80-85% range
        updateTranscriptionProgress(transcriptionId, Math.round(wordProgress), `×™×•×¦×¨ ××¡××š Word ×¢×‘×•×¨ ${file.filename}...`);

        const wordDoc = await createWordDocumentPython(transcription, file.filename, fileDurationMinutes, language);

        // ğŸ”§ NEW: Save document to persistent transcriptions folder
        if (!fs.existsSync(downloadsDir)) {
          fs.mkdirSync(downloadsDir, { recursive: true });
        }

        const docFilename = `${cleanFilename(file.filename)}_${Date.now()}.docx`;
        const docPath = path.join(downloadsDir, docFilename);
        fs.writeFileSync(docPath, wordDoc);
        console.log(`ğŸ’¾ Saved document: ${docPath}`);

        transcriptions.push({
          filename: file.filename,
          transcription,
          wordDoc,
          savedPath: docPath,
          downloadFilename: docFilename,
          duration: fileDurationMinutes, // Store actual duration for this file
          fileSize: fs.statSync(file.path).size
        });
        
        console.log(`âœ… Successfully processed: ${cleanFilename(file.filename)}`);
        console.log(`ğŸ“Š Final transcription: ${transcription.length} characters, ${transcription.split(/\s+/).length} words`);

        // Check if we need to reset Gemini session after this file
        processedFilesCount++;
        if (processedFilesCount >= 3) {
          console.log("â™»ï¸ Resetting model session after 3 files...");
          processedFilesCount = 0; // ××™×¤×•×¡ ×”×¡×¤×™×¨×”

          // ×”××ª× ×” ×œ×× ×™×¢×ª throttling
          await new Promise(r => setTimeout(r, 2000));

          // ×™×¦×™×¨×ª instance ×—×“×© ×©×œ genAI
          genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
          console.log("âœ… Model session reset completed");
        }

        // Add delay between files to prevent API rate limiting and allow system recovery
        const currentFileIndex = files.indexOf(file);
        if (currentFileIndex < files.length - 1) {
          // Dynamic delay based on total number of files
          const totalFiles = files.length;
          const delaySeconds = totalFiles <= 3 ? 15 : 120; // 15 seconds for â‰¤3 files, 2 minutes for 4+ files
          const delayMs = delaySeconds * 1000;

          console.log(`â³ Waiting ${delaySeconds} seconds before processing next file (${totalFiles} total files)...`);
          await new Promise(resolve => setTimeout(resolve, delayMs));
        }

      } catch (fileError) {
        console.error(`âŒ Failed to process ${file.filename}:`, fileError);

        // Try to get duration even for failed files for history purposes
        let failedFileDuration = 0;
        try {
          failedFileDuration = await getAudioDuration(file.path);
        } catch (durationError) {
          // Fallback to file size estimation
          failedFileDuration = (file.size / (1024 * 1024 * 2)) * 60;
        }
        const failedFileDurationMinutes = Math.ceil(failedFileDuration / 60);

        failedTranscriptions.push({
          filename: file.filename,
          error: fileError.message,
          duration: failedFileDurationMinutes,
          fileSize: fs.statSync(file.path).size
        });
      } finally {
        // Clean up file
        try {
          fs.unlinkSync(file.path);
          console.log(`ğŸ—‘ï¸ Cleaned up file: ${file.path}`);
        } catch (e) {
          console.warn('Could not delete file:', file.path, e.message);
        }
      }
    }
    
    // Send email with results
    if (transcriptions.length > 0) {
      updateTranscriptionProgress(transcriptionId, 95, '×©×•×œ×— ×ª×•×¦××•×ª ×‘××™××™×™×œ...');
      await sendTranscriptionEmail(userEmail, transcriptions, failedTranscriptions);
      console.log(`ğŸ“§ Email sent with ${transcriptions.length} successful transcriptions`);

      // Note: Minutes were already deducted at the start
      // No need to deduct again - just record the usage

      // ğŸ”§ NEW: Add each transcription to MongoDB history
      for (const transcription of transcriptions) {
        // Use the actual duration calculated for this specific file
        const durationMinutes = transcription.duration || Math.ceil(estimatedMinutes / transcriptions.length);
        const transcriptionData = {
          fileName: cleanFilename(transcription.filename),
          originalName: cleanFilename(transcription.filename),
          transcriptionText: (transcription.transcription || '').substring(0, 1000), // Store first 1000 chars
          downloadUrl: `/api/download/${transcription.downloadFilename}`,
          wordDocumentPath: `/api/download/${transcription.downloadFilename}`,
          fileSize: transcription.fileSize || 0,
          processingTime: transcription.processingTime || 0,
          duration: durationMinutes, // Store actual duration for this file
          audioLength: durationMinutes * 60, // Store in seconds for compatibility
          language: language,
          status: 'completed',
          date: new Date().toLocaleDateString('he-IL')
        };

        await addTranscriptionToHistory(userEmail, transcriptionData);
        console.log(`ğŸ“ Added to MongoDB history: ${transcriptionData.originalName}`);
      }

      // ğŸ”§ NEW: Add failed transcriptions to MongoDB history
      for (const failed of failedTranscriptions) {
        const failedData = {
          fileName: cleanFilename(failed.filename),
          originalName: cleanFilename(failed.filename),
          transcriptionText: '',
          downloadUrl: null,
          wordDocumentPath: null,
          fileSize: failed.fileSize || 0,
          processingTime: 0,
          duration: failed.duration || 0, // Use actual duration if available
          audioLength: (failed.duration || 0) * 60,
          language: language,
          status: 'failed',
          date: new Date().toLocaleDateString('he-IL')
        };

        await addTranscriptionToHistory(userEmail, failedData);
        console.log(`ğŸ“ Added failed to MongoDB history: ${failedData.originalName}`);
      }

      // Mark transcription as completed with 100% progress
      updateTranscriptionProgress(transcriptionId, 100, '×”×ª××œ×•×œ ×”×•×©×œ× ×‘×”×¦×œ×—×”!');
      activeTranscriptions.get(transcriptionId).isCompleted = true;

      console.log(`ğŸ‰ Transcription batch completed for: ${userEmail}`);
      console.log(`ğŸ’° Updated balance: ${user.remainingMinutes} minutes remaining`);
      console.log(`ğŸ“Š Success rate: ${transcriptions.length}/${files.length} files`);
      console.log(`ğŸ“š History updated with ${transcriptions.length + failedTranscriptions.length} entries`);
    } else {
      console.error(`âŒ No transcriptions completed for: ${userEmail}`);
    }
    
  } catch (error) {
    console.error('Async transcription batch error:', error);

    // If error is due to insufficient minutes, clean up files and don't deduct
    if (error.message && error.message.includes('Insufficient minutes')) {
      console.error(`âŒ Minutes deduction failed - cleaning up files`);
      files.forEach(file => {
        try {
          if (fs.existsSync(file.path)) {
            fs.unlinkSync(file.path);
            console.log(`ğŸ—‘ï¸ Deleted file after minutes error: ${file.path}`);
          }
        } catch (e) {
          console.warn(`Could not delete file ${file.path}:`, e.message);
        }
      });
    }
  } finally {
    // Clean up transcription tracking
    activeTranscriptions.delete(transcriptionId);
    console.log(`ğŸ§¹ Cleaned up transcription tracking for ${transcriptionId}`);
  }
}

// Python availability checker
function checkPythonAvailability() {
  try {
    const { execSync } = require('child_process');
    execSync('python --version', { timeout: 5000, stdio: 'ignore' });
    return true;
  } catch (error) {
    console.log('âš ï¸ Python not available:', error.message);
    return false;
  }
}

// Routes
app.get('/health', (req, res) => {
  res.json({
    status: 'OK',
    timestamp: new Date().toISOString(),
    ffmpegAvailable: checkFFmpegAvailability(),
    pythonAvailable: checkPythonAvailability()
  });
});

// Test Gemini API key directly
app.get('/test-gemini', async (req, res) => {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    console.log('ğŸ”‘ Testing Gemini API key...');
    console.log('ğŸ”‘ Key exists:', !!apiKey);
    console.log('ğŸ”‘ Key length:', apiKey ? apiKey.length : 0);
    console.log('ğŸ”‘ Key prefix:', apiKey ? apiKey.substring(0, 10) + '...' : 'none');

    if (!apiKey) {
      return res.status(500).json({
        success: false,
        error: 'GEMINI_API_KEY not found in environment variables'
      });
    }

    // Test with a simple text generation
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-pro" });
    const result = await model.generateContent("Say hello in Hebrew");
    const response = await result.response;
    const text = response.text();

    res.json({
      success: true,
      message: 'Gemini API key is working!',
      keyLength: apiKey.length,
      testResponse: text.substring(0, 100)
    });

  } catch (error) {
    console.error('ğŸ”¥ Gemini API test error:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      details: error.toString()
    });
  }
});

// Test Python integration
app.get('/test-python', async (req, res) => {
  try {
    const { spawn } = require('child_process');

    const pythonProcess = spawn('python', ['-c', `
import sys
from docx import Document
print("Python and python-docx are working!")
print(f"Python version: {sys.version}")
    `]);

    let output = '';
    let error = '';

    pythonProcess.stdout.on('data', (data) => {
      output += data.toString();
    });

    pythonProcess.stderr.on('data', (data) => {
      error += data.toString();
    });

    pythonProcess.on('close', (code) => {
      if (code === 0) {
        res.json({
          success: true,
          output: output.trim(),
          message: 'Python and python-docx integration working!'
        });
      } else {
        res.status(500).json({
          success: false,
          error: error.trim(),
          exitCode: code
        });
      }
    });

  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ğŸ”§ NEW: Download endpoint for transcribed files
app.get('/api/download/:filename', (req, res) => {
  try {
    const filename = req.params.filename;
    const filePath = path.join(PERSISTENT_PATH, 'transcriptions', filename);

    console.log(`ğŸ“¥ Download request for: ${filename}`);

    if (!fs.existsSync(filePath)) {
      console.log(`âŒ File not found: ${filePath}`);
      return res.status(404).json({ success: false, error: '×§×•×‘×¥ ×œ× × ××¦×' });
    }

    const originalName = filename.replace(/_\d+\.docx$/, '.docx'); // Remove timestamp
    const hebrewName = originalName;

    res.setHeader('Content-Disposition', `attachment; filename*=UTF-8''${encodeURIComponent(hebrewName)}`);
    res.setHeader('Content-Type', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document');

    const fileStream = fs.createReadStream(filePath);
    fileStream.pipe(res);

    console.log(`âœ… Download started for: ${filename}`);
  } catch (error) {
    console.error('Download error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×”×•×¨×“×ª ×”×§×•×‘×¥' });
  }
});

app.get('/api/test', (req, res) => {
  res.json({
    success: true,
    message: 'API is working!',
    geminiConfigured: !!process.env.GEMINI_API_KEY,
    geminiKeyLength: process.env.GEMINI_API_KEY ? process.env.GEMINI_API_KEY.length : 0,
    geminiKeyPrefix: process.env.GEMINI_API_KEY ? process.env.GEMINI_API_KEY.substring(0, 10) + '...' : 'none',
    emailConfigured: !!process.env.EMAIL_USER,
    ffmpegAvailable: checkFFmpegAvailability()
  });
});

// Authentication routes
app.post('/api/login', (req, res) => {
  try {
    const clientIP = getClientIP(req);

    // Rate limiting: 10 login attempts per IP per 15 minutes
    if (isRateLimited('login', clientIP, 10, 15)) {
      console.log(`â›” Login rate limit exceeded for IP: ${clientIP}`);
      return res.status(429).json({
        success: false,
        error: '×™×•×ª×¨ ××“×™ × ×™×¡×™×•× ×•×ª ×”×ª×—×‘×¨×•×ª. × ×¡×” ×©×•×‘ ×‘×¢×•×“ 15 ×“×§×•×ª.'
      });
    }

    console.log('ğŸ” Login attempt:', req.body);
    
    const { email, password } = req.body;
    
    if (!email || !password) {
      return res.json({ success: false, error: '××™××™×™×œ ×•×¡×™×¡××” × ×“×¨×©×™×' });
    }
    
    const user = users.find(u => u.email.toLowerCase() === email.toLowerCase() && u.password === password);
    console.log('ğŸ” User found:', user ? 'Yes' : 'No');
    console.log('ğŸ“‹ Available users:', users.map(u => ({ email: u.email, isAdmin: u.isAdmin })));
    
    if (user) {
      // Check if email verification is required (for new users only)
      if (user.emailVerified === false) {
        console.log('âŒ Login blocked - email not verified for:', user.email);
        return res.json({
          success: false,
          error: '×™×© ×œ×××ª ××ª ×›×ª×•×‘×ª ×”××™×™×œ ×§×•×“×. ×‘×“×•×§ ××ª ×ª×™×‘×ª ×”×“×•××¨ ×©×œ×š.',
          needsVerification: true,
          email: user.email
        });
      }

      console.log('âœ… Login successful for:', user.email);
      res.json({ success: true, user: { ...user, password: undefined } });
    } else {
      console.log('âŒ Login failed for:', email);
      res.json({ success: false, error: '××™××™×™×œ ××• ×¡×™×¡××” ×©×’×•×™×™×' });
    }
  } catch (error) {
    console.error('Login error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×©×¨×ª' });
  }
});

// User sync endpoint - sync localStorage with server data
app.post('/api/user-sync', (req, res) => {
  try {
    const { email } = req.body;

    if (!email) {
      return res.json({ success: false, error: 'Email required' });
    }

    const user = users.find(u => u.email.toLowerCase() === email.toLowerCase());

    if (user) {
      console.log('ğŸ”„ User sync successful for:', user.email);
      res.json({ success: true, user: { ...user, password: undefined } });
    } else {
      console.log('âŒ User not found for sync:', email);
      res.json({ success: false, error: 'User not found' });
    }
  } catch (error) {
    console.error('User sync error:', error);
    res.status(500).json({ success: false, error: 'Server error' });
  }
});

app.post('/api/register', async (req, res) => {
  try {
    const clientIP = getClientIP(req);

    // Rate limiting: 3 registrations per IP per hour
    if (isRateLimited('registration', clientIP, 3, 60)) {
      console.log(`â›” Registration rate limit exceeded for IP: ${clientIP}`);
      return res.status(429).json({
        success: false,
        error: '×™×•×ª×¨ ××“×™ ×”×¨×©××•×ª ××”×›×ª×•×‘×ª ×©×œ×š. × ×¡×” ×©×•×‘ ×‘×¢×•×“ ×©×¢×”.'
      });
    }

    console.log('ğŸ“ Registration attempt:', req.body);

    const { name, email, password, phone } = req.body;

    if (!name || !email || !password) {
      return res.json({ success: false, error: '×©×, ××™××™×™×œ ×•×¡×™×¡××” × ×“×¨×©×™×' });
    }

    if (users.find(u => u.email.toLowerCase() === email.toLowerCase())) {
      console.log('âŒ User already exists:', email);
      return res.json({ success: false, error: '××©×ª××© ×¢× ×”××™××™×™×œ ×”×–×” ×›×‘×¨ ×§×™×™×' });
    }

    // Additional rate limiting: 1 registration per email per day
    if (isRateLimited('registration', email, 1, 24 * 60)) {
      console.log(`â›” Email registration rate limit exceeded: ${email}`);
      return res.json({
        success: false,
        error: '×›×‘×¨ × ×¨×©××ª ×¢× ×”××™××™×™×œ ×”×–×” ×”×™×•×. × ×¡×” ×©×•×‘ ××—×¨.'
      });
    }

    // Generate verification code
    const verificationCode = Math.floor(100000 + Math.random() * 900000).toString();

    const newUser = {
      id: users.length + 1,
      name,
      email: email.toLowerCase(),
      password,
      phone: phone || '',
      isAdmin: false,
      remainingMinutes: 0, // No free minutes
      totalTranscribed: 0,
      history: [],
      transcriptionHistory: [],
      joinDate: new Date().toISOString(),
      emailVerified: false,
      verificationCode: verificationCode,
      verificationExpires: new Date(Date.now() + 24 * 60 * 60 * 1000) // 24 hours
    };

    // Rate limiting for email sending: 3 emails per email address per hour
    if (isRateLimited('verification', `email_${email}`, 3, 60)) {
      console.log(`â›” Email sending rate limit exceeded: ${email}`);
      return res.json({
        success: false,
        error: '× ×©×œ×—×• ×™×•×ª×¨ ××“×™ ××™×™×œ×™ ××™××•×ª. × ×¡×” ×©×•×‘ ×‘×¢×•×“ ×©×¢×”.'
      });
    }

    // Send verification email
    try {
      const mailOptions = {
        from: process.env.EMAIL_USER,
        to: email,
        subject: '×××ª ××ª ×”××™×™×œ ×©×œ×š - ××¢×¨×›×ª ×ª××œ×•×œ',
        html: `
          <div dir="rtl" style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
            <h2 style="color: #3b82f6;">×‘×¨×•×š ×”×‘× ×œ××¢×¨×›×ª ×”×ª××œ×•×œ! ğŸ™ï¸</h2>
            <p>×©×œ×•× ${name},</p>
            <p>×ª×•×“×” ×©× ×¨×©××ª ×œ××¢×¨×›×ª ×”×ª××œ×•×œ ×©×œ× ×•. ×›×“×™ ×œ×”×©×œ×™× ××ª ×”×”×¨×©××”, ×× × ×××ª ××ª ×›×ª×•×‘×ª ×”××™×™×œ ×©×œ×š.</p>

            <div style="background: #f3f4f6; padding: 20px; border-radius: 8px; text-align: center; margin: 20px 0;">
              <h3 style="margin: 0;">×§×•×“ ×”××™××•×ª ×©×œ×š:</h3>
              <div style="font-size: 32px; font-weight: bold; color: #3b82f6; margin: 10px 0; letter-spacing: 5px;">
                ${verificationCode}
              </div>
              <p style="margin: 0; color: #666;">×”×§×•×“ ×ª×§×£ ×œ××©×š 24 ×©×¢×•×ª</p>
            </div>

            <p>××—×¨×™ ×©×ª×××ª ××ª ×”××™×™×œ, ×ª×•×›×œ ×œ×”×ª×—×‘×¨ ×•×œ×”×ª×—×™×œ ×œ×”×©×ª××© ×‘××¢×¨×›×ª.</p>

            <p style="margin-top: 30px;">
              ×‘×‘×¨×›×”,<br>
              ×¦×•×•×ª ××¢×¨×›×ª ×”×ª××œ×•×œ
            </p>
          </div>
        `
      };

      await transporter.sendMail(mailOptions);
      console.log('âœ… Verification email sent to:', email);

    } catch (emailError) {
      console.error('âŒ Failed to send verification email:', emailError);
      return res.json({ success: false, error: '×©×’×™××” ×‘×©×œ×™×—×ª ××™×™×œ ××™××•×ª' });
    }

    users.push(newUser);
    saveUsersData(); // Save after adding new user
    console.log('âœ… User registered successfully (pending verification):', newUser.email);
    console.log('ğŸ“‹ Total users now:', users.length);

    res.json({
      success: true,
      message: '×”×¨×©××” ×”×•×©×œ××”! × ×©×œ×— ××œ×™×š ××™×™×œ ×¢× ×§×•×“ ××™××•×ª.',
      needsVerification: true
    });
  } catch (error) {
    console.error('Registration error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×”×¨×©××”' });
  }
});

// Email verification endpoint
app.post('/api/verify-email', (req, res) => {
  try {
    const { email, verificationCode } = req.body;

    // Rate limiting: 5 verification attempts per email per 15 minutes
    if (isRateLimited('verification', email, 5, 15)) {
      console.log(`â›” Verification rate limit exceeded for email: ${email}`);
      return res.status(429).json({
        success: false,
        error: '×™×•×ª×¨ ××“×™ × ×™×¡×™×•× ×•×ª ××™××•×ª. × ×¡×” ×©×•×‘ ×‘×¢×•×“ 15 ×“×§×•×ª.'
      });
    }

    if (!email || !verificationCode) {
      return res.json({ success: false, error: '××™××™×™×œ ×•×§×•×“ ××™××•×ª × ×“×¨×©×™×' });
    }

    const user = users.find(u => u.email.toLowerCase() === email.toLowerCase());

    if (!user) {
      console.log('âŒ User not found for verification:', email);
      return res.json({ success: false, error: '××©×ª××© ×œ× × ××¦×' });
    }

    if (user.emailVerified) {
      console.log('âš ï¸ User already verified:', email);
      return res.json({ success: false, error: '×”××™×™×œ ×›×‘×¨ ×××•××ª' });
    }

    if (user.verificationCode !== verificationCode) {
      console.log('âŒ Invalid verification code for:', email);
      return res.json({ success: false, error: '×§×•×“ ××™××•×ª ×©×’×•×™' });
    }

    if (new Date() > new Date(user.verificationExpires)) {
      console.log('âŒ Verification code expired for:', email);
      return res.json({ success: false, error: '×§×•×“ ×”××™××•×ª ×¤×’ ×ª×•×§×£. ×× × ×”×™×¨×©× ××—×“×©.' });
    }

    // Mark as verified
    user.emailVerified = true;
    delete user.verificationCode;
    delete user.verificationExpires;
    saveUsersData();

    console.log('âœ… Email verified successfully for:', email);

    res.json({
      success: true,
      message: '×”××™×™×œ ××•××ª ×‘×”×¦×œ×—×”! ×›×¢×ª ×ª×•×›×œ ×œ×”×ª×—×‘×¨.',
      user: { ...user, password: undefined }
    });
  } catch (error) {
    console.error('Email verification error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘××™××•×ª ××™×™×œ' });
  }
});

// Admin route to add minutes
app.post('/api/admin/add-minutes', (req, res) => {
  try {
    console.log('ğŸ”§ Admin add-minutes endpoint called');
    console.log('ğŸ”§ Request body:', req.body);
    
    const { userEmail, minutes } = req.body;
    
    if (!userEmail || !minutes || minutes <= 0) {
      console.log('âŒ Invalid input:', { userEmail, minutes });
      return res.status(400).json({ 
        success: false, 
        error: '××™××™×™×œ ×•××¡×¤×¨ ×“×§×•×ª × ×“×¨×©×™×' 
      });
    }
    
    const user = users.find(u => u.email.toLowerCase() === userEmail.toLowerCase());
    console.log('ğŸ” User lookup result:', user ? 'Found' : 'Not found');
    console.log('ğŸ“‹ Available users:', users.map(u => u.email));
    
    if (!user) {
      console.log('âŒ User not found for email:', userEmail);
      return res.status(404).json({ 
        success: false, 
        error: `××©×ª××© ×œ× × ××¦×: ${userEmail}` 
      });
    }
    
    const oldBalance = user.remainingMinutes;
    user.remainingMinutes += minutes;
    const newBalance = user.remainingMinutes;
    saveUsersData(); // Save after updating balance

    console.log(`âœ… Added ${minutes} minutes to ${userEmail}: ${oldBalance} â†’ ${newBalance}`);
    
    res.json({ 
      success: true, 
      message: `× ×•×¡×¤×• ${minutes} ×“×§×•×ª ×œ×—×©×‘×•×Ÿ ${userEmail}`,
      oldBalance,
      newBalance,
      user: { ...user, password: undefined }
    });
    
  } catch (error) {
    console.error('ğŸ”§ Admin add-minutes error:', error);
    res.status(500).json({ 
      success: false, 
      error: '×©×’×™××” ×‘×”×•×¡×¤×ª ×“×§×•×ª' 
    });
  }
});

// Admin route to delete user
app.post('/api/admin/delete-user', (req, res) => {
  try {
    console.log('ğŸ—‘ï¸ Admin delete-user endpoint called');
    console.log('ğŸ—‘ï¸ Request body:', req.body);

    const { adminEmail, userEmail } = req.body;

    if (!adminEmail || !userEmail) {
      return res.status(400).json({
        success: false,
        error: '××™××™×™×œ×™ ××“××™×Ÿ ×•××©×ª××© × ×“×¨×©×™×'
      });
    }

    // Verify admin permissions
    const admin = users.find(u => u.email.toLowerCase() === adminEmail.toLowerCase());
    if (!admin || !admin.isAdmin) {
      console.log('âŒ Unauthorized delete attempt by:', adminEmail);
      return res.status(403).json({
        success: false,
        error: '×”×¨×©××•×ª ××“××™×Ÿ × ×“×¨×©×•×ª'
      });
    }

    // Find user to delete
    const userIndex = users.findIndex(u => u.email.toLowerCase() === userEmail.toLowerCase());
    if (userIndex === -1) {
      return res.status(404).json({
        success: false,
        error: `××©×ª××© ×œ× × ××¦×: ${userEmail}`
      });
    }

    const userToDelete = users[userIndex];

    // Prevent deletion of admin users
    if (userToDelete.isAdmin) {
      return res.status(400).json({
        success: false,
        error: '×œ× × ×™×ª×Ÿ ×œ××—×•×§ ××©×ª××© ××“××™×Ÿ'
      });
    }

    // Delete the user
    users.splice(userIndex, 1);
    saveUsersData();

    console.log(`âœ… User deleted successfully: ${userEmail} by admin: ${adminEmail}`);
    console.log(`ğŸ“‹ Total users now: ${users.length}`);

    res.json({
      success: true,
      message: `×”××©×ª××© ${userEmail} × ××—×§ ×‘×”×¦×œ×—×”`,
      totalUsers: users.length
    });

  } catch (error) {
    console.error('Delete user error:', error);
    res.status(500).json({
      success: false,
      error: '×©×’×™××” ×‘××—×™×§×ª ×”××©×ª××©'
    });
  }
});

// Multer error handling middleware
function handleMulterError(err, req, res, next) {
  if (err) {
    console.error('ğŸ“¤ Multer error:', err);

    if (err.code === 'LIMIT_FILE_SIZE') {
      return res.status(413).json({
        success: false,
        error: `×”×§×•×‘×¥ ×’×“×•×œ ××“×™! ×”××’×‘×œ×” ×”×™× 500MB. ×”×§×•×‘×¥ ×©×œ×š: ${Math.round(err.field?.size / (1024 * 1024) || 0)}MB`,
        errorCode: 'FILE_TOO_LARGE',
        maxSize: '500MB'
      });
    }


    if (err.code === 'LIMIT_UNEXPECTED_FILE') {
      return res.status(400).json({
        success: false,
        error: '×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š',
        errorCode: 'UNSUPPORTED_FILE_TYPE'
      });
    }

    // General multer error
    return res.status(400).json({
      success: false,
      error: '×©×’×™××” ×‘×”×¢×œ××ª ×”×§×•×‘×¥: ' + (err.message || '×©×’×™××” ×œ× ×™×“×•×¢×”'),
      errorCode: 'UPLOAD_ERROR'
    });
  }
  next();
}


// Enhanced transcription route (supports both regular files and Google Drive files)
app.post('/api/transcribe', upload.array('files'), handleMulterError, async (req, res) => {
  try {
    console.log('ğŸ¯ Enhanced transcription request received');
    console.log('ğŸ“ Regular files uploaded:', req.files?.length || 0);

    // Parse Google Drive files if any
    const driveFiles = req.body.driveFiles ? JSON.parse(req.body.driveFiles) : [];
    console.log('ğŸ”— Google Drive files:', driveFiles?.length || 0);
    console.log('ğŸ“§ Request body:', { ...req.body, driveFiles: driveFiles?.length ? `${driveFiles.length} files` : 'none' });

    // Check if we have any files at all (either uploaded or from Google Drive)
    const totalFiles = (req.files?.length || 0) + (driveFiles?.length || 0);
    if (totalFiles === 0) {
      return res.status(400).json({ success: false, error: '×œ× × ×‘×—×¨×• ×§×‘×¦×™×' });
    }

    // For now, if there are Google Drive files, return a message that it's coming soon
    if (driveFiles && driveFiles.length > 0) {
      console.log('ğŸ”— Google Drive files detected - feature coming soon');
      return res.status(501).json({
        success: false,
        error: '×ª×›×•× ×ª Google Drive ×–××™× ×” ×‘×§×¨×•×‘ - ×‘×™× ×ª×™×™× ×”×©×ª××© ×‘×”×¢×œ××” ×¨×’×™×œ×” ××”××—×©×‘'
      });
    }

    const { email, language, customInstructions } = req.body;

    console.log('ğŸ¯ Custom instructions received:', customInstructions ? `"${customInstructions}"` : 'None');

    if (!email) {
      return res.status(400).json({ success: false, error: '××™××™×™×œ × ×“×¨×©' });
    }
    
    // Check FFmpeg availability for chunking
    const ffmpegAvailable = checkFFmpegAvailability();
    
    // ××¦× ××• ×™×¦×•×¨ ××©×ª××© ×‘××¡×“ ×”× ×ª×•× ×™×
    const user = await findOrCreateUser(email);
    console.log('ğŸ” User lookup for transcription: Found');
    console.log('ğŸ“§ Email:', email);
    console.log('â±ï¸ User minutes remaining:', user.remainingMinutes);

   // Calculate total estimated minutes ACCURATELY
    let totalDurationSeconds = 0;
    for (const file of req.files) {
        try {
            // Use the accurate function from line 212
            const duration = await getAudioDuration(file.path); 
            totalDurationSeconds += duration;
        } catch (error) {
            console.error(`Could not get duration for ${file.filename}, falling back to size estimate.`, error);
            // Fallback for safety
            totalDurationSeconds += (file.size / (1024 * 1024 * 2)) * 60;
        }
    }

    // Convert total seconds to minutes and round up
    const accurateMinutes = Math.ceil(totalDurationSeconds / 60);

    console.log(`â±ï¸ Accurate minutes calculated: ${accurateMinutes}, User balance: ${user.remainingMinutes}`);

    if (accurateMinutes > user.remainingMinutes) {
        console.log('âŒ Insufficient minutes, deleting uploaded files.');
        // Clean up files immediately if not enough minutes
        for (const file of req.files) {
            try {
                fs.unlinkSync(file.path);
            } catch (e) {
                console.warn(`Could not delete file ${file.path} after failed check.`)
            }
        }
        return res.status(400).json({
            success: false,
            error: `××™×Ÿ ××¡×¤×™×§ ×“×§×•×ª ×‘×—×©×‘×•×Ÿ. × ×“×¨×©: ${accurateMinutes}, ×–××™×Ÿ: ${user.remainingMinutes}`
        });
    }

    // Generate unique transcription ID for cancellation tracking
    const transcriptionId = `trans_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    // Start enhanced async processing with the ACCURATE minutes
    processTranscriptionAsync(req.files, email, language, accurateMinutes, transcriptionId, customInstructions);

    console.log('âœ… Enhanced transcription started successfully with accurate minute count.');
    res.json({
        success: true,
        message: ffmpegAvailable ?
            '×”×ª××œ×•×œ ×”××ª×§×“× ×”×ª×—×™×œ - ×§×‘×¦×™× ×’×“×•×œ×™× ×™×ª×—×œ×§×• ×œ××§×˜×¢×™× ××•×˜×•××˜×™×ª' :
            '×”×ª××œ×•×œ ×”×ª×—×™×œ - ×œ×œ× ×—×œ×•×§×” ×œ××§×˜×¢×™× (FFmpeg ×œ× ×–××™×Ÿ)',
        estimatedMinutes: accurateMinutes, // Return the accurate count to the client
        chunkingEnabled: ffmpegAvailable,
        transcriptionId: transcriptionId // Return transcription ID for cancellation
    });
  } catch (error) {
    console.error('Enhanced transcription error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ğŸ†• Cancel transcription endpoint (safe cancellation window)
app.post('/api/cancel-transcription', (req, res) => {
  try {
    const { transcriptionId, email } = req.body;

    console.log(`ğŸ›‘ Cancellation request for transcription ${transcriptionId} by ${email}`);

    if (!transcriptionId || !email) {
      return res.status(400).json({
        success: false,
        error: '× ×“×¨×© ××–×”×” ×ª××œ×•×œ ×•××™××™×™×œ'
      });
    }

    const transcriptionData = activeTranscriptions.get(transcriptionId);

    if (!transcriptionData) {
      return res.status(404).json({
        success: false,
        error: '×”×ª××œ×•×œ ×œ× × ××¦× ××• ×›×‘×¨ ×”×¡×ª×™×™×'
      });
    }

    if (transcriptionData.userEmail.toLowerCase() !== email.toLowerCase()) {
      return res.status(403).json({
        success: false,
        error: '××™×Ÿ ×”×¨×©××” ×œ×‘×˜×œ ×ª××œ×•×œ ×–×”'
      });
    }

    if (transcriptionData.minutesDeducted) {
      return res.status(400).json({
        success: false,
        error: '×”×ª××œ×•×œ ×›×‘×¨ ×”×ª×—×™×œ - ×œ× × ×™×ª×Ÿ ×œ×‘×˜×œ'
      });
    }

    // Mark as cancelled
    transcriptionData.cancelled = true;
    console.log(`âœ… Transcription ${transcriptionId} marked as cancelled`);

    // Clean up uploaded files immediately
    let filesDeleted = 0;
    transcriptionData.files.forEach(filePath => {
      try {
        if (fs.existsSync(filePath)) {
          fs.unlinkSync(filePath);
          filesDeleted++;
          console.log(`ğŸ—‘ï¸ Deleted cancelled file: ${filePath}`);
        }
      } catch (e) {
        console.warn(`Could not delete file ${filePath}:`, e.message);
      }
    });

    // Remove from tracking
    activeTranscriptions.delete(transcriptionId);

    res.json({
      success: true,
      message: `×”×ª××œ×•×œ ×‘×•×˜×œ ×‘×”×¦×œ×—×”. × ××—×§×• ${filesDeleted} ×§×‘×¦×™×.`,
      filesDeleted
    });

    console.log(`ğŸ›‘ Transcription ${transcriptionId} cancelled successfully`);

  } catch (error) {
    console.error('Cancel transcription error:', error);
    res.status(500).json({
      success: false,
      error: '×©×’×™××” ×‘×‘×™×˜×•×œ ×”×ª××œ×•×œ'
    });
  }
});

// ğŸ†• Get transcription progress endpoint
app.get('/api/transcription-progress/:transcriptionId', (req, res) => {
  try {
    const { transcriptionId } = req.params;
    console.log(`ğŸ“Š Progress request for transcriptionId: '${transcriptionId}'`);
    const transcriptionData = activeTranscriptions.get(transcriptionId);
    console.log(`ğŸ“Š Found transcription data:`, transcriptionData ? 'Yes' : 'No');

    if (!transcriptionData) {
      return res.status(404).json({
        success: false,
        error: '×”×ª××œ×•×œ ×œ× × ××¦× ××• ×”×¡×ª×™×™×'
      });
    }

    // Return current progress information
    res.json({
      success: true,
      progress: {
        percentage: transcriptionData.progress || 0,
        stage: transcriptionData.stage || '××ª×—×™×œ...',
        currentFile: transcriptionData.currentFile || '',
        filesProcessed: transcriptionData.filesProcessed || 0,
        totalFiles: transcriptionData.totalFiles || 0,
        isCompleted: transcriptionData.isCompleted || false
      }
    });

  } catch (error) {
    console.error('Progress check error:', error);
    res.status(500).json({
      success: false,
      error: '×©×’×™××” ×‘×‘×“×™×§×ª ×”×ª×§×“××•×ª ×”×ª××œ×•×œ'
    });
  }
});

// ğŸ”§ NEW: Admin API endpoints
app.get('/api/admin/overview', (req, res) => {
  try {
    const today = new Date().toDateString();
    const newUsersToday = users.filter(user => {
      const userDate = user.joinDate ? new Date(user.joinDate).toDateString() : null;
      return userDate === today;
    }).length;

    const totalTranscriptions = users.reduce((total, user) => {
      return total + (user.history ? user.history.length : 0);
    }, 0);

    const totalMinutesUsed = users.reduce((total, user) => {
      return total + (user.totalTranscribed || 0);
    }, 0);

    res.json({
      success: true,
      totalUsers: users.length,
      newUsersToday,
      totalTranscriptions,
      totalMinutesUsed
    });
  } catch (error) {
    console.error('Admin overview error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×˜×¢×™× ×ª × ×ª×•× ×™×' });
  }
});

app.get('/api/admin/users', (req, res) => {
  try {
    const usersData = users.map(user => ({
      name: user.name,
      email: user.email,
      remainingMinutes: user.remainingMinutes,
      totalTranscribed: user.totalTranscribed || 0,
      joinDate: user.joinDate || '×œ× ×–××™×Ÿ',
      isAdmin: user.isAdmin || false
    }));

    res.json({
      success: true,
      users: usersData
    });
  } catch (error) {
    console.error('Admin users error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×˜×¢×™× ×ª ××©×ª××©×™×' });
  }
});

// Get specific user's transcription history (for admin)
app.get('/api/users/:email/history', (req, res) => {
  try {
    const { email } = req.params;
    const { limit = 20 } = req.query;

    const user = users.find(u => u.email.toLowerCase() === email.toLowerCase());

    if (!user) {
      return res.status(404).json({
        success: false,
        error: '××©×ª××© ×œ× × ××¦×'
      });
    }

    // Check both transcriptionHistory and history for backward compatibility
    const userHistory = user.transcriptionHistory || user.history || [];

    // Sort by timestamp (newest first) and limit results
    const sortedHistory = userHistory
      .sort((a, b) => {
        if (a.timestamp && b.timestamp) {
          return b.timestamp - a.timestamp;
        }
        return 0;
      })
      .slice(0, parseInt(limit));

    res.json({
      success: true,
      history: sortedHistory
    });

  } catch (error) {
    console.error('Error fetching user history:', error);
    res.status(500).json({
      success: false,
      error: '×©×’×™××” ×‘×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×”'
    });
  }
});

app.get('/api/admin/transcriptions', (req, res) => {
  try {
    const allTranscriptions = [];

    users.forEach(user => {
      // Check both transcriptionHistory and history for backward compatibility
      const userHistory = user.transcriptionHistory || user.history || [];
      if (userHistory.length > 0) {
        userHistory.forEach(entry => {
          allTranscriptions.push({
            ...entry,
            userEmail: user.email,
            userName: user.name
          });
        });
      }
    });

    // Sort by date (newest first)
    allTranscriptions.sort((a, b) => {
      if (a.timestamp && b.timestamp) {
        return b.timestamp - a.timestamp;
      }
      return 0;
    });

    // Take only the last 50 transcriptions for performance
    const recentTranscriptions = allTranscriptions.slice(0, 50);

    res.json({
      success: true,
      transcriptions: recentTranscriptions
    });
  } catch (error) {
    console.error('Admin transcriptions error:', error);
    res.status(500).json({ success: false, error: '×©×’×™××” ×‘×˜×¢×™× ×ª ×ª××œ×•×œ×™×' });
  }
});

// ğŸ”§ NEW: History and files cleanup function
function cleanupOldHistory() {
  const thirtyDaysAgo = Date.now() - (30 * 24 * 60 * 60 * 1000); // 30 days in milliseconds
  let totalCleaned = 0;
  let totalFilesDeleted = 0;

  users.forEach(user => {
    if (user.history && user.history.length > 0) {
      const originalCount = user.history.length;

      // Keep only entries from the last 30 days
      user.history = user.history.filter(entry => {
        // For backward compatibility, keep entries without timestamp
        if (!entry.timestamp) return true;

        // If entry is older than 30 days, also delete its file
        if (entry.timestamp <= thirtyDaysAgo && entry.downloadUrl) {
          try {
            const filename = entry.downloadUrl.split('/').pop();
            const filePath = path.join(PERSISTENT_PATH, 'transcriptions', filename);
            if (fs.existsSync(filePath)) {
              fs.unlinkSync(filePath);
              totalFilesDeleted++;
              console.log(`ğŸ—‘ï¸ Deleted old file: ${filename}`);
            }
          } catch (error) {
            console.warn(`âš ï¸ Could not delete file for entry: ${entry.fileName}`, error.message);
          }
        }

        return entry.timestamp > thirtyDaysAgo;
      });

      const cleanedCount = originalCount - user.history.length;
      if (cleanedCount > 0) {
        totalCleaned += cleanedCount;
        console.log(`ğŸ§¹ Cleaned ${cleanedCount} old history entries for user: ${user.email}`);
      }
    }
  });

  if (totalCleaned > 0 || totalFilesDeleted > 0) {
    saveUsersData(); // Save after cleanup
    console.log(`ğŸ§¹ Total cleanup: Removed ${totalCleaned} history entries and ${totalFilesDeleted} old files`);
  }
}

// ğŸ”§ NEW: Schedule daily cleanup at midnight
function scheduleHistoryCleanup() {
  const now = new Date();
  const tomorrow = new Date(now);
  tomorrow.setDate(tomorrow.getDate() + 1);
  tomorrow.setHours(0, 0, 0, 0); // Set to midnight

  const msUntilMidnight = tomorrow.getTime() - now.getTime();

  // Schedule first cleanup at next midnight
  setTimeout(() => {
    cleanupOldHistory();

    // Then schedule daily cleanups
    setInterval(() => {
      cleanupOldHistory();
    }, 24 * 60 * 60 * 1000); // Every 24 hours

  }, msUntilMidnight);

  console.log(`ğŸ•’ History cleanup scheduled for every day at midnight`);
}

// Start server
// Graceful shutdown handling
process.on('SIGINT', () => {
  console.log('\nğŸ›‘ Received SIGINT, saving data before shutdown...');
  saveUsersData();
  console.log('ğŸ’¾ Data saved successfully');
  process.exit(0);
});

process.on('SIGTERM', () => {
  console.log('\nğŸ›‘ Received SIGTERM, saving data before shutdown...');
  saveUsersData();
  console.log('ğŸ’¾ Data saved successfully');
  process.exit(0);
});

// EMAIL TRANSCRIPTION SYSTEM DISABLED
// let processedEmails = new Set(); // Disabled - not tracking emails anymore

// Email monitoring disabled - not using email transcription service
function startEmailMonitoring() {
  console.log('ğŸ“§ Email monitoring disabled per user request - not checking for transcription emails');
  // Function disabled - no longer checking emails for audio/video files
}

// Email checking disabled - not using email transcription service
async function checkForTranscriptionEmails() {
  // Function disabled - no longer checking emails for audio/video files
  console.log('ğŸ“§ Email checking skipped - email transcription service disabled');
  return;
  // Disabled code below:
  /*
  try {
    const imap = new Imap(imapConfig);

    imap.once('ready', function() {
      console.log('ğŸ“§ Connected to email server, checking for new emails...');

      imap.openBox('INBOX', true, function(err, box) {
        if (err) {
          console.error('ğŸ“§ Error opening inbox:', err);
          return;
        }

        // Search for unread emails with attachments from last 24 hours
        const criteria = [
          'UNSEEN',
          ['SINCE', new Date(Date.now() - 24 * 60 * 60 * 1000)]
        ];

        imap.search(criteria, function(err, results) {
          if (err) {
            console.error('ğŸ“§ Email search error:', err);
            return;
          }

          if (results && results.length > 0) {
            console.log(`ğŸ“§ Found ${results.length} new emails to check`);
            processEmails(imap, results);
          } else {
            console.log('ğŸ“§ No new emails found');
          }

          imap.end();
        });
      });
    });

    imap.once('error', function(err) {
      console.error('ğŸ“§ IMAP connection error:', err);
    });

    imap.connect();

  } catch (error) {
    console.error('ğŸ“§ Email monitoring error:', error);
  }
  */
}

// Process found emails
// Email processing disabled - not using email transcription service
function processEmails(imap, uids) {
  // Function disabled - no longer processing emails for audio/video files
  return;
  const fetch = imap.fetch(uids, {
    bodies: ['HEADER.FIELDS (FROM TO SUBJECT DATE)', 'TEXT'],
    struct: true
  });

  fetch.on('message', function(msg, seqno) {
    let emailData = {
      headers: {},
      body: '',
      attachments: [],
      uid: null,
      seqno: seqno
    };

    msg.on('body', function(stream, info) {
      let buffer = '';

      stream.on('data', function(chunk) {
        buffer += chunk.toString('utf8');
      });

      stream.once('end', function() {
        if (info.which === 'TEXT') {
          emailData.body = buffer;
        } else {
          // Parse headers
          const lines = buffer.split('\r\n');
          lines.forEach(line => {
            const match = line.match(/^([^:]+):\s*(.*)$/);
            if (match) {
              emailData.headers[match[1].toLowerCase()] = match[2];
            }
          });
        }
      });
    });

    msg.once('attributes', function(attrs) {
      // Save UID for later use
      emailData.uid = attrs.uid;

      // Process attachments
      if (attrs.struct) {
        extractAttachments(attrs.struct, emailData);
      }
    });

    msg.once('end', function() {
      // Download attachments immediately while IMAP connection is still active
      if (emailData.attachments.length > 0) {
        downloadAttachmentsInPlace(emailData, imap, seqno)
          .then(() => {
            // Process this email for transcription
            handleTranscriptionEmail(emailData, imap, seqno);
          })
          .catch((error) => {
            console.error('ğŸ“§ Error downloading attachments in place:', error);
            // Try to process anyway
            handleTranscriptionEmail(emailData, imap, seqno);
          });
      } else {
        // Process this email for transcription
        handleTranscriptionEmail(emailData, imap, seqno);
      }
    });
  });

  fetch.once('error', function(err) {
    console.error('ğŸ“§ Fetch error:', err);
  });
}

// Download attachments immediately while IMAP connection is active
// Email attachment download disabled - not using email transcription service
async function downloadAttachmentsInPlace(emailData, imap, seqno) {
  // Function disabled - no longer downloading attachments from emails
  return;
  const tempDir = path.join(__dirname, 'temp_email_attachments');
  if (!fs.existsSync(tempDir)) {
    fs.mkdirSync(tempDir, { recursive: true });
  }

  console.log(`ğŸ“§ Downloading ${emailData.attachments.length} attachments in place for seqno ${seqno}`);

  for (let i = 0; i < emailData.attachments.length; i++) {
    const attachment = emailData.attachments[i];
    if (!attachment.downloadNeeded) continue;

    try {
      const tempFilePath = path.join(tempDir, `${seqno}_${attachment.filename}`);
      console.log(`ğŸ“§ Downloading ${attachment.filename} to ${tempFilePath}`);

      await new Promise((resolve, reject) => {
        const fetch = imap.fetch([seqno], {
          bodies: attachment.partId,
          struct: false
        });

        let attachmentData = Buffer.alloc(0);

        fetch.on('message', function(msg, fetchSeqno) {
          msg.on('body', function(stream, info) {
            let buffer = Buffer.alloc(0);

            stream.on('data', function(chunk) {
              buffer = Buffer.concat([buffer, chunk]);
            });

            stream.once('end', function() {
              // Decode based on encoding
              let finalData = buffer;

              if (attachment.encoding === 'base64') {
                finalData = Buffer.from(buffer.toString(), 'base64');
              } else if (attachment.encoding === 'quoted-printable') {
                // Handle quoted-printable if needed
                finalData = buffer;
              }

              attachmentData = finalData;
            });
          });
        });

        fetch.once('end', function() {
          try {
            fs.writeFileSync(tempFilePath, attachmentData);
            console.log(`ğŸ“§ âœ… Downloaded ${attachment.filename}: ${attachmentData.length} bytes`);

            // Update attachment info
            attachment.downloadedPath = tempFilePath;
            attachment.downloadNeeded = false;
            attachment.actualSize = attachmentData.length;

            resolve();
          } catch (writeError) {
            console.error(`ğŸ“§ Error writing ${attachment.filename}:`, writeError);
            reject(writeError);
          }
        });

        fetch.once('error', function(err) {
          console.error(`ğŸ“§ Error downloading ${attachment.filename}:`, err);
          reject(err);
        });
      });

    } catch (error) {
      console.error(`ğŸ“§ Failed to download ${attachment.filename}:`, error);
      // Continue with other attachments
    }
  }

  console.log(`ğŸ“§ âœ… All attachments downloaded for seqno ${seqno}`);
}

// Extract attachments from email structure
function extractAttachments(struct, emailData, partId = '') {
  if (Array.isArray(struct)) {
    struct.forEach((part, index) => {
      const newPartId = partId ? `${partId}.${index + 1}` : `${index + 1}`;
      extractAttachments(part, emailData, newPartId);
    });
  } else {
    console.log(`ğŸ“§ Checking email part: type=${struct.type}/${struct.subtype}, disposition=${struct.disposition?.type}`);

    // Check for attachments in multiple ways
    const isAttachment =
      (struct.disposition && struct.disposition.type === 'attachment') ||
      (struct.disposition && struct.disposition.type === 'inline') ||
      (struct.disposition && struct.disposition.params?.filename) ||
      (!struct.disposition && struct.params?.name);

    if (isAttachment) {
      const rawFilename =
        struct.disposition?.params?.filename ||
        struct.params?.name ||
        `unknown_${Date.now()}.${struct.subtype}`;

      // Decode filename if it's encoded
      const filename = decodeEmailSubject(rawFilename);

      const type = struct.type + '/' + struct.subtype;

      console.log(`ğŸ“§ Found potential attachment: ${filename}, type: ${type}`);

      // Check if it's an audio/video file
      if (isAudioVideoFile(filename, type)) {
        console.log(`ğŸ“§ âœ… Valid audio/video file: ${filename}`);
        emailData.attachments.push({
          filename: filename,
          type: type,
          encoding: struct.encoding,
          size: struct.size,
          partId: partId,
          downloadNeeded: true
        });
      } else {
        console.log(`ğŸ“§ âŒ Not audio/video file: ${filename} (${type})`);
      }
    }
  }
}

// Check if file is audio/video
function isAudioVideoFile(filename, mimeType) {
  if (!filename) return false;

  const audioVideoExtensions = ['.mp3', '.mp4', '.wav', '.m4a', '.mov', '.avi', '.mkv', '.flac', '.aac', '.ogg'];
  const audioVideoTypes = ['audio/', 'video/'];

  const hasValidExtension = audioVideoExtensions.some(ext =>
    filename.toLowerCase().endsWith(ext)
  );

  const hasValidMimeType = audioVideoTypes.some(type =>
    mimeType.toLowerCase().startsWith(type)
  );

  return hasValidExtension || hasValidMimeType;
}

// Decode email subject or filename if it's encoded
function decodeEmailSubject(subject) {
  if (!subject) return '';

  // Handle multiple UTF-8 Base64 encoded parts like =?UTF-8?B?...?= =?UTF-8?B?...?=
  let decoded = subject;
  const encodedMatches = subject.match(/=\?UTF-8\?B\?([^?]+)\?=/g);

  if (encodedMatches) {
    try {
      for (const match of encodedMatches) {
        const base64Part = match.match(/=\?UTF-8\?B\?([^?]+)\?=/)[1];
        const decodedPart = Buffer.from(base64Part, 'base64').toString('utf8');
        decoded = decoded.replace(match, decodedPart);
      }
      return decoded.trim();
    } catch (error) {
      console.log('ğŸ“§ Failed to decode subject/filename, using original');
      return subject;
    }
  }

  return subject;
}

// Handle transcription email with all validation
// Email transcription handling disabled - not using email transcription service
async function handleTranscriptionEmail(emailData, imap, seqno) {
  // Function disabled - no longer handling transcription emails
  return;
  try {
    const from = emailData.headers.from;
    const rawSubject = emailData.headers.subject || '';
    const subject = decodeEmailSubject(rawSubject);

    console.log(`ğŸ“§ Processing email from: ${from}, subject: "${subject}" (raw: "${rawSubject}")`);

    // Create unique email ID to avoid duplicates
    const emailId = `${from}_${emailData.headers.date}_${seqno}`;
    if (processedEmails.has(emailId)) {
      console.log('ğŸ“§ Email already processed, skipping');
      return;
    }

    // 1. Check subject contains transcription keywords
    const transcriptionKeywords = ['×ª××œ×•×œ', 'transcribe', '×ª××œ×™×œ', 'transcription'];
    const hasTranscriptionKeyword = transcriptionKeywords.some(keyword =>
      subject.toLowerCase().includes(keyword.toLowerCase())
    );

    if (!hasTranscriptionKeyword) {
      console.log('ğŸ“§ Email subject does not contain transcription keywords, skipping');
      return;
    }

    // 2. Check for audio/video attachments
    if (!emailData.attachments || emailData.attachments.length === 0) {
      console.log('ğŸ“§ No audio/video attachments found, skipping');
      return;
    }

    // 3. Extract sender email
    const senderEmail = extractEmailAddress(from);
    if (!senderEmail) {
      console.log('ğŸ“§ Could not extract sender email, skipping');
      return;
    }

    // 4. Check if sender is registered user
    const user = users.find(u => u.email.toLowerCase() === senderEmail.toLowerCase());
    if (!user) {
      console.log(`ğŸ“§ Sender ${senderEmail} is not a registered user, sending info email`);
      await sendRegistrationInfoEmail(senderEmail);
      return;
    }

    // 5. Mark email as processed
    processedEmails.add(emailId);

    // 6. Process transcription
    console.log(`ğŸ“§ âœ… Valid transcription request from ${senderEmail} with ${emailData.attachments.length} attachments`);
    await processEmailTranscription(user, emailData, senderEmail);

  } catch (error) {
    console.error('ğŸ“§ Error handling transcription email:', error);
  }
}

// Extract email address from "Name <email@domain.com>" format
function extractEmailAddress(fromHeader) {
  const match = fromHeader.match(/<([^>]+)>/) || fromHeader.match(/([^\s<>]+@[^\s<>]+)/);
  return match ? match[1] : null;
}

// Send registration info to unregistered users
async function sendRegistrationInfoEmail(senderEmail) {
  try {
    const mailOptions = {
      from: process.env.EMAIL_USER,
      to: senderEmail,
      subject: '×”×¨×©××” × ×“×¨×©×ª ×œ×©×™×¨×•×ª ×”×ª××œ×•×œ',
      html: `
        <div dir="rtl" style="font-family: Arial, sans-serif;">
          <h2>×©×œ×•×!</h2>
          <p>×ª×•×“×” ×¢×œ ×”×¤× ×™×™×” ×œ×©×™×¨×•×ª ×”×ª××œ×•×œ ×©×œ× ×•.</p>
          <p>×›×“×™ ×œ×”×©×ª××© ×‘×©×™×¨×•×ª, ×¢×œ×™×š ×œ×”×™×¨×©× ×ª×—×™×œ×” ×‘××ª×¨:</p>
          <a href="https://transcription-app-2uci.onrender.com" style="color: #667eea; font-weight: bold;">
            https://transcription-app-2uci.onrender.com
          </a>
          <p>×œ××—×¨ ×”×¨×©××” ×•×¨×›×™×©×ª ×“×§×•×ª ×ª××œ×•×œ, ×ª×•×›×œ ×œ×©×œ×•×— ×§×‘×¦×™ ××•×“×™×• ×œ××™×™×œ ×–×” ×œ×ª××œ×•×œ ××•×˜×•××˜×™.</p>
          <p><strong>××™×š ×–×” ×¢×•×‘×“:</strong></p>
          <ul>
            <li>×”×™×¨×©× ×‘××ª×¨</li>
            <li>×¨×›×•×© ×“×§×•×ª ×ª××œ×•×œ</li>
            <li>×©×œ×— ××™×™×œ ×¢× ×”× ×•×©× "×ª××œ×•×œ" ×•×§×•×‘×¥ ××•×“×™×• ××¦×•×¨×£</li>
            <li>×§×‘×œ ×‘×—×–×¨×” ×§×•×‘×¥ Word ××ª×•××œ×œ</li>
          </ul>
          <p>×‘×‘×¨×›×”,<br>×¦×•×•×ª ×”×ª××œ×•×œ</p>
        </div>
      `
    };

    await transporter.sendMail(mailOptions);
    console.log(`ğŸ“§ Registration info sent to ${senderEmail}`);

  } catch (error) {
    console.error('ğŸ“§ Error sending registration info:', error);
  }
}

// Find and download specific attachment from email structure
async function findAndDownloadAttachment(struct, targetFilename, imap, seqno, outputPath) {
  return new Promise((resolve, reject) => {
    function searchStruct(structure, partId = '') {
      if (Array.isArray(structure)) {
        structure.forEach((part, index) => {
          const newPartId = partId ? `${partId}.${index + 1}` : `${index + 1}`;
          searchStruct(part, newPartId);
        });
      } else {
        const filename = structure.disposition?.params?.filename || structure.params?.name;
        const decodedFilename = decodeEmailSubject(filename || '');

        if (decodedFilename === targetFilename) {
          console.log(`ğŸ“§ Found attachment ${targetFilename} at part ${partId}`);

          // Download this specific part
          const fetch = imap.fetch([seqno], {
            bodies: partId,
            struct: false
          });

          let attachmentData = Buffer.alloc(0);

          fetch.on('message', function(msg, seqno) {
            msg.on('body', function(stream, info) {
              let buffer = Buffer.alloc(0);

              stream.on('data', function(chunk) {
                buffer = Buffer.concat([buffer, chunk]);
              });

              stream.once('end', function() {
                // Decode based on encoding
                let finalData = buffer;

                if (structure.encoding === 'base64') {
                  finalData = Buffer.from(buffer.toString(), 'base64');
                } else if (structure.encoding === 'quoted-printable') {
                  // Handle quoted-printable if needed
                  finalData = buffer;
                }

                attachmentData = finalData;
              });
            });
          });

          fetch.once('end', function() {
            try {
              fs.writeFileSync(outputPath, attachmentData);
              console.log(`ğŸ“§ âœ… Attachment downloaded successfully: ${outputPath} (${attachmentData.length} bytes)`);
              resolve();
            } catch (writeError) {
              console.error(`ğŸ“§ Error writing attachment:`, writeError);
              reject(writeError);
            }
          });

          fetch.once('error', function(err) {
            console.error('ğŸ“§ Error downloading attachment part:', err);
            reject(err);
          });
        }
      }
    }

    searchStruct(struct);
  });
}

// Download attachment from email data - now just copies pre-downloaded file
async function downloadAttachmentFromEmail(emailData, attachment, tempFilePath) {
  console.log(`ğŸ“§ Copying pre-downloaded ${attachment.filename} to ${tempFilePath}`);

  if (attachment.downloadedPath && fs.existsSync(attachment.downloadedPath)) {
    try {
      fs.copyFileSync(attachment.downloadedPath, tempFilePath);
      console.log(`ğŸ“§ âœ… Attachment copied successfully: ${tempFilePath} (${attachment.actualSize} bytes)`);
      return;
    } catch (error) {
      console.error(`ğŸ“§ Error copying pre-downloaded file:`, error);
      throw error;
    }
  } else {
    console.error(`ğŸ“§ Pre-downloaded file not found: ${attachment.downloadedPath}`);
    throw new Error(`Pre-downloaded attachment not found: ${attachment.filename}`);
  }
}

// Process email transcription (download attachments and transcribe)
async function processEmailTranscription(user, emailData, senderEmail) {
  try {
    console.log(`ğŸ“§ Processing transcription for ${senderEmail} with ${emailData.attachments.length} files`);

    // Calculate total estimated duration
    let totalEstimatedMinutes = 0;
    emailData.attachments.forEach(attachment => {
      // Rough estimate: 1MB = 1 minute for audio, 3MB = 1 minute for video
      const fileSizeMB = (attachment.size || 1000000) / (1024 * 1024);
      const isVideo = attachment.type.startsWith('video/');
      const estimatedMinutes = isVideo ? Math.ceil(fileSizeMB / 3) : Math.ceil(fileSizeMB / 1.2);
      totalEstimatedMinutes += estimatedMinutes;
    });

    console.log(`ğŸ“§ Estimated total duration: ${totalEstimatedMinutes} minutes`);

    // Check user balance
    if (user.remainingMinutes < totalEstimatedMinutes) {
      console.log(`ğŸ“§ Insufficient balance: ${user.remainingMinutes} < ${totalEstimatedMinutes}`);
      await sendInsufficientBalanceEmail(senderEmail, user.remainingMinutes, totalEstimatedMinutes);
      return;
    }

    // Process each attachment
    const transcriptionResults = [];
    let actualMinutesUsed = 0;

    for (let i = 0; i < emailData.attachments.length; i++) {
      const attachment = emailData.attachments[i];
      console.log(`ğŸ“§ Processing attachment ${i + 1}/${emailData.attachments.length}: ${attachment.filename}`);

      try {
        console.log(`ğŸ“§ Starting real transcription of ${attachment.filename}`);

        // Download attachment to temporary file
        const tempDir = path.join(__dirname, 'temp_email_uploads');
        if (!fs.existsSync(tempDir)) {
          fs.mkdirSync(tempDir, { recursive: true });
        }

        const tempFilePath = path.join(tempDir, `email_${Date.now()}_${attachment.filename}`);
        console.log(`ğŸ“§ Downloading attachment to: ${tempFilePath}`);

        // Download the actual attachment from the email
        await downloadAttachmentFromEmail(emailData, attachment, tempFilePath);
        console.log(`ğŸ“§ File downloaded successfully, starting transcription...`);

        // Get actual audio duration for accurate billing
        let actualDuration;
        try {
          actualDuration = await getAudioDuration(tempFilePath);
        } catch (durationError) {
          console.warn(`âš ï¸ Could not get audio duration, using file size estimate`);
          // Fallback to file size estimation
          const fileSizeMB = (attachment.size || 1000000) / (1024 * 1024);
          const isVideo = attachment.type.startsWith('video/');
          actualDuration = isVideo ? (fileSizeMB / 3) * 60 : (fileSizeMB / 1.2) * 60;
        }
        const durationMinutes = Math.ceil(actualDuration / 60);

        console.log(`ğŸ“§ Starting real transcription of ${attachment.filename} (${durationMinutes} minutes)`);

        // Transcribe the real audio file using our transcription system
        let realTranscription;
        try {
          if (durationMinutes <= 15) {
            // Direct transcription for short files
            realTranscription = await directGeminiTranscription(tempFilePath, attachment.filename, 'Hebrew');
          } else {
            // Chunked transcription for longer files
            realTranscription = await chunkedGeminiTranscription(tempFilePath, attachment.filename, 'Hebrew', durationMinutes, null);
          }
        } catch (transcriptionError) {
          console.error(`ğŸ“§ Transcription failed for ${attachment.filename}:`, transcriptionError);
          throw new Error(`×©×’×™××” ×‘×ª××œ×•×œ ×”×§×•×‘×¥ ${attachment.filename}: ${transcriptionError.message}`);
        }

        console.log(`ğŸ“§ Real transcription completed: ${realTranscription.length} characters`);

        // Create Word document with real transcription
        const wordFilePath = await createWordDocument(realTranscription, attachment.filename, durationMinutes);

        const result = {
          filename: attachment.filename,
          transcription: realTranscription,
          duration: durationMinutes,
          wordFilePath: wordFilePath,
          success: true
        };

        transcriptionResults.push(result);
        actualMinutesUsed += result.duration;

        // Clean up temporary file
        try {
          fs.unlinkSync(tempFilePath);
          console.log(`ğŸ—‘ï¸ Cleaned up temporary file: ${tempFilePath}`);
        } catch (cleanupError) {
          console.warn(`âš ï¸ Could not delete temp file: ${tempFilePath}`);
        }

      } catch (error) {
        console.error(`ğŸ“§ Error processing ${attachment.filename}:`, error);
        transcriptionResults.push({
          filename: attachment.filename,
          error: error.message,
          success: false
        });
      }
    }

    // Update user balance
    user.remainingMinutes = Math.max(0, user.remainingMinutes - actualMinutesUsed);

    // Add to transaction history
    if (!user.transactions) {
      user.transactions = [];
    }
    user.transactions.push({
      type: 'usage',
      amount: -actualMinutesUsed,
      description: `×ª××œ×•×œ ××™××™×™×œ: ${emailData.attachments.length} ×§×‘×¦×™×`,
      timestamp: new Date().toISOString(),
      source: 'email'
    });

    // Save user data
    await saveUsersData();

    // Send results email
    await sendTranscriptionResultsEmail(senderEmail, transcriptionResults, actualMinutesUsed, user.remainingMinutes);

    console.log(`ğŸ“§ âœ… Email transcription completed for ${senderEmail}. Used: ${actualMinutesUsed} minutes, Remaining: ${user.remainingMinutes} minutes`);

  } catch (error) {
    console.error('ğŸ“§ Error in email transcription processing:', error);
    await sendErrorEmail(senderEmail, error.message);
  }
}

// Send insufficient balance email
async function sendInsufficientBalanceEmail(senderEmail, currentBalance, requiredMinutes) {
  try {
    const mailOptions = {
      from: process.env.EMAIL_USER,
      to: senderEmail,
      subject: '×”×ª××œ×•×œ × ×›×©×œ - ×™×ª×¨×” ×œ× ××¡×¤×™×§×”',
      html: `
        <div dir="rtl" style="font-family: Arial, sans-serif; font-size: 18px;">
          <p><strong>×”×ª××œ×•×œ × ×›×©×œ!</strong></p>
          <p>××•×¨×š ×”×§×•×‘×¥: ${requiredMinutes} ×“×§×•×ª</p>
          <p>×™×ª×¨×” × ×•×›×—×™×ª: ${currentBalance} ×“×§×•×ª</p>
        </div>
      `
    };

    await transporter.sendMail(mailOptions);
    console.log(`ğŸ“§ Insufficient balance email sent to ${senderEmail}`);

  } catch (error) {
    console.error('ğŸ“§ Error sending insufficient balance email:', error);
  }
}

// Send transcription results email
async function sendTranscriptionResultsEmail(senderEmail, results, minutesUsed, remainingMinutes) {
  try {
    const successfulResults = results.filter(r => r.success);

    let transcriptionContent = '';
    const attachments = [];

    successfulResults.forEach((result, index) => {
      transcriptionContent += `\n\n=== ${result.filename} ===\n${result.transcription}`;

      // Add Word file as attachment
      if (result.wordFilePath && fs.existsSync(result.wordFilePath)) {
        attachments.push({
          filename: `${result.filename.replace(/\.[^/.]+$/, '')}.docx`,
          path: result.wordFilePath
        });
      }
    });

    const mailOptions = {
      from: process.env.EMAIL_USER,
      to: senderEmail,
      subject: '×”×ª××œ×•×œ ×©×œ×š ××•×›×Ÿ!',
      html: `
        <div dir="rtl" style="font-family: Arial, sans-serif; font-size: 18px;">
          <p><strong>×”×ª××œ×•×œ ×©×œ×š ××•×›×Ÿ!</strong></p>
          <p>××•×¨×š ×”×§×•×‘×¥: ${minutesUsed} ×“×§×•×ª</p>
          <p>×™×ª×¨×” × ×•×ª×¨×ª: ${remainingMinutes} ×“×§×•×ª</p>

          <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; white-space: pre-wrap; font-family: monospace; margin-top: 20px;">
            ${transcriptionContent || '××™×Ÿ ×ª××œ×•×œ ×–××™×Ÿ'}
          </div>
        </div>
      `,
      attachments: attachments
    };

    await transporter.sendMail(mailOptions);
    console.log(`ğŸ“§ Transcription results sent to ${senderEmail} with ${attachments.length} Word files`);

    // Clean up temporary Word files
    successfulResults.forEach(result => {
      if (result.wordFilePath && fs.existsSync(result.wordFilePath)) {
        try {
          fs.unlinkSync(result.wordFilePath);
          console.log(`ğŸ—‘ï¸ Cleaned up temp Word file: ${result.wordFilePath}`);
        } catch (error) {
          console.error(`Error cleaning up ${result.wordFilePath}:`, error);
        }
      }
    });

  } catch (error) {
    console.error('ğŸ“§ Error sending transcription results:', error);
  }
}

// Send error email
async function sendErrorEmail(senderEmail, errorMessage) {
  try {
    const mailOptions = {
      from: process.env.EMAIL_USER,
      to: senderEmail,
      subject: '×”×ª××œ×•×œ × ×›×©×œ - ×©×’×™××” ×˜×›× ×™×ª',
      html: `
        <div dir="rtl" style="font-family: Arial, sans-serif; font-size: 18px;">
          <p><strong>×”×ª××œ×•×œ × ×›×©×œ!</strong></p>
          <p>×¡×™×‘×”: ×©×’×™××” ×˜×›× ×™×ª</p>
        </div>
      `
    };

    await transporter.sendMail(mailOptions);
    console.log(`ğŸ“§ Error email sent to ${senderEmail}`);

  } catch (error) {
    console.error('ğŸ“§ Error sending error email:', error);
  }
}

// Start server without MongoDB
const server = app.listen(PORT, () => {
  const ffmpegAvailable = checkFFmpegAvailability();

  console.log(`ğŸš€ Enhanced server running on port ${PORT}`);
  console.log(`ğŸ”‘ Gemini API configured: ${!!process.env.GEMINI_API_KEY}`);
  console.log(`ğŸ“§ Email configured: ${!!process.env.EMAIL_USER}`);
  console.log(`ğŸ“‚ Data file: ${DATA_FILE}`);
  console.log(`ğŸ“ Transcriptions folder: ${downloadsDir}`);
  console.log(`ğŸ’¾ Backups folder: ${BACKUPS_DIR}`);

  if (ffmpegAvailable) {
    console.log(`âœ… FFmpeg is available - enhanced chunking enabled`);
  } else {
    console.log(`âš ï¸ FFmpeg not available - using direct transcription only`);
  }

  console.log(`ğŸ¯ Enhanced features: Smart chunking for large files, complete transcription guarantee`);

  // Start history cleanup scheduler
  scheduleHistoryCleanup();

  // Email monitoring disabled per user request
  console.log('ğŸ•’ History cleanup scheduled for every day at midnight');
  console.log('ğŸ“§ Email monitoring disabled - not using email transcription service');
});
























































